accurately and less densely than its competitors.
4.4.2. Height Measurement Test 10 km/h
Figure 11 shows the height of the second standing vehicle measured by the LiDAR
in relation to the distance. The actual height of the measured car was 1.7 m. Height mea-
surements are less important for automotive use cases; hence the vertical resolution is
often compromised. A low vertical resolution leads to a phenomenon called quantization.
At far distances of around 150 m, just a few points reﬂect from the measured second vehicle.
The result of the height measurement relies on the highest point that was reﬂected and
is therefore only an approximation that will get better the closer the LiDAR gets to the
measured object. The same applies to width measurements, even though the horizontal
resolution is often higher.
0 50 100 150 200 250 300
Distance to vehicle [m]
0
0.5
1
1.5
2
2.5Measured height of vehicle [m]
Actual Height
Measurement Point
(a)
0 50 100 150 200 250 300
Distance to vehicle [m]
0

Our results show that the different sensors perform quite differently in the various test
scenarios. Some perform well for static scenarios, while they fail at the dynamic scenarios;
some have high deviations in measuring depth information while others struggle with
precise measurements for x and y ranges. We further investigated the observed phenomena,
and our ﬁndings show that this also depends on the scanning patterns that the different
sensors use. Other observations showed that some sensors have particular problems on
object edges, such as crash or jersey barriers. The main contributions of this paper are
as follows:
1. To propose a LiDAR benchmark in realistic drive scenarios.
2. To ﬁnd particular relationships between the scan patterns and the performance in the
proposed real-word tests.
3. To come up with a list of state-of-the-art scanning devices for self-driving cars.
The paper is organized as follows: In Section 2, we discuss related research, while in

result in a too narrow FOV and therefore the sensor was excluded from dynamic tests.
The Velodyne Velarray performed with an average result. There is a noticeable decrease
in the accuracy between 7 m to 12 m. Compared to its competitors, the accuracy of the
Robosense M1 was decreasing less with higher distances. The reason for this could be its
really high amount of points and homogeneous scan pattern with the same amount of
beams in vertical and horizontal alignment. Finally, the Livox Horizon provided a high
accuracy at 7 m to 15 m distance, while at a distance of 25 m, the accuracy decreases. Fewer
points hitting the sphere at this distance lead to a smaller accuracy. It shows marginal noise
for each point; this also explains the accurate measurements at closer distances.
4.2. Scenario 2: Static Square Meter Reference Plane
Figure 7 shows the measured standard deviations for each LiDAR in x, y and z

Figure 9. This ﬁgure presents the visualization of the distortion effect due to movement of the
sensor at high velocities. ( a) Picture of target. (b) View at 10 km/h, Visualization of the measured
point-cloud at 10 km/h rotated so the structure can be viewed from the left side. (c)View at 80 km/h,
The visualization of the measured point-cloud at 80 km/h rotated so the structure can be viewed
from the left side. In (c), the measured structure is virtually stretched over a span of 2.22 m.
4.4. Scenario 4: Dynamic Vehicle Detection
This test was conducted with the selected top three sensors out of the previous scenar-
ios. These three yielded best results so far and are best suited for Scenario 4:
• Robosense M1;
• Velodyne Velarray H800;
• Livox Horizon.
4.4.1. Position Difference Test 10 km/h
Figure 10 shows the difference between the distance to the second vehicle measured
via GPS against the distance to the second vehicle measured by each LiDAR in relation

Scenario 2 (static spheres in increasing distances , Section 4.1) and especially the static
square meter reference plane scenario in Section 4.2 show that the tested LiDAR sensors can
have major deviations in point precision.
Scenario 4 (dynamic vehicle detection, Section 4.4) shows that the scan pattern of a LiDAR
can make a difference, an observation of which researchers and developers seem not to
be very aware. When designing a LiDAR-based use case, the scan pattern should not be
ignored. The results of this publication help to select the best-suited LiDAR for a particular
application. Further, the minor and major differences between the tested LiDAR sensors
and their particular technologies become apparent.
Author Contributions: Conceptualization, J.S.-T., M.R. and A.F.; software, M.F.; validation, J.S.-T.,
M.F. and D.K.; resources, D.M. and D.K.; data curation, J.S.-T.; writing—original draft preparation,

proposed real-word tests.
3. To come up with a list of state-of-the-art scanning devices for self-driving cars.
The paper is organized as follows: In Section 2, we discuss related research, while in
Section 3, we deﬁne four different benchmarks, present the results and discuss them in
Sections 4 and 5, respectively. We conclude with Section 6.
2. Related Work
Recently, LiDAR sensors have gained more attention from the scientiﬁc community,
as many research results about perception [ 8] and localisation [ 9,10] algorithms have
been published.
The team of Lambert, Carballo et al. [11] followed a similar approach and shared in
their work similar ideas. They analyzed 10 different LiDARs. Similar to our work, they
designed their tests with multiple detection targets and varying distance as well as the
surface reﬂectivity of the objects being measured. Furthermore, they used a self-calibration
method for each LiDAR. However, their research focuses solely on static scenarios, whereas

Sensors 2022, 22, 7146 3 of 20
LiDARs on functions with high security implications, such as the detection of children-sized
targets or inﬂuence on human eyesight when exposed to LiDARs.
As shown in [8], in particular, the ﬁeld of deep learning for 3D object detection based
on LiDAR data has made major leaps forward by yielding higher accuracies than previ-
ous methods. Some of the best performing algorithms in terms of quality and execution
times are algorithms processing only point cloud information, which often are provided
by a LiDAR. Good examples for this are PV-RCNN [ 15], PointPillars [ 16] and PointR-
CNN [17], to name just a few. Despite the mentioned approaches use different methods,
they have in common that they all extract features from the point cloud: (1) PC-RCNN
uses a combination of voxel- and point-based feature extractions; (2) PointPillar deploys a
feature extraction from pillar-like groupings of points in a pseudo-image representation of

dimension). Of course, the difference in the distance to the plane should be 0 (x dimension).
Refer to Figures 2c and d for the naming of the axes. The measured sizes will scatter around
the true size and with 1000 measurements we approximate a normal distribution of the
values just like with Scenario 1. The results are shown in Section 4.2.

In this paper, a benchmark of currently available non-rotary LiDAR sensors is pre-
sented to identify suitable LiDAR hardware for real-world usage. The selected LiDARs
were tested in our automated driving (AD) platform, which was developed in a long-
standing research cooperation between the Hyundai Motor Europe Technical Center GmbH
(HMETC) and the University of Applied Science (FH) Aachen. The overall goal is to
develop and to integrate our automated driving software framework [6] into a HMETC
prototype vehicle to support the European research activities of HMETC, particularly in
the European project Hi-Drive [7].
One common argument against LiDAR sensors for mass-produced cars is their price,
which usually heavily exceeds the price of vision-based systems. Current technical devel-
opments, such as the development of solid-state LiDARs, have further reduced the price of
these systems, making them more attractive for vehicle OEM series development activities.

Sensors 2022, 22, 7146 19 of 20
Another measurement type “ﬁrst return” leads to the ﬁrst reﬂected beam to be chosen for
the same calculation.
We want to point out that some problems should be addressed by the manufacturers;
when asked about the fringing and distortion problem, the manufacturer’s technological
support was often unaware that such problems exist or had to speculate.
6. Conclusions
Deploying LiDAR technology has major beneﬁts in many robotics application ﬁelds,
as well in the ﬁeld of automated driving. Series production of automated vehicles would
demand sensors that are precise and in an acceptable price range. A set of different LiDAR
sensors were selected to be benchmarked against each other in four different scenarios.
To the best of our knowledge, benchmark scenarios based on real-life use cases have not
been proposed in the literature before. We divided the scenarios into static and dynamic