{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq pip --progress-bar off\n",
    "%pip install -qqq ollama --progress-bar off\n",
    "%pip install -qqq pathlib --progress-bar off\n",
    "%pip install -qqq pandas --progress-bar off\n",
    "%pip install -qqq PyPDF2 --progress-bar off\n",
    "%pip install -qqq owlready2 --progress-bar off\n",
    "%pip install -qqq rdflib --progress-bar off\n",
    "%pip install -qqq langchain-ollama --progress-bar off\n",
    "%pip install -qqq langchain-community --progress-bar off\n",
    "%pip install -qqq langchain_community pypdf --progress-bar off\n",
    "%pip install -qqq langchain-chroma --progress-bar off\n",
    "%pip install -qqq faiss-cpu --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import ollama\n",
    "import json\n",
    "from enum import Enum\n",
    "import json\n",
    "import re\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.chat_models import ChatOllama\n",
    "from owlready2 import *\n",
    "\n",
    "MODEL = \"deepseek-r1:8b-llama-distill-q8_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove LaTeX equations\n",
    "    text = re.sub(r'\\$.*?\\$', '', text)  # Remove inline equations\n",
    "    # Fix hyphenated words\n",
    "    text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "    # Remove excessive whitespace\n",
    "    return re.sub(r'\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF\n",
    "pdf_loader = PyPDFLoader(file_path=\"LiDAR-Sensors.pdf\",extract_images=False)\n",
    "docs = pdf_loader.load();\n",
    "# Enhanced cleaning pipeline\n",
    "for doc in docs:\n",
    "    doc.page_content = clean_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_splits(splits):\n",
    "    stats = {\n",
    "        'total_chunks': len(splits),\n",
    "        'avg_chunk_length': sum(len(c.page_content) for c in splits)/len(splits),\n",
    "        'max_length': max(len(c.page_content) for c in splits),\n",
    "        'min_length': min(len(c.page_content) for c in splits),\n",
    "        'metadata_fields': list(splits[0].metadata.keys()) if splits else []\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_chunks': 9,\n",
       " 'avg_chunk_length': 2127.6666666666665,\n",
       " 'max_length': 3143,\n",
       " 'min_length': 435,\n",
       " 'metadata_fields': ['source', 'page', 'page_label', 'start_index']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=lambda text: len(text.split()),  # Word-based counting\n",
    "        add_start_index=True,\n",
    "       separators=[\n",
    "        \"\\n\\n## \",    # Section headers\n",
    "        \"\\n\\n\",       # Paragraph breaks\n",
    "        \"\\n\",         # New lines\n",
    "        \"(?<!\\d)\\.(?!\\d)\\s+\",  # Sentence ends with space\n",
    "        \";\",          # Semi-colons\n",
    "        \", \",         # Commas\n",
    "        \" \"\n",
    "        ],\n",
    "        keep_separator=True,\n",
    "        is_separator_regex=True,\n",
    "    )\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "analyze_splits(splits)\n",
    "\n",
    "# word_count(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='d7748f6c-b91d-46cf-bda1-b5ed4a647ed0', metadata={'source': 'LiDAR-Sensors.pdf', 'page': 2, 'page_label': '26', 'start_index': -1}, page_content='. Recording of digitised echo signals and sub - sequent full-waveform analysis. Manufacturer Type/name of Lidar sensor Date of introduction/last update Dimensions - weight [kg] & size [cm] of laser system - weight [kg] & size [cm] of total system - power requirements Laser Pulse Characteristics - wavelength [mm] - pulse length [ns] - beam divergence (across/along tr.) [mrad] - type/class laser - eyesafe range [m] Recording Methodology - scanning method [1] - rotation speed of mirror [2] - pulse frequency (min-max) [Hz] - max. scan angle [deg] - max. # of recorded echoes/pulse - pulse sampling frequency [3] - pulse detection method [4] - dynamic range of intensity signal [bits] Positioning System - GPS system [5] - GPS precision planimetric/height (2 sigma) [cm] - INS system [6] - INS precision (roll/pitch/heading) [deg] - GPS/INS postprocessing software Precision and Resolution - Pointing precision (roll/pitch/heading) [deg] - Range precision (2 sigma) [cm] - Elevation precision at 1km (2 sigma) [cm] - Overall planimetric precision (2 sigma) [cm] - Range precision (2 sigma) [cm] - Max. # of points/m2 - Along-track point spacing [m] [7] - Across-track point spacing [m] [8] Other System Parts - Cameras [9] - Data Storage Facilities [10] - Power equipment Operation Characteristics - typical platform - flying heights (min/typical/max) [m] - max. acquisition duration [hrs] - air temperature (min-max) [°C] - air humidity (min-max) [%] - mission-planning software - postprocessing software - proven applications Remarks [[1] E.g. rotating mirror, oscillating mirror etc. [2] Also called scan frequency. [3] Also called sample interval per pulse. [4] Describe here which part of the reflected pulse is recorded. [5] Brand, number of channels, single or dual frequency, update frequency [Hz] . [6] Brand, update frequency [Hz]. [7] Number referred to flight altitude 1000m. [8] Number referred to a typical flying speed of 150 km/h, or other appropriate speed. [9] Types of camera standard to system. [10] Type of storage facilities (tape, disk, etc.), storage [GB], removable or not.'), Document(id='54e58fb0-8b07-4ba5-9123-87a872a7ec8a', metadata={'source': 'LiDAR-Sensors.pdf', 'page': 0, 'page_label': '24', 'start_index': 5492}, page_content='. # of points/m2 - Along-track point spacing [m] [7] - Across-track point spacing [m] [8] Other System Parts - Cameras [9] - Data Storage Facilities [10] - Power equipment Operation Characteristics - typical platform - flying heights (min/typical/max) [m] - max. acquisition duration [hrs] - air temperature (min-max) [°C] - air humidity (min-max) [%] - mission-planning software - postprocessing software - proven applications Remarks'), Document(id='074e060f-aa97-4b9b-84e4-871c1abf511b', metadata={'source': 'LiDAR-Sensors.pdf', 'page': 2, 'page_label': '26', 'start_index': 0}, page_content='Product survey February 2007 GIM International Riegl LMS LMS-Q240i-60/LMS-Q240i-80 Last update 09/2006 7kg; 18 x 37cm [Dia x L] N/A 43 W 0.9 um < 10ns 2.7 mrad Class 1 0m Rotating multi-facet mirror 6 - 80Hz/ 5 - 60Hz 30,000Hz 60 deg/ 80 deg First or last or alternating N/A Center of gravity of echo pulse 8 bits N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A Helicopter 2m / 200m /350m N/A -10 to + 50 °C 80% (at or below 31°C) N/A N/A Corridor mapping, glacier mapping Small and lightweight sensor, suitable for helicopters, ultra-lights and UAVs. Riegl LMS LMS-S560-I/ LMS-S560-A Last update 10/2006 20kg; 56 x 20 x 22cm [LxWxH] Depending on system configuration 120 W (laser scanner) 1,500nm <4 ns 0.3 mrad with 1 mrad option Class 1 0m Rotating multi-facet mirror 10 - 160Hz 25,000 up to 200,000Hz 60 deg Practically unlimited 1GHz Full waveform processing of complete echo 16 bits Novatel/ Trimble: 12 channels, dual-frequency, up to 10Hz <10 /< 20cm rms / 5 - 30cm rms IGI AEROcontrol / Applanix POS AV 510. 256Hz / 200Hz 0.004 / 0.004 / 0.01 / 0.005 / 0.005 / 0.008 AEROoffice/ POSPac Limited by INS/GPS specification 2cm < 15cm, depending on DGPS accuracy < 10cm, depending on DGPS accuracy 2cm 9 points @ 500m AGL, 90km/h ground speed Min. 0.16m @ 10 scans/s Min. 0.26m @ 160 scans/s IGI DigiCAM / Applanix DSS Hard disk RIEGL DR560, 2 x 320 Gbytes Available Both, complete turnkey solution with Diamond Aircraft twin-engine plane DA42MPP available. 30m / 500m / 1,000m ~ 8 hrs 0 - 40 °C 80% (at or below 31°C) IGI WinMP / TrackAir RiANALYZE 560, RiPROCESS 560, RiWORLD 560 All typical airborne scanning projects. Recording of digitised echo signals & subsequent full-waveform analysis, complete turnkey solution with Diamond Aircraft DA42MPP . Riegl LMS LMS-Q560 Last update 10/2006 20kg; 56 x 20 x 22cm [LxWxH] N/A 120 W 1,500nm <4 ns 0.3 mrad with 1 mrad option Class 1 0m Rotating multi-facet mirror 10 - 160Hz 25,000 up to 200,000Hz 60 deg Practically unlimited 1GHz Full waveform processing of complete echo 16 bits See LMS-S560 system See LMS-S560 system See LMS-S560 system Hard disk RIEGL DR560, 2 x 320 Gbytes N/A Both 30m / 500m / 1000m ~ 8 hrs 0 - 40 °C 80% (at or below 31°C) IGI WinMP/ TrackAir RiANALYZE 560, RiPROCESS 560, RiWORLD 560 All typical airborne scanning projects. Recording of digitised echo signals and sub - sequent full-waveform analysis'), Document(metadata={'source': 'LiDAR-Sensors.pdf', 'page': 3, 'page_label': '27', 'start_index': 2640}, page_content='. T urnkey solution, additional sensors such as temperature, oblique or video available, cus - tomised housing possible, stable frame cam - era also for photogrammetric work,very easy to handle, no operator required. T opoSys GmbH Harrier 24 October 2005 > 10kg customised due to options 2 boxes, > 30kg total 28 V DC, 13 A max. 900nm < 10ns 2.7mrad Class 1 0m Rotating multi-facet mirror 6 - 80Hz / 5 - 60Hz 30,000 60 deg / 80 deg First or last or alternating N/A Center of gravity of echo pulse 8 bits Applanix POSAV 310 5 - 30cm Applanix POSAV 310 0.015/0.015/0.035 deg Applanix Pos/Pac INS precision 3cm 15cm N.A. 3 10 points 0,5 (@150m, 150km/h) 0,7m (@150m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 200GB UPS Helicopter (60°) 3/280/430 (80°) 3/250/380 > 8 hrs 0 to + 50°C 80% (at or below 31°C) TrackAir T opPIT Low-altitude corridor mapping and survey - ing for construction and engineering, snow, ice and glacier mapping, ortho and trueortho images. Entry level system, low-cost turnkey solu - tion, additional sensors such as tempera - ture, oblique or video available, customised housing possible, very easy to handle, no operator required.'), Document(metadata={'source': 'LiDAR-Sensors.pdf', 'page': 3, 'page_label': '27', 'start_index': 0}, page_content='GIM International February 2007 Product survey T opEye T opEye Mk II January 2006 25kg 250kg 500 W 1,064nm 4 ns 1 mrad 3B 40m at low effect Plamer Scanner 0-75Hz 1-50,000 +/- 20 deg 14 deg BWD/FWD Unlimited 2 GigaSamples Full Waveform logic 10 bits Trimble 5700 L1/L2 Honeywell 764 < 0,005 deg POS GPS T opEye PP < 0.25 mrad 2 sigma 1cm - Range indepenent N/A Std Product 30 points N/A N/A Rollei AIC Removable HDD - RW Honeywell 764 60m / 300m / 750m 3 hrs -10°C to + 35°C Non-condensing T opEye MPS T opEye PP & TASQ Corridor, 3D City, PowerLines, etc. The Palmer scanner means that a Laser Echo is extracted from each ‘sub area’ twice with a 4-8 sec time difference by a single mechanical system and with full receiver apperture. T opoSys GmbH Falcon III February 2000/July 2006 > 20kg customised due to options 2 boxes, < 95kg total 28 V DC, 15 A max. 1,550nm 5 ns 0.7 mrad Class IM 0.27m Fibre scanner Up to 415Hz 50,000 - 125,000 28 deg fixed 8 or full waveform Analogue Rising edge detection or full wave form 8 bits Applanix POSAV 510 5 - 30cm Applanix POSAV 510 0.005/0.005/0.008 deg Applanix Pos/Pac INS precision 1cm 7cm 10cm 1 50 points 0,1 (@1000m, 150km/h) 0,3m (@1000m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 500GB UPS Both + high speed aircrafts 30m / 1,500m / 2,000m > 8 hrs -10°C to + 50°C Non-condensing, <95% TrackAir T opPIT All kinds of applications which require high point density and error free data, such as city models, corridor / river / coastal / flood plain / wide area / forest mapping, deposites and mining, contruction and engineering, ortho and true-ortho images. High-end system, turnkey solution, stable scanner geometry avoids any data error, no repetitive calibration required, extremely high survey speed possible > 400km/h, very long flight lines possible. T opoSys GmbH Harrier 56 October 2005/September 2006 > 15kg customised due to options 2 boxes, > 45kg total 28 V DC, 17 A max. 1,550nm < 4 ns 0.3 mrad with up to 1mrad option Class 1 0m Rotating multi-facet mirror 10 - 160Hz 25,000 - 200,000 45 deg. or 60 deg Practically unlimited 1GHz Full waveform processing of complete echo 16 bits Applanix POSAV 410 5 - 30cm Applanix POSAV 410 0.008/0.008/0.015 deg Applanix Pos/Pac INS precision 3cm 15cm 15cm 2 40 points 0,6 (@ 1000m, 150km/h) 0,6m (@ 1000m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 500GB UPS Both 30m / 800m /1,000m > 8 hrs 0° to + 40°C 80% (at or below 31°C) TrackAir T opPIT Corridor mapping such as pipelines or power-lines or motorways, construction and engineering, forest, city, target classification, ortho and true-ortho images'), Document(id='d6f90b27-537a-4ffe-963d-d70d24359735', metadata={'source': 'LiDAR-Sensors.pdf', 'page': 1, 'page_label': '25', 'start_index': 2846}, page_content='. Removable HDD Ground power supply Fixed-wing or helicopter 200 - 6,000m AGL ~17 hrs @ max pulse rate 0 - 40 °C cabin-side temperature Non-condensing Leica FPES Leica ALS Post Processor for point-cloud generation,T erraScan/T erraModeler for viewing/editing. DEMs, city models, flood plain, erosion & forestery studies, forest floor, disaster management, power-lines, pipe-line and railway and roadway corridors, coastal mapping. Full-function system for a wide variety of applications now features highly integrated FCMS flight-management system and flex - ible external sensor integration. Optech ALTM Gemini October 2006 23.4kg, 26 x 19 x 57cm 95kg, control rack size 65 x 59 x 49cm 28 VDC, 35 A (maximum) 1,060nm 7ns 0.8, 0.25, 0.15 1/e Class IV (FDA 21 CFR) 80 m + Oscillating Mirror 100Hz 167kHz 50 deg 4 ranges Leading edge 12 bits Trimble, 12 channel, dual-frequency 0.05cm POS 610, 200 Hz 0.0025/0.0025/0.005 deg POS PAC 0.0025/0.0025/0.005 deg 3cm < 10cm 1/11000 20 points - 100 Knots, 500m, 100Hz scan, +/- 10°, PRF = 167kHz. As above 0.25m As above 0.21m Applanix DSS, Rollei 39 Mpixel Removable hard disk, min 70 Gbytes Internal to the system T win engine fixed-wing, rotary wing 200m / 1km to 2km / 4km max; higher avail - able on request Unlimited -10°C to 35°C 0 to 95% non-condensing ALTM NAV DASHMap Power-line mapping, topographic survey, urban mapping, flood mapping, etc. Multipulse airborne Lidar system with the highest PRF rate of 167kHz in the industry; global 24/7 technical support.'), Document(id='611c374a-4efe-4a79-afea-1498554a892c', metadata={'source': 'LiDAR-Sensors.pdf', 'page': 3, 'page_label': '27', 'start_index': 2640}, page_content='. T urnkey solution, additional sensors such as temperature, oblique or video available, cus - tomised housing possible, stable frame cam - era also for photogrammetric work,very easy to handle, no operator required. T opoSys GmbH Harrier 24 October 2005 > 10kg customised due to options 2 boxes, > 30kg total 28 V DC, 13 A max. 900nm < 10ns 2.7mrad Class 1 0m Rotating multi-facet mirror 6 - 80Hz / 5 - 60Hz 30,000 60 deg / 80 deg First or last or alternating N/A Center of gravity of echo pulse 8 bits Applanix POSAV 310 5 - 30cm Applanix POSAV 310 0.015/0.015/0.035 deg Applanix Pos/Pac INS precision 3cm 15cm N.A. 3 10 points 0,5 (@150m, 150km/h) 0,7m (@150m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 200GB UPS Helicopter (60°) 3/280/430 (80°) 3/250/380 > 8 hrs 0 to + 50°C 80% (at or below 31°C) TrackAir T opPIT Low-altitude corridor mapping and survey - ing for construction and engineering, snow, ice and glacier mapping, ortho and trueortho images. Entry level system, low-cost turnkey solu - tion, additional sensors such as tempera - ture, oblique or video available, customised housing possible, very easy to handle, no operator required.'), Document(metadata={'source': 'LiDAR-Sensors.pdf', 'page': 0, 'page_label': '24', 'start_index': 0}, page_content='Product survey February 2007 GIM International Airborne Lidar Sensors This is the second Product Survey on Airborne Lidar Sensors; the last appeared under the title ‘Airborne Laser-scanners’ in our May 2004 issue. Seven companies were willing to co-operate by filling in the questionnaire for the present survey. ‘Airborne Laser-scanners’ is a term used in Europe; other parts of the world have generally adopted the term ‘Air - borne Lidar’. Two companies represented in our previous survey , Mosaic Mapping Systems and Terrapoint are beyond the scope of the present survey , while we welcome two newcomers. The first is Ingenieur-Gesellschaft für Interfaces (IGI) based in Kreuztal, Germany , which produces and sells the airborne Lidar Terrain Mapping system (LiteMapper) 2400. IGI is an engineering company founded in 1978 by Albrecht Grimm and specialising in the design and development of guidance positioning, attitude determination and sensormanagement systems for airborne survey . The second newcomer is Fugro, a company that operates the FLI-MAP 400 system for Lidar survey . This company is positioned somewhat eccentrically in relation to other firms in that it does not put the FLI-MAP system itself on the for-sale shelf but performs only surveys. However, its system has been developed in-house and differs significantly from what other sensor operators are using in performing surveys based on Lidar systems offered by one or more manufacturers. We felt the uniqueness of the Fugro system qualified it for inclusion in this product survey . Another company standing apart from its counterparts in a similar respect is the German Toposys, which enjoys a unique position worldwide in that it combines the manufacture of Lidar systems with self-executed Lidar surveys. The company considers this dual role an advantage as it provides a broad base of expertise. Although Optech, based in Toronto, Canada is a world leader in the development, manufacture and sale of Lidar systems, the company prefers here to present only its newest system, the Airborne Laser Terrain Mappers ALTM Gemini, able to generate 167,000 pulses per second. Precision and resolution statistics presented in these surveys are always a little tricky because the claims depend on system components taken into account. For example, does eleva - tion precision include GPS errors or is it quoted without? Statistics on minimum detectable size of objects should also be considered with care because this factor depends on flying height and target reflectivity . At a platform altitude of 200m power-lines just 8mm in diameter may be mapped; at flying height 1000m they need to be 3cm. The maximum possible number of points detected per square metre also depends on pulse rate and rotation/nutating speed of mirror on flying height, reflectivity and platform speed. The fields of application for Lidar are very diverse and include generation of digital elevation models, 3D-city modelling, forestry management, coastline protection, disaster man - agement, erosion studies, archaeology , monitoring of corridors such as power-lines, pipelines, railways and roads'), Document(metadata={'source': 'LiDAR-Sensors.pdf', 'page': 0, 'page_label': '24', 'start_index': -1}, page_content='. The fields of application for Lidar are very diverse and include generation of digital elevation models, 3D-city modelling, forestry management, coastline protection, disaster man - agement, erosion studies, archaeology , monitoring of corridors such as power-lines, pipelines, railways and roads. By Mathias Lemmens, editor-in-chief, GIM International Fugro FLI-MAP 400 Q1-2006 30kg, 50 x 30 x 30cm ~100kg 24V /30W 1,500nm 4ns 0.45 mrad (radial) Fiber / Class 1 M 0.3m Rotating mirror 150Hz 250,000Hz 60 deg 4 0.025 ps Threshold 11 bits 2x Trimble DB950 L1/L2, 10 Hz 5 / 10cm (2 sigma) Applanix PosAV 410, 200 Hz 0.008 / 0.008 / 0.015 deg GrafNav/PosProc 0.008 / 0.008 / 0.015 deg 2-3 cm Depending on network quality Depending on network quality 2-3 cm (2 sigma) 175 points (first return) altitude and speed- dependent 0.27m @ 150km/h 0.46m @ 400m AGL Forward and downward-looking 11Mpix still and video Removable hard disks, 80 GB Aircraft power 24V Helicopter/fixed wing 50 - 400m 3 - 6hrs -10 to 50 °C 99% non-condensing FLIP7 FLIP7 Corridor mapping, DTM/DSM [1] E.g. rotating mirror, oscillating mirror etc. [2] Also called scan frequency. [3] Also called sample interval per pulse. [4] Describe here which part of the reflected pulse is recorded. [5] Brand, number of channels, single or dual frequency, update frequency [Hz] . [6] Brand, update frequency [Hz]. [7] Number referred to flight altitude 1000m. [8] Number referred to a typical flying speed of 150 km/h, or other appropriate speed. [9] Types of camera standard to system. [10] Type of storage facilities (tape, disk, etc.), storage [GB], removable or not. Manufacturer Type/name of Lidar sensor Date of introduction/last update Dimensions - weight [kg] & size [cm] of laser system - weight [kg] & size [cm] of total system - power requirements Laser Pulse Characteristics - wavelength [mm] - pulse length [ns] - beam divergence (across/along tr.) [mrad] - type/class laser - eyesafe range [m] Recording Methodology - scanning method [1] - rotation speed of mirror [2] - pulse frequency (min-max) [Hz] - max. scan angle [deg] - max. # of recorded echoes/pulse - pulse sampling frequency [3] - pulse detection method [4] - dynamic range of intensity signal [bits] Positioning System - GPS system [5] - GPS precision planimetric/height (2 sigma) [cm] - INS system[6] - INS precision (roll/pitch/heading) [deg] - GPS/INS postprocessing software Precision and Resolution - Pointing precision (roll/pitch/heading) [deg] - Range precision (2 sigma) [cm] - Elevation precision at 1km (2 sigma) [cm] - Overall planimetric precision (2 sigma) [cm] - Range precision (2 sigma) [cm] - Max. # of points/m2 - Along-track point spacing [m] [7] - Across-track point spacing [m] [8] Other System Parts - Cameras [9] - Data Storage Facilities [10] - Power equipment Operation Characteristics - typical platform - flying heights (min/typical/max) [m] - max'), Document(metadata={'source': 'LiDAR-Sensors.pdf', 'page': 2, 'page_label': '26', 'start_index': 0}, page_content='Product survey February 2007 GIM International Riegl LMS LMS-Q240i-60/LMS-Q240i-80 Last update 09/2006 7kg; 18 x 37cm [Dia x L] N/A 43 W 0.9 um < 10ns 2.7 mrad Class 1 0m Rotating multi-facet mirror 6 - 80Hz/ 5 - 60Hz 30,000Hz 60 deg/ 80 deg First or last or alternating N/A Center of gravity of echo pulse 8 bits N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A N/A Helicopter 2m / 200m /350m N/A -10 to + 50 °C 80% (at or below 31°C) N/A N/A Corridor mapping, glacier mapping Small and lightweight sensor, suitable for helicopters, ultra-lights and UAVs. Riegl LMS LMS-S560-I/ LMS-S560-A Last update 10/2006 20kg; 56 x 20 x 22cm [LxWxH] Depending on system configuration 120 W (laser scanner) 1,500nm <4 ns 0.3 mrad with 1 mrad option Class 1 0m Rotating multi-facet mirror 10 - 160Hz 25,000 up to 200,000Hz 60 deg Practically unlimited 1GHz Full waveform processing of complete echo 16 bits Novatel/ Trimble: 12 channels, dual-frequency, up to 10Hz <10 /< 20cm rms / 5 - 30cm rms IGI AEROcontrol / Applanix POS AV 510. 256Hz / 200Hz 0.004 / 0.004 / 0.01 / 0.005 / 0.005 / 0.008 AEROoffice/ POSPac Limited by INS/GPS specification 2cm < 15cm, depending on DGPS accuracy < 10cm, depending on DGPS accuracy 2cm 9 points @ 500m AGL, 90km/h ground speed Min. 0.16m @ 10 scans/s Min. 0.26m @ 160 scans/s IGI DigiCAM / Applanix DSS Hard disk RIEGL DR560, 2 x 320 Gbytes Available Both, complete turnkey solution with Diamond Aircraft twin-engine plane DA42MPP available. 30m / 500m / 1,000m ~ 8 hrs 0 - 40 °C 80% (at or below 31°C) IGI WinMP / TrackAir RiANALYZE 560, RiPROCESS 560, RiWORLD 560 All typical airborne scanning projects. Recording of digitised echo signals & subsequent full-waveform analysis, complete turnkey solution with Diamond Aircraft DA42MPP . Riegl LMS LMS-Q560 Last update 10/2006 20kg; 56 x 20 x 22cm [LxWxH] N/A 120 W 1,500nm <4 ns 0.3 mrad with 1 mrad option Class 1 0m Rotating multi-facet mirror 10 - 160Hz 25,000 up to 200,000Hz 60 deg Practically unlimited 1GHz Full waveform processing of complete echo 16 bits See LMS-S560 system See LMS-S560 system See LMS-S560 system Hard disk RIEGL DR560, 2 x 320 Gbytes N/A Both 30m / 500m / 1000m ~ 8 hrs 0 - 40 °C 80% (at or below 31°C) IGI WinMP/ TrackAir RiANALYZE 560, RiPROCESS 560, RiWORLD 560 All typical airborne scanning projects. Recording of digitised echo signals and sub - sequent full-waveform analysis'), Document(metadata={'source': 'LiDAR-Sensors.pdf', 'page': 1, 'page_label': '25', 'start_index': 0}, page_content='GIM International February 2007 Product survey IGI LiteMapper 5600 2003/2006 20kg; 56 x 200 x 21.7cm 48kg; modular 300W 1550nm 3.5ns 0.5 mrad, with 1.2 mrad option Class 1 0m Rotating polygon mirror 5 - 160 scans/sec 40 - 200kHz 60 deg Unlimited 1GHz Full waveform 16 bits AEROcontrol, > 60 channels, L1/L2, 2Hz < 20cm AEROcontrol, 256Hz 0.004/0.004/0.01 deg AEROoffice 0.004/0.004/0.01 deg 2cm 0.06cm @ 1,000m, without GPS error 0.30cm @ 1,000m, without GPS error 156 points @ 50m AGL, 30 kts Variable, typ. 0.6m @ 150km/h Variable, typ. 0.6m @ 150km/h DigiCAM-H/22 Removable Data Recorder, 2x 320 GB Included Fixed-wing, helicopter 30m / - / 1,800m 10-30hrs - 0°C to +40°C Max. 80% at 31°C WinMP AEROoffice, GeocodeWF , T erraScan, T erraModeler Wide-area, urban, floodplain mapping, corridors, power-lines Full-waveform digitisation IGI LiteMapper 2400 2005/2006 7kg; 37,4 x 18 (length x diameter) 27kg; modular 140W 905nm - 2.7 mrad Class 1 0m Rotating polygon mirror 6 - 60 scans/s 30kHz 80 deg 1 - First or last pulse 8 bits AEROcontrol, > 60 channels, L1/L2, 2Hz < 20cm AEROcontrol, 256Hz 0.004/0.004/0.01 deg AEROoffice 0.007/0.007/0.01 deg 3cm 0.04cm @ 300m without GPS error 0.12 @ 300m without GPS error 8 points @ 50m AGL, 30 kts Variable, typ. 1m @ 300m, 40 kts Variable, typ. 1m @ 300 m, 40 kts DigiCAM-H/22 hard disk, 40GB Included Helicopter 10m / - / 650m 50hrs -10°C to +50°C Max. 80% at 31°C WinMP AEROoffice, Geocode, T erraScan, T erraModeler Corridors, power-lines Leica Geosystems ALS50-II February 2006 37W x 56L x 24H cm, 30kg scanner 45W x 47D x 36H (8U) cm, 40kg elec - tronics 28A average, 35A peak @ 28VDC 1,064nm <9ns 0.22 @ 1/e^2 (0.15 @ 1/e) CL IV 200m, single pulse exposure, aiding optics Oscillating mirror, sinusoidal scan pattern 90Hz max, full cycle 150,000Hz max 75 deg 4 (1st, 2nd, 3rd, last) N/A Leading edge CFD 8 bits plus 100:1 laser output control Leica IPAS10, 12 channel, dual-frequency, 20 Hz max < 10cm Leica IPAS10, 200Hz 0.005/0.005/0.008 deg GrafNav/IPAS Pro 0.005/0.005/ 0.008 deg with standard IPAS10 DUS5 GPS/IMU subsystem <10cm @ 1,000m AGL <14cm @ 1,000m AGL, including GPS error of 10cm @ 2 sigma <24cm @ 1,000m AGL, including GPS error of 10cm @ 2 sigma <10cm @ 1,000m AGL Depends on speed, flying height, FOV; 103 points @ 200m AGL, 81 knots (150km/h), 10 degree FOV; 14 points @ 1000m AGL, 81 knots (150 km/h),10 degree FOV Depends on speed, scan rate (not altitude); 0.23m @ nadir @ 81 knots (150km/h), 90Hz scan rate Depends on flying height, FOV, scan rate; 0.07m @ 200 m AGL, 81 knots (150km/h), 10 degree FOV, 90Hz scan rate; 0.38m @ 1000 m AGL, 81 knots (150km/h), 10 degree FOV, 72Hz scan rate Standard 1.3 MP integrated digital frame camera with real-time display and anno - tated recording of individual frames at user selected rate; optional RCD10a 39 MP digital frame camera'), Document(id='2faffa27-c3d7-4a3b-8daa-88152ea5fec1', metadata={'source': 'LiDAR-Sensors.pdf', 'page': 0, 'page_label': '24', 'start_index': 0}, page_content='Product survey February 2007 GIM International Airborne Lidar Sensors This is the second Product Survey on Airborne Lidar Sensors; the last appeared under the title ‘Airborne Laser-scanners’ in our May 2004 issue. Seven companies were willing to co-operate by filling in the questionnaire for the present survey. ‘Airborne Laser-scanners’ is a term used in Europe; other parts of the world have generally adopted the term ‘Air - borne Lidar’. Two companies represented in our previous survey , Mosaic Mapping Systems and Terrapoint are beyond the scope of the present survey , while we welcome two newcomers. The first is Ingenieur-Gesellschaft für Interfaces (IGI) based in Kreuztal, Germany , which produces and sells the airborne Lidar Terrain Mapping system (LiteMapper) 2400. IGI is an engineering company founded in 1978 by Albrecht Grimm and specialising in the design and development of guidance positioning, attitude determination and sensormanagement systems for airborne survey . The second newcomer is Fugro, a company that operates the FLI-MAP 400 system for Lidar survey . This company is positioned somewhat eccentrically in relation to other firms in that it does not put the FLI-MAP system itself on the for-sale shelf but performs only surveys. However, its system has been developed in-house and differs significantly from what other sensor operators are using in performing surveys based on Lidar systems offered by one or more manufacturers. We felt the uniqueness of the Fugro system qualified it for inclusion in this product survey . Another company standing apart from its counterparts in a similar respect is the German Toposys, which enjoys a unique position worldwide in that it combines the manufacture of Lidar systems with self-executed Lidar surveys. The company considers this dual role an advantage as it provides a broad base of expertise. Although Optech, based in Toronto, Canada is a world leader in the development, manufacture and sale of Lidar systems, the company prefers here to present only its newest system, the Airborne Laser Terrain Mappers ALTM Gemini, able to generate 167,000 pulses per second. Precision and resolution statistics presented in these surveys are always a little tricky because the claims depend on system components taken into account. For example, does eleva - tion precision include GPS errors or is it quoted without? Statistics on minimum detectable size of objects should also be considered with care because this factor depends on flying height and target reflectivity . At a platform altitude of 200m power-lines just 8mm in diameter may be mapped; at flying height 1000m they need to be 3cm. The maximum possible number of points detected per square metre also depends on pulse rate and rotation/nutating speed of mirror on flying height, reflectivity and platform speed. The fields of application for Lidar are very diverse and include generation of digital elevation models, 3D-city modelling, forestry management, coastline protection, disaster man - agement, erosion studies, archaeology , monitoring of corridors such as power-lines, pipelines, railways and roads'), Document(metadata={'source': 'LiDAR-Sensors.pdf', 'page': 1, 'page_label': '25', 'start_index': 2846}, page_content='. Removable HDD Ground power supply Fixed-wing or helicopter 200 - 6,000m AGL ~17 hrs @ max pulse rate 0 - 40 °C cabin-side temperature Non-condensing Leica FPES Leica ALS Post Processor for point-cloud generation,T erraScan/T erraModeler for viewing/editing. DEMs, city models, flood plain, erosion & forestery studies, forest floor, disaster management, power-lines, pipe-line and railway and roadway corridors, coastal mapping. Full-function system for a wide variety of applications now features highly integrated FCMS flight-management system and flex - ible external sensor integration. Optech ALTM Gemini October 2006 23.4kg, 26 x 19 x 57cm 95kg, control rack size 65 x 59 x 49cm 28 VDC, 35 A (maximum) 1,060nm 7ns 0.8, 0.25, 0.15 1/e Class IV (FDA 21 CFR) 80 m + Oscillating Mirror 100Hz 167kHz 50 deg 4 ranges Leading edge 12 bits Trimble, 12 channel, dual-frequency 0.05cm POS 610, 200 Hz 0.0025/0.0025/0.005 deg POS PAC 0.0025/0.0025/0.005 deg 3cm < 10cm 1/11000 20 points - 100 Knots, 500m, 100Hz scan, +/- 10°, PRF = 167kHz. As above 0.25m As above 0.21m Applanix DSS, Rollei 39 Mpixel Removable hard disk, min 70 Gbytes Internal to the system T win engine fixed-wing, rotary wing 200m / 1km to 2km / 4km max; higher avail - able on request Unlimited -10°C to 35°C 0 to 95% non-condensing ALTM NAV DASHMap Power-line mapping, topographic survey, urban mapping, flood mapping, etc. Multipulse airborne Lidar system with the highest PRF rate of 167kHz in the industry; global 24/7 technical support.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers import EnsembleRetriever, BM25Retriever, MultiQueryRetriever\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Step 1: Store Embeddings in FAISS (Faster Retrieval)\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "faiss_store = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "# Step 2: Set Up Retrieval Methods\n",
    "vector_retriever = faiss_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k = 3  # Match vector retriever\n",
    "\n",
    "# Dynamic Weights for Different Queries\n",
    "query_type = \"entity\"  # or \"relation\"\n",
    "weights = [0.8, 0.2] if query_type == \"entity\" else [0.6, 0.4]\n",
    "\n",
    "# Ensemble Retriever\n",
    "retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=weights\n",
    ")\n",
    "llm = ChatOllama(model=MODEL) \n",
    "# Multi-Query Expansion (Better Recall)\n",
    "mq_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)\n",
    "\n",
    "# Retrieve Once, Then Filter\n",
    "combined_query = \"\"\"\n",
    "EXTRACT: LiDAR sensors, their components, technical specifications.\n",
    "FIND: has_part, implements, measurement_properties relationships.\n",
    "IGNORE: Experimental results, methodology, figures.\n",
    "FILTER: Only technical specifications sections.\n",
    "\"\"\"\n",
    "retrieved_docs = mq_retriever.get_relevant_documents(combined_query)\n",
    "print(retrieved_docs)\n",
    "# Post-Retrieval Filtering\n",
    "# filtered_docs = {doc.page_content for doc in retrieved_docs if \"LiDAR\" in doc or \"sensor\" in doc}  \n",
    "# retrieved_text = \"\\n\\n\".join(filtered_docs)\n",
    "retrieved_text = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\AppData\\Local\\Temp\\ipykernel_11956\\2807396875.py:2: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=MODEL)\n"
     ]
    }
   ],
   "source": [
    "# Initialize with your local model\n",
    "compressor = LLMChainExtractor.from_llm(llm=llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever,\n",
    "    search_kwargs={\"k\": 10}  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KG_EXTRACTION_PROMPT = \"\"\"As a LiDAR sensor expert, analyze this technical text to extract:\n",
    "\n",
    "# **Target Entities**:\n",
    "# 1. Sensor Models: Manufacturer-branded names (Velodyne HDL-64E, Livox Horizon)\n",
    "# 2. Components: Physical/software parts (e.g., MEMS mirror, FPGA processor)\n",
    "# 3. Technical Specs: Quantified values with units (120m range, 0.08° resolution)\n",
    "# 4. Implementations: Standards/protocols (IEEE 802.11p, ROS2)\n",
    "\n",
    "# **Extraction Rules**:\n",
    "# - Preserve contextual relationships: \n",
    "#   \"The Velodyne VLP-32C's rotating assembly enables 360° coverage\" → \n",
    "#   {{\"parts\": [\"rotating assembly\"], \"properties\": [\"field of view: 360°\"]}}\n",
    "# - Capture implied properties from comparisons:\n",
    "#   \"Outperforms Ouster OS2 in range\" → \n",
    "#   {{\"properties\": [\"comparative_range: > Ouster OS2\"]}}\n",
    "# - Retain partial information with \"[INFERRED]\" tags\n",
    "\n",
    "# **Enhanced Format**:\n",
    "# ```json\n",
    "# {{\n",
    "#   \"sensors\": [\n",
    "#     {{\n",
    "#       \"name\": \"Livox Horizon\",\n",
    "#       \"category\": \"Automotive Lidar\",\n",
    "#       \"parts\": [\"MEMS mirror\", \"905nm laser array\"],\n",
    "#       \"properties\": [\n",
    "#         \"horizontal_fov: 81.7°\", \n",
    "#         \"range: 260m @ 10% reflectivity\",\n",
    "#         \"scan_pattern: non-repetitive\"\n",
    "#       ],\n",
    "#       \"implements\": [\"ROS2\", \"AutoSAR\"]\n",
    "#     }}\n",
    "#   ]\n",
    "# }}\n",
    "# ```\n",
    "# <text>\n",
    "# {text}\n",
    "# <text>\n",
    "# \"\"\"\n",
    "KG_EXTRACTION_PROMPT=\"\"\"As a LiDAR sensor expert, analyze this technical text to extract:\n",
    "\n",
    "**Target Entities**:\n",
    "1. Sensor Models: Manufacturer-branded names (Velodyne HDL-64E, Livox Horizon)\n",
    "2. Components: Physical/software parts (e.g., MEMS mirror, FPGA processor)\n",
    "3. Technical Specs: Quantified values with units (120m range, 0.08° resolution)\n",
    "4. Implementations: Standards/protocols (IEEE 802.11p, ROS2)\n",
    "5. Category: Automotive LiDAR, Industrial LiDAR, etc.\n",
    "\n",
    "**Extraction Rules**:\n",
    "- Preserve contextual relationships: \n",
    "  \"The Velodyne VLP-32C rotating assembly enables 360° coverage\" → \n",
    "  {{\"parts\": [\"rotating assembly\"], \"properties\": [\"field of view: 360°\"]}}\n",
    "- Capture implied properties from comparisons:\n",
    "  \"Outperforms Ouster OS2 in range\" → \n",
    "  {{\"properties\": [\"comparative_range: > Ouster OS2\"]}}\n",
    "- Retain partial information with \"[INFERRED]\" tags\n",
    "\n",
    "<example>\n",
    "Input: \"The Velodyne VLP-32C has a 200m range and 0.2° resolution\"\n",
    "Output:\n",
    "{{\n",
    "  \"sensors\": [\n",
    "    {{\n",
    "      \"name\": \"Velodyne VLP-32C\",\n",
    "      \"category\": \"Automotive LiDAR\",\n",
    "      \"parts\": [],\n",
    "      \"properties\": [\"range: 200m\", \"resolution: 0.2°\"],\n",
    "      \"implements\": []\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "</example>\n",
    "\n",
    "**Format**:\n",
    "```json\n",
    "{{\n",
    "  \"sensors\": [\n",
    "    {{\n",
    "      \"name\": \"\",\n",
    "      \"category\": \"\",\n",
    "      \"parts\": [],\n",
    "      \"properties\": [],\n",
    "      \"implements\": []\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "**Critical Instructions**:\n",
    "1. If no sensors are found, return: {{\"sensors\": []}}\n",
    "2. Always maintain valid JSON structure\n",
    "3. Never add extra text outside the JSON\n",
    "4. Use exact values from tables when available\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<text>\n",
    "{text}\n",
    "<text>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormat(Enum):\n",
    "    JSON = \"json_object\"\n",
    "    TEXT = \"text\"\n",
    " \n",
    " \n",
    "def call_model(\n",
    "    prompt: str, response_format: ResponseFormat = ResponseFormat.TEXT\n",
    ") -> str:\n",
    "    response = ollama.generate(\n",
    "        model=MODEL,\n",
    "        prompt=prompt,\n",
    "        keep_alive=\"1h\",\n",
    "        format=\"\" if response_format == ResponseFormat.TEXT else \"json\",\n",
    "    )\n",
    "    return response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks = [retrieved_text[i:i + CHUNK_SIZE] for i in range(0, len(retrieved_text), CHUNK_SIZE)];\n",
    "chunks = text_splitter.split_text(retrieved_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the final prompt with the concatenated text\n",
    "\n",
    "responses = []\n",
    "\n",
    "for chunk in chunks:\n",
    "        final_prompt = KG_EXTRACTION_PROMPT.format(text=chunk)\n",
    "        # Send the final prompt to Ollama\n",
    "        # print (final_prompt)\n",
    "        response = call_model(final_prompt)\n",
    "        responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responses: ['<think>\\nAlright, so I\\'m trying to help this user who\\'s an expert in LiDAR sensors. They want me to analyze a piece of technical text and extract specific entities like sensor models, components, specs, implementations, and categories. \\n\\nFirst, I need to understand the structure they\\'re asking for. The output needs to be in JSON format with sensors as an array, each containing name, category, parts, properties, and implements. If there are no sensors found, I just return an empty array.\\n\\nLooking at the text provided, it seems to be a list of various specifications about LiDAR sensors. There\\'s a lot of technical jargon here, like \"Recording Methodology,\" \"Positioning System,\" \"Precision and Resolution,\" etc. But I don\\'t see any specific sensor models mentioned. The user did mention looking for manufacturer-branded names like Velodyne or Livox, but those aren\\'t present here.\\n\\nNext, the extraction rules say to preserve contextual relationships and capture implied properties from comparisons. However, without actual sensor models, it\\'s hard to apply these rules. For example, if a sentence said \"The sensor outperforms the Ouster OS2 in range,\" I could infer a comparative range property. But since no such information is present, I can\\'t extract anything related.\\n\\nI also need to check for components like MEMS mirrors or FPGA processors, but again, there\\'s no mention of these parts in the text provided. The technical specs they want are quantified values with units, like 120m range or 0.08° resolution. However, without specific models, I can\\'t extract those numbers.\\n\\nLooking at the \"Category\" part, the user wants automotive, industrial, etc., but since no sensor types are mentioned, this is also not applicable here.\\n\\nSo, considering all these points, it seems like there\\'s no data available in the provided text to extract any of the target entities. Therefore, according to the critical instructions, I should just return an empty JSON array with no sensors found.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": []\\n}\\n```', '<think>\\nOkay, so the user has provided a text snippet that\\'s part of a product survey from February 2007. It\\'s about various LiDAR sensors made by Riegl. The task is to extract specific entities as per the given instructions. Let me break this down.\\n\\nFirst, I need to identify the sensor models. The text mentions \"Riegl LMS Q240i-60/LMS-Q240i-80\" and later \"LMS-S560-I/ LMS-S560-A\". These seem to be the manufacturer-branded names, so they fall under the Sensor Models category.\\n\\nNext, looking for components or parts. It mentions a \"rotating multi-facet mirror\", which is definitely a physical part of the sensor. There\\'s also mention of \"full waveform processing\" and \"16 bits\" which might refer to software components like the processing units. I\\'ll note these down under Components.\\n\\nNow, technical specs. The text provides several quantitative values. For example, it talks about range: \"2m / 200m /350m\". There\\'s also \"0.3 mrad with 1 mrad option\" which is angular resolution. Additionally, there are specs like \"120 W\", \"16 bits\", and \"practically unlimited\" which likely refer to power consumption, bit depth, and data rates respectively. I\\'ll extract these as properties with their respective units.\\n\\nImplementations or protocols aren\\'t directly mentioned here. The text is more about the sensors\\' features rather than how they integrate into systems. So, this category might remain empty in the JSON output.\\n\\nRegarding categories, it\\'s mentioned that these sensors are for \"helicopters, ultra-lights and UAVs\", which suggests they fall under \"Aerocontrol\" or perhaps \"Industrial LiDAR\". I\\'ll go with \"Aerocontrol\" as a safer bet based on the context provided.\\n\\nI also need to be careful about capturing implied properties. For instance, when it mentions outperforming other systems, but since there\\'s no direct comparison here, I might have to infer that later if needed. But in this text, it\\'s more about specifications than comparisons.\\n\\nThe example provided helps: each sensor is an object with name, category, parts, properties, and implements. Since the user didn\\'t specify any implements here, they\\'ll be empty.\\n\\nI should also make sure to structure everything properly, using exact values from the tables where possible. The JSON format needs to be valid, so no missing commas or brackets.\\n\\nFinally, I need to ensure that all entities are correctly tagged with their relationships preserved, even if some info is inferred. For example, \"16 bits\" and \"full waveform processing\" are both noted under properties.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Riegl LMS Q240i-60/LMS-Q240i-80\",\\n      \"category\": \"Aerocontrol\",\\n      \"parts\": [\"rotating multi-facet mirror\"],\\n      \"properties\": [\\n        \"range: 2m / 200m / 350m\",\\n        \"angular resolution: 0.3 mrad with 1 mrad option\",\\n        \"power consumption: 43 W\",\\n        \"bit depth: 16 bits\",\\n        \"data rate: practically unlimited\"\\n      ],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Riegl LMS-S560-I/LMS-S560-A\",\\n      \"category\": \"Aerocontrol\",\\n      \"parts\": [\"rotating multi-facet mirror\", \"full waveform processing\"],\\n      \"properties\": [\\n        \"power consumption: 120 W\",\\n        \"bit depth: 16 bits\",\\n        \"angular resolution: 0.3 mrad with 1 mrad option\",\\n        \"data rate: practically unlimited\"\\n      ],\\n      \"implements\": []\\n    }\\n  ]\\n}\\n```', '<think>\\nAlright, let\\'s tackle this problem step by step. The user has provided a technical text and wants me to extract specific entities using the given instructions. \\n\\nFirst, I need to understand what exactly they\\'re asking for. They want entities categorized into sensor models, components, technical specs, implementations, and categories. The extraction rules are quite detailed, so I must ensure I follow them accurately.\\n\\nLooking at the example provided, it seems that each sensor model is treated as a separate entry within the \"sensors\" array. Each entry includes name, category, parts (which are physical/components), properties (with their values and units), and any implementations like standards or protocols used.\\n\\nNow, looking at the input text: It\\'s quite dense with technical terms. I need to identify sensor models first. The text mentions \"Turnkey solution\" which might not be a model name but more of a service offering. Then there\\'s \"TopoSys GmbH Harrier 24 October 2005,\" which seems like a company and date, so probably not a sensor model.\\n\\nNext, scanning for components: the text talks about a rotating multi-facet mirror with specific frequencies (6-80Hz and 5-60Hz). It also mentions parts like the Applanix POSAV 310, which is likely another component. So, these would go under the \"parts\" array.\\n\\nTechnical specs are more about quantified values. The text provides things like 900nm < 10ns, which I think refers to wavelength and pulse duration. There\\'s also mention of a rotating mirror with angles (60 deg/80 deg), so that\\'s another spec. The frame cameras have specs like resolution and frame rate.\\n\\nFor implementations, the text mentions protocols or standards like \"TrackAir TopPIT,\" which is used for low-altitude corridor mapping and surveying. That might fall under implementations.\\n\\nThe category is mentioned as \"Entry level system\" and also refers to applications like construction, engineering, snow, ice, and glacier mapping. So, the category should be something like \"Surveying LiDAR.\"\\n\\nNow, considering the extraction rules: I need to preserve contextual relationships, capture implied properties from comparisons, and retain partial info with inferred tags where necessary.\\n\\nIn the example provided by the user, they show how each sensor model is a separate entry in the array. So, perhaps I should list each component as its own sensor if applicable, but since this text seems more about a system rather than individual sensors, maybe I should treat it differently. Alternatively, maybe it\\'s better to structure each major component as a separate sensor within the sensors array.\\n\\nWait, looking back at the example, the output had one sensor entry with parts and properties. But in our case, perhaps we need multiple entries if there are multiple systems or components. Hmm, but the text seems to describe a single system with various parts and specs.\\n\\nI think I\\'ll structure it as a single entry in the sensors array, listing all relevant parts, their properties, and any implementations. That way, it captures the comprehensive setup described.\\n\\nSo, compiling all this: The sensor model might be \"TopoSys GmbH Harrier\" if that\\'s a specific model, but I\\'m not entirely sure. Alternatively, it could be categorized under Surveying LiDAR as an entry-level system. The components include the rotating mirror and Applanix POSAV 310. Properties would cover range, resolution, frame rate, etc., and implementations would include protocols used like TopPIT.\\n\\nI should also make sure to follow the JSON format exactly as per their instructions, ensuring no extra text is added outside the JSON structure and that all entities are correctly nested under their respective keys.\\n\\nWait, the user\\'s example shows \"sensors\" as an array of objects, each representing a sensor. So, in this case, even though the text describes multiple components, perhaps it\\'s better to list each significant part as a separate sensor or group them under one. Given that, I think it\\'s more accurate to treat the entire system described as one sensor entry with all its parts and specs.\\n\\nSo, putting it all together, I\\'ll create a single sensor object within the \"sensors\" array, listing the category, any parts, their properties, and the implementation protocols.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": [\\n    {\\n      \"name\": \"TopoSys GmbH Harrier\",\\n      \"category\": \"Surveying LiDAR\",\\n      \"parts\": [\"rotating multi-facet mirror\", \"Applanix POSAV 310\"],\\n      \"properties\": [\\n        \"rotation speed: 6 - 80Hz, 5 - 60Hz\",\\n        \"mirror angle: 60°/80°\",\\n        \"frame rate: 3/280/430 (80°), 3/250/380\",\\n        \"range: N/A\",\\n        \"resolution: 0.015/0.015/0.035°\",\\n        \"power requirements: 28 V DC, 13 A max\"\\n      ],\\n      \"implements\": [\"TrackAir TopPIT\"]\\n    }\\n  ]\\n}\\n```', '<think>\\nAlright, so I\\'m looking at this text that someone provided, and I need to extract specific entities from it. The user is acting as a LiDAR sensor expert, so they want me to analyze the given technical text and pull out certain parts based on their instructions.\\n\\nFirst, let\\'s break down what they\\'re asking for. They have five target categories: Sensor Models, Components, Technical Specs, Implementations, and Category. Each of these has specific rules for extraction, including preserving contextual relationships, capturing implied properties from comparisons, and retaining partial information with [INFERRED] tags. If no sensors are found, I should return an empty list.\\n\\nLooking at the example provided, it shows how to parse a simple sentence into JSON format with each sensor\\'s details. So, my goal is to apply similar logic to the given text.\\n\\nThe text itself is quite dense and technical, filled with various product specifications, models, and applications. My first step is to scan through this text to identify any sensor models mentioned. The example response lists \"Velodyne VLP-32C\" as a sensor model, so I should look for similar manufacturer-branded names.\\n\\nNext, I need to extract components like parts of the LiDAR system, such as MEMS mirrors or FPGA processors. Technical specs include quantified values with units, like range and resolution. Implementations would involve standards or protocols used, like ROS2. Finally, categorizing each sensor into types like Automotive LiDAR or Industrial LiDAR.\\n\\nNow, looking at the text, I notice mentions of \"TopEye\" in several contexts, such as \"TopEye Mk II,\" \"TopEye PP,\" and \"TopoSys GmbH Falcon III.\" These seem to be sensor models. Additionally, there\\'s mention of \"Palmer scanner,\" which might be a component or part of the system.\\n\\nFor technical specs, I see values like \"1,064nm 4 ns\" which refers to wavelength and pulse duration. There are also mentions of range in meters and degrees, such as \"40m at low effect\" and \"0-75Hz.\" These will fall under properties.\\n\\nComponents include terms like \"rotating assembly,\" \"multi-facet mirror,\" and \"FPGA processing.\" However, the text doesn\\'t explicitly state these, so I might need to infer them based on context. For example, when it says \"Rotating multi-facet mirror,\" that\\'s a clear component.\\n\\nRegarding implementations, the text mentions standards like \"IEEE 802.11p\" and protocols such as \"full waveform logic\" and \"16 bits.\" These will be added under the implements section.\\n\\nThe categories are more straightforward; the text refers to applications in areas like city models, corridors, power lines, etc., but it doesn\\'t explicitly state if these sensors are for automotive or industrial use. Therefore, I\\'ll need to infer the category based on the context of high-end systems and turnkey solutions, which lean towards industrial applications.\\n\\nThere\\'s also a mention of \"TrackAir\" and \"T opPIT,\" which might be parts of the system but aren\\'t explicitly clear. These could be inferred components or part of the implementation.\\n\\nOne tricky part is handling implied properties from comparisons. The text doesn\\'t directly compare sensors against each other, so this might not apply here. However, mentions like \"high survey speed possible > 400km/h\" give a comparative advantage, but without explicit comparisons to others, it\\'s hard to use that information beyond noting the performance.\\n\\nI also need to ensure that all extracted data is in JSON format as per the example. Each sensor model will have its own object within the array. For each sensor, I\\'ll list the components used, their technical specifications, any relevant implementations, and categorize them appropriately.\\n\\nSince the text doesn\\'t explicitly mention some components or protocols, some of this information might need to be inferred with [INFERRED] tags. However, based on the example response, it seems that only explicit mentions are included without the tag unless specified otherwise.\\n\\nIn summary, I\\'ll extract the sensor models, note their components and specs, include any relevant implementations, and categorize them as industrial LiDAR systems based on the context provided.\\n</think>\\n\\n```json\\n[\\n  {\\n    \"Sensor Model\": \"TopEye Mk II\",\\n    \"Components\": [\"Rotating multi-facet mirror\"],\\n    \"Technical Specs\": {\\n      \"Wavelength\": \"1,064nm\",\\n      \"Pulse Duration\": \"4ns\",\\n      \"Range\": \"40m at low effect\",\\n      \"Frequency\": \"0-75Hz\"\\n    },\\n    \"Implementations\": [\"Full waveform processing\", \"16 bits\"],\\n    \"Category\": \"Industrial LiDAR\"\\n  },\\n  {\\n    \"Sensor Model\": \"TopoSys GmbH Falcon III\",\\n    \"Components\": [\"Rotating multi-facet mirror\", \"Multi-facet mirror (up to 1mrad option)\"],\\n    \"Technical Specs\": {\\n      \"Wavelength\": \"1,550nm\",\\n      \"Pulse Duration\": \"<4ns\",\\n      \"Range\": \"30m /800m /1,000m\"\\n    },\\n    \"Implementations\": [\"Full waveform processing\", \"16 bits\"],\\n    \"Category\": \"Industrial LiDAR\"\\n  }\\n]\\n```', '<think>\\nAlright, I\\'m trying to analyze this technical text about LiDAR sensors. The user wants me to extract specific entities like sensor models, components, technical specs, implementations, and categories. Let me break it down step by step.\\n\\nFirst, I need to identify the sensor models mentioned. I see names like Velodyne VLP-32C, Optech ALTM Gemini, Applanix DSS, and Turnkey solutions from TopoSys GmbH Harrier. Wait, but the user only wants manufacturer-branded names, so maybe the Harrier is part of the system rather than a sensor model. Hmm, I might need to check that.\\n\\nNext, components. The text mentions parts like rotating multi-facet mirror, oscillating mirror, POS systems, frame cameras, etc. These are physical or software parts related to the LiDAR systems.\\n\\nFor technical specs, I\\'m looking for quantified values with units. I notice things like 200m range, 167kHz PRF, 0.0025/0.0025/0.005 deg POS accuracy, and others. I\\'ll need to extract these with their respective units.\\n\\nImplementations involve standards or protocols used. The text mentions ROS2 for point-cloud generation and integration with flight management systems like FCMS. These are likely the implementations.\\n\\nCategories include types of LiDAR, such as airborne, fixed-wing, rotary wing, etc., and applications like topographic survey, urban mapping, flood mapping. I need to categorize each sensor based on these aspects.\\n\\nI should also apply the extraction rules: preserve contextual relationships, capture implied properties from comparisons, and use inferred tags when partial info is available. For example, \"Outperforms Ouster OS2 in range\" would become a comparative_range property against the OS2.\\n\\nLooking at the example provided, it structures the output into sensors with name, category, parts, properties, and implementations. I need to ensure each extracted sensor has these fields correctly populated.\\n\\nI\\'m concerned about not missing any sensors. Scanning through the text again, there are mentions of Leica FPES, ALS Post Processor, TerraScan/TerraModeler, DEMs, etc., but those seem more like software or data processing components rather than sensors. So I\\'ll stick to the sensor models listed earlier.\\n\\nI also need to be careful with units and properties. For instance, \"0.8, 0.25, 0.15 1/e\" probably refers to pulse periods or distances, so I should parse them correctly into their respective units.\\n\\nIn terms of formatting, I must ensure the JSON is valid, no extra text outside it, and correct structure with empty arrays if needed. Also, use exact values from tables when possible, but in this case, most are inferred from context.\\n\\nFinally, I\\'ll review everything to make sure all entities are captured accurately without adding any extra information beyond what\\'s provided.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Optech ALTM Gemini\",\\n      \"category\": \"Airborne LiDAR\",\\n      \"parts\": [\"rotating multi-facet mirror\", \"oscillating mirror\", \"POS\"],\\n      \"properties\": [\\n        \"range: 200m\",\\n        \"PRF: 167kHz\",\\n        \"accuracy: 0.0025/0.0025/0.005 deg\",\\n        \"control rack size: 65 x 59 x 49cm\"\\n      ],\\n      \"implements\": [\"ROS2\", \"FCMS\"]\\n    },\\n    {\\n      \"name\": \"Applanix DSS\",\\n      \"category\": \"Airborne LiDAR\",\\n      \"parts\": [\"POS\"],\\n      \"properties\": [\\n        \"accuracy: 0.015/0.015/0.035 deg\"\\n      ],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Turnkey solution (TopoSys GmbH Harrier)\",\\n      \"category\": \"Entry level LiDAR\",\\n      \"parts\": [\"frame cameras\"],\\n      \"properties\": [\\n        \"range: 150m\",\\n        \"accuracy: 0.5 (@150m, 150km/h), 0.7 (@150m, 150km/h)\"\\n      ],\\n      \"implements\": []\\n    }\\n  ]\\n}\\n```', '<think>\\nAlright, so I\\'ve been given a task to analyze some technical text about LiDAR sensors. The user wants me to extract specific entities from the text following certain rules. Let\\'s break down what I need to do.\\n\\nFirst, I need to understand the structure of the output JSON they\\'re expecting. It should have an array of sensor objects, each with name, category, parts, properties, and implements. If there are no sensors found, I just return an empty array.\\n\\nLooking at the extraction rules, I see that I need to extract sensor models, components, technical specs, implementations, and categories. The text provided is from a product survey, so it\\'s likely mentioning various LiDAR systems and their specifications.\\n\\nI\\'ll start by scanning through the text for manufacturer-branded names like \"Velodyne\" or \"Livox.\" From the example given, I know these are sensor models, so I should note those down under sensors. Wait, in the provided text, I don\\'t see any of those names mentioned. Hmm, maybe the sensors are from different companies.\\n\\nNext, components. The rules mention parts like MEMS mirrors or FPGA processors. In the text, words like \"LidAR Terrain Mapping system,\" \"FLI-MAP 400,\" and \"ALTM Gemini\" might refer to sensor models, but I should look for specific components mentioned alongside them. However, the text doesn\\'t explicitly list components; it talks more about systems and their applications.\\n\\nTechnical specs involve quantified values with units like range (e.g., 120m) or resolution (0.08°). The text does mention things like \"167,000 pulses per second\" for the ALTM Gemini system. It also discusses how factors like platform altitude affect detection size, which ties into range and resolution indirectly. I should extract these as properties.\\n\\nImplementations refer to standards or protocols used, such as ROS2 or IEEE 802.11p. The text doesn\\'t mention any specific implementations, so this might be an empty list for each sensor.\\n\\nCategories are about whether the LiDAR is for Automotive, Industrial, etc. The text mentions applications like digital elevation models, city modeling, forestry management, etc., which suggest these are airborne sensors used in various industrial sectors.\\n\\nI need to ensure I capture implied properties and relationships. For example, if a system outperforms another in range or resolution, I note that as comparative specs. But the text doesn\\'t explicitly compare systems against others beyond mentioning their unique features.\\n\\nIn the example given, they have sensors without any parts listed because none were explicitly mentioned. So maybe that\\'s acceptable if components aren\\'t specified.\\n\\nPutting it all together, each sensor object will include the model name (if found), category based on application, properties from specs, and any implied comparative data if I can infer it.\\n\\nWait, the text does mention Fugro using FLI-MAP 400 in-house and unique applications. Optech\\'s ALTM Gemini is highlighted with pulse rate specs. Toposys combines manufacturing and surveys, which might fall under a specific category but isn\\'t explicitly stated.\\n\\nSo, my final JSON will list each sensor model (like FLI-MAP 400, ALTM Gemini), their categories as Industrial/Airborne Lidar, their properties based on the specs provided, and any implied comparative data if inferred from context. But in this text, there aren\\'t explicit comparisons mentioned between different sensors.\\n\\nTherefore, I\\'ll structure the JSON with each sensor having its name, category, properties like pulse rate or platform altitude effects, and leave implements empty since no protocols are mentioned.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": [\\n    {\\n      \"name\": \"FLI-MAP 400\",\\n      \"category\": \"Airborne Lidar\",\\n      \"parts\": [],\\n      \"properties\": [\"pulse_rate: 167,000 pulses per second\"],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"LidAR Terrain Mapping system (LiteMapper) 2400\",\\n      \"category\": \"Airborne Lidar\",\\n      \"parts\": [],\\n      \"properties\": [],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"ALTM Gemini\",\\n      \"category\": \"Airborne Lidar\",\\n      \"parts\": [],\\n      \"properties\": [\"pulse_rate: 167,000 pulses per second\"],\\n      \"implements\": []\\n    }\\n  ]\\n}\\n```', '<think>\\nAlright, so I need to analyze this technical text and extract specific entities as per the given instructions. Let me go through it step by step.\\n\\nFirst, looking at the text provided, it\\'s a detailed description of a LiDAR sensor system. It mentions various components like the rotating mirror, pulse characteristics, positioning systems, etc. There are also specifications about ranges, resolutions, and other technical aspects.\\n\\nStarting with **Target Entities**:\\n\\n1. **Sensor Models**: I need to find manufacturer-branded names. Scanning through the text, I see \"Fugro FLI-MAP 400 Q1-2006\" mentioned, but that seems more like a model name or version. There\\'s also a mention of \"Applanix PosAV 410\" and \"Trimble DB950 L1/L2\". These could be sub-components rather than the main sensor models. So maybe there aren\\'t specific sensor models listed here.\\n\\n2. **Components**: Physical or software parts. The text mentions components like \"rotating mirror\", \"oscillating mirror\", \"pulse frequency (min-max)\", and others. It also talks about different types of mirrors, pulse characteristics, and data storage methods. I\\'ll need to list these as components with their inferred properties.\\n\\n3. **Technical Specs**: Quantified values with units. The text provides specs like range, resolution, pulse length, beam divergence, etc. For example, \"1,500nm\" is the wavelength, \"4ns\" is pulse length, and \"0.45 mrad (radial)\" is beam divergence. There\\'s also mention of 24V power, 30W consumption, and different accuracies like \"5 / 10cm (2 sigma)\". I should extract these with their units.\\n\\n4. **Implementations**: Standards or protocols. The text doesn\\'t explicitly mention any standards like IEEE 802.11p or ROS2, so this might be empty here.\\n\\n5. **Category**: The category isn\\'t directly specified beyond \"LiDAR\", but the context suggests it\\'s a fixed-wing or helicopter system, possibly for corridor mapping and such.\\n\\nMoving to **Extraction Rules**:\\n\\n- **Contextual Relationships**: Look for phrases where parts are described with their properties. For example, \"rotating mirror\" implies field of view or rotation speed. The text mentions \"150Hz 250,000Hz\", which is the pulse frequency and total scan rate.\\n\\n- **Implied Properties from Comparisons**: There\\'s no direct comparison mentioned in this text, so I might not have any comparative data here.\\n\\n- **Inferred Tags**: Since some components are labeled with [INFERRED], like rotating mirror or oscillating mirror, I should note that these are inferred from context rather than explicitly stated.\\n\\nPutting it all together, the JSON structure needs to include each sensor\\'s name, category, parts, properties, and any implementations. However, since specific sensor models aren\\'t clearly listed, I might have to infer them as part of the components.\\n\\nWait, looking again, there is a mention of \"FLIP7\" which might be a subsystem, like data storage or something else. Also, \"Trimble DB950 L1/L2\" and \"Applanix PosAV 410\" are mentioned as parts, so those should be included in the components list.\\n\\nI think I\\'ve covered all the components, specs, and inferred relationships. Now, structuring this into the JSON format as specified.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": [\\n    {\\n      \"name\": \"\",\\n      \"category\": \"LiDAR\",\\n      \"parts\": [\\n        \"rotating mirror\",\\n        \"oscillating mirror\",\\n        \"pulse frequency\",\\n        \"data storage facilities\",\\n        \"power equipment\",\\n        \"trimble db950 l1/l2\",\\n        \"applanix posav 410\"\\n      ],\\n      \"properties\": [\\n        {\\n          \"Component\": \"Rotating Mirror\",\\n          \"Property\": \"Scan Angle (max.) [deg]\",\\n          \"Value\": \"150Hz\"\\n        },\\n        {\\n          \"Component\": \"Pulse Frequency\",\\n          \"Property\": \"Range (min-max) [Hz]\",\\n          \"Value\": \"250,000Hz\"\\n        },\\n        {\\n          \"Component\": \"Data Storage Facilities\",\\n          \"Property\": \"Type\",\\n          \"Value\": \"[10]\"\\n        }\\n      ]\\n    }\\n  ]\\n}\\n```', '<think>\\nAlright, so I\\'ve got this technical text here, and my task is to extract specific entities using the given rules. Let me start by understanding what exactly needs to be done.\\n\\nFirst, the user has provided a detailed query with clear instructions on what to extract from the text. The target entities include sensor models, components, technical specs, implementations, and categories. Each of these has specific rules for extraction, so I need to make sure I follow them carefully.\\n\\nLooking at the example they provided helps clarify things. In that example, they took a sentence about the Velodyne VLP-32C sensor and extracted its name, category, parts, properties, and any implementations. The output was a JSON structure with these details neatly organized.\\n\\nNow, applying this to the given text. The text seems to be a product survey from 2007, mentioning various LiDAR sensors like Riegl LMS Q240i-60/LMS-Q240i-80, LMS-S560-I, and so on. My goal is to identify each sensor model, their components, specs, any protocols or standards they use, and their category.\\n\\nI need to go through the text sentence by sentence, looking for keywords related to sensors and their specifications. For example, mentions of \"rotating multi-facet mirror\" might indicate a component part. Technical specs like \"120m range\" or \"0.3 mrad\" should be noted under properties.\\n\\nOne thing I notice is that the text sometimes provides comparative information, but in this case, it doesn\\'t mention any direct comparisons to other sensors. So, I might not need to infer any comparative properties unless something stands out.\\n\\nI also need to ensure that each sensor model has its own entry in the JSON output. The example had one sensor, so I assume multiple sensors would each have their own object within the \"sensors\" array.\\n\\nAnother important point is maintaining valid JSON structure. That means proper commas, brackets, and ensuring all keys are correctly spelled as per the example—like \"name\", \"category\", etc.\\n\\nI should also pay attention to any specifications that might be implied by context. For instance, if a sensor is described for use in helicopters or UAVs, it falls under the category of being an \"Aerospatial\" LiDAR.\\n\\nOne potential challenge is dealing with repeated information. The text mentions Riegl LMS-S560-I and others multiple times, so I need to avoid duplicating entries. Each unique model should have its own object in the array.\\n\\nAdditionally, the user mentioned that if no sensors are found, we return an empty array. But here, there are definitely sensors present, so that\\'s not a concern.\\n\\nI\\'ll start by listing out each sensor model identified: LMS-Q240i-60/LMS-Q240i-80, LMS-S560-I, and LMS-S560-A. For each of these, I\\'ll extract their properties like weight, dimensions, power consumption, etc., converting them into the required units.\\n\\nFor components, phrases like \"rotating multi-facet mirror\" directly indicate a part. Since the example didn\\'t specify parts unless they were implied, I think it\\'s appropriate to include these as part of the component list under each sensor model.\\n\\nTechnical specs such as \"120 W (laser scanner)\" or \"1,500nm <4 ns\" need to be formatted with their respective units. These will go into the properties array for each sensor.\\n\\nLooking at the implementations, I don\\'t see any direct mentions of standards like IEEE 802.11p or ROS2. So, the \"implements\" array might remain empty for these sensors unless there\\'s a mention that I missed.\\n\\nEach sensor’s category is generally clear from context—most are LiDAR systems used in aerospace applications, so they fall under \"Aerospatial\".\\n\\nI need to ensure consistency in the JSON output. Each object should have all required keys, even if some values like \"components\" or \"implements\" might be empty. This avoids issues with parsing the JSON later on.\\n\\nLastly, after extracting all necessary information, I\\'ll structure it into a JSON array as per the example, making sure each sensor has its own object and that the overall format is correct.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Riegl LMS-Q240i-60/LMS-Q240i-80\",\\n      \"category\": \"Aerospatial\",\\n      \"components\": [\"Rotating multi-facet mirror\"],\\n      \"properties\": {\\n        \"weight\": \"20kg\",\\n        \"dimensions\": \"56 x 20 x 22 cm [LxWxH]\",\\n        \"power_consumption\": \"120 W (laser scanner)\",\\n        \"wavelength\": \"1,500nm <4 ns\",\\n        \"resolution\": \"0.3 mrad with 1 mrad option\"\\n      },\\n      \"implementations\": []\\n    },\\n    {\\n      \"name\": \"Riegl LMS-S560-I\",\\n      \"category\": \"Aerospatial\",\\n      \"components\": [\"Rotating multi-facet mirror\"],\\n      \"properties\": {\\n        \"weight\": \"20kg\",\\n        \"dimensions\": \"56 x 20 x 22 cm [LxWxH]\",\\n        \"power_consumption\": \"120 W\",\\n        \"wavelength\": \"1,500nm <4 ns\",\\n        \"resolution\": \"0.3 mrad with 1 mrad option\"\\n      },\\n      \"implementations\": []\\n    },\\n    {\\n      \"name\": \"Riegl LMS-S560-A\",\\n      \"category\": \"Aerospatial\",\\n      \"components\": [\"Rotating multi-facet mirror\"],\\n      \"properties\": {\\n        \"weight\": \"20kg\",\\n        \"dimensions\": \"56 x 20 x 22 cm [LxWxH]\",\\n        \"power_consumption\": \"120 W\",\\n        \"wavelength\": \"1,500nm <4 ns\",\\n        \"resolution\": \"0.3 mrad with 1 mrad option\"\\n      },\\n      \"implementations\": []\\n    }\\n  ]\\n}\\n```', '<think>\\nAlright, so I\\'m looking at this problem where I need to extract specific information from a given text using the guidelines provided. The task is to parse technical text related to LiDAR sensors and structure it into a JSON format with various fields like sensor models, components, technical specs, implementations, etc.\\n\\nFirst, I\\'ll start by understanding the requirements thoroughly. The user wants me to act as an expert in LiDAR sensors and extract certain entities from the given text. The entities include sensor models, components, technical specifications, implementations, and categories. There are also specific extraction rules to follow, such as preserving contextual relationships, capturing implied properties through comparisons, and retaining partial information with \"[INFERRED]\" tags.\\n\\nLooking at the example provided, I see that when the input is \"The Velodyne VLP-32C has a 200m range and 0.2° resolution,\" the output is a JSON structure with the sensor name, category, parts, properties, and implements fields. The parts are empty here, but the properties include the range and resolution.\\n\\nNow, moving on to the actual text provided. It\\'s quite lengthy and seems to be a product survey from GIM International in 2007. There are mentions of several LiDAR models: IGI LiteMapper 5600, 2400, and Leica Geosystems ALS50-II. Each model has various specifications mentioned, such as weight, dimensions, power consumption, wavelength, scan rates, etc.\\n\\nI\\'ll need to parse each section for sensor models, their components, technical specs, and any implementations or standards they follow. For instance, the IGI LiteMapper 5600 is described with a rotating polygon mirror, specific scan rates, and certain resolutions. The Leica Geosystems ALS50-II mentions things like oscillating mirrors, scan patterns, leading edge CFD, etc.\\n\\nI should also look out for any comparative statements to extract implied properties. For example, phrases like \"Outperforms Ouster OS2 in range\" would need to be converted into a property like \"comparative_range: > Ouster OS2.\" However, in the provided text, I don\\'t immediately see such direct comparisons, so maybe this part won\\'t be triggered here.\\n\\nNext, I\\'ll need to map these extracted entities into the JSON structure. Each sensor model will be an object within the \"sensors\" array. The category seems to be implied by the manufacturer or application context, but since it\\'s not explicitly stated in the text, I might have to infer it or leave it as a placeholder.\\n\\nComponents like mirrors and scan patterns are important, so they\\'ll go into the components field. Technical specifications such as power consumption, wavelength, scan rates, etc., will populate the properties. Implementations would include any subsystems mentioned, like GPS/IMU for positioning accuracy.\\n\\nI should also pay attention to any additional information that might be relevant but doesn\\'t fall neatly into the categories provided. For example, the mention of integrated digital frame cameras and optional RCD10a 39 MP camera is more about peripherals rather than the core LiDAR functionality, so maybe it\\'s less relevant here unless specified otherwise.\\n\\nAnother point is the handling of numerical data. I\\'ll need to present these as strings in the JSON output, possibly with units if they\\'re not already provided. For instance, \"37W x 56L x 24H cm\" for dimensions should be converted into a more readable format like \"37 cm (width) x 56 cm (length) x 24 cm (height).\"\\n\\nI also need to ensure that the JSON structure is correctly formatted, with each sensor model as an object under the \"sensors\" array. Each key in these objects must correspond accurately to the fields specified: name, category, components (if applicable), properties, and implements.\\n\\nAs I go through the text, I\\'ll list out all the sensor models first. From what I can see, there are three main models: IGI LiteMapper 5600, IGI LiteMapper 2400, and Leica Geosystems ALS50-II. Each of these will be a separate object in the sensors array.\\n\\nFor each model, I\\'ll extract the components mentioned. For example, the IGI models mention rotating polygon mirrors or oscillating mirrors for the Leica model. These will go into the components field as an array.\\n\\nTechnical specifications will include power consumption, wavelength (like 1064nm for some models), scan rates (e.g., 90Hz max for ALS50-II), and measurement accuracies. These specs should be listed clearly under the properties key.\\n\\nImplementations would cover any subsystems or additional hardware mentioned, such as GPS/IMU for positioning accuracy in the Leica model.\\n\\nI also need to ensure that if there are any implied relationships or comparisons in the text, they\\'re correctly noted with \"[INFERRED]\" tags. However, since the provided text doesn\\'t have direct comparisons, I might not need to use this feature here unless I infer something indirectly from the specs (e.g., if a higher power consumption could imply lower range, but that\\'s speculative and better left as separate fields).\\n\\nLastly, after extracting all the necessary information, I\\'ll structure it into the required JSON format. Each sensor model will be an object with name, category (if inferred), components, properties, and implements.\\n\\nI should also double-check for any missing information or possible ambiguities in the text to ensure accuracy. For instance, making sure that technical terms are correctly identified as components or properties rather than being misclassified.\\n\\nIn summary, my approach is to systematically parse each section of the text, identify the relevant entities based on the extraction rules, and structure them into the appropriate JSON format, ensuring all required fields are populated accurately.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": [\\n    {\\n      \"name\": \"IGI LiteMapper 5600\",\\n      \"category\": \"LiDAR Scanner\",\\n      \"components\": [\"rotating polygon mirror\"],\\n      \"properties\": {\\n        \"weight\": \"30 kg\",\\n        \"dimensions\": \"37 cm (width) x 56 cm (length) x 24 cm (height)\",\\n        \"power_consumption\": \"45W\",\\n        \"wavelength\": \"1064 nm\",\\n        \"scan_rates\": {\\n          \"max\": \"150,000 Hz\",\\n          \"full_cycle\": \"150,000 Hz\"\\n        },\\n        \"measurement_accuracy\": \"<10cm @ 1,000m AGL including GPS error of 10cm @ 2 sigma\"\\n      }\\n    },\\n    {\\n      \"name\": \"IGI LiteMapper 2400\",\\n      \"category\": \"LiDAR Scanner\",\\n      \"components\": [\"oscillating mirror\"],\\n      \"properties\": {\\n        \"weight\": \"40 kg (electronics)\",\\n        \"dimensions\": \"45 cm (width) x 47 cm (depth) x 36 cm (height)\",\\n        \"power_consumption\": \"28A average, 35A peak @ 28VDC\",\\n        \"wavelength\": \"1064 nm\",\\n        \"scan_rates\": {\\n          \"max\": \"90Hz\"\\n        },\\n        \"measurement_accuracy\": \"<10cm @ 1,000m AGL including GPS error of 10cm @ 2 sigma\"\\n      }\\n    },\\n    {\\n      \"name\": \"Leica Geosystems ALS50-II\",\\n      \"category\": \"LiDAR Scanner\",\\n      \"components\": [\"oscillating mirror\"],\\n      \"properties\": {\\n        \"weight\": \"22 kg (scanner head)\",\\n        \"dimensions\": \"37 cm (width) x 56 cm (length) x 24 cm (height)\",\\n        \"power_consumption\": \"37W\",\\n        \"wavelength\": \"1064 nm\",\\n        \"scan_rates\": {\\n          \"max\": \"90Hz\"\\n        },\\n        \"measurement_accuracy\": \"<5cm @ 1,000m AGL with GPS/IMU subsystem\"\\n      },\\n      \"implements\": [\"GPS/IMU subsystem for positioning accuracy\"]\\n    }\\n  ]\\n}\\n```', '<think>\\nAlright, I need to analyze this technical text about LiDAR sensors. The user has provided a specific structure for the output JSON, so I should make sure I follow that closely.\\n\\nFirst, I\\'ll read through the text carefully to identify the sensor models mentioned. The companies are IGI, Fugro, and Toposys. Each of them has their own LiDAR system: LiteMapper 2400, FLI-MAP 400, and a combined system respectively. So, these should be my target entities under \"sensors\".\\n\\nNext, I\\'ll look for components mentioned in the text. It talks about GPS errors, pulse rate, rotation/nutating speed of mirrors, and platform speed. These are technical aspects, but some of them might not be directly part of a sensor component. However, pulse rate is definitely a key component related to system performance.\\n\\nFor technical specifications, I need to extract quantified values with units. The text mentions the pulse rate: 167,000 pulses per second for Optech\\'s ALTM Gemini. That\\'s a clear specification.\\n\\nRegarding implementations or protocols, the text doesn\\'t mention any standards like IEEE 802.11p or ROS2. So, I won\\'t include anything under \"implements.\"\\n\\nThe category of each sensor needs to be identified. Since it\\'s an airborne LiDAR survey, all sensors fall into the \"Airborne Lidar\" category.\\n\\nNow, organizing this information into the JSON structure: each sensor will have a name, category, any parts mentioned (like pulse rate), properties with their values, and if they implement any protocols, which in this case there are none.\\n\\nI should ensure that I follow the extraction rules, especially preserving contextual relationships. For example, mentioning pulse rate as a component related to system performance. Also, using inferred tags where necessary, but since all info seems directly stated, maybe not needed here.\\n\\nFinally, checking if all sensors are found. There are three: IGI\\'s LiteMapper 2400, Fugro\\'s FLI-MAP 400, and Toposys\\'s combined system. Optech is mentioned with their ALTM Gemini, but it\\'s only presented as a product. However, the user\\'s example doesn\\'t include it, so perhaps it\\'s outside the current scope.\\n\\nPutting it all together, I\\'ll structure each sensor with the information extracted step by step.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": [\\n    {\\n      \"name\": \"IGI LiteMapper 2400\",\\n      \"category\": \"Airborne Lidar\",\\n      \"parts\": [\"pulse rate\"],\\n      \"properties\": [\"pulse_rate: 167,000 pulses/second\"],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Fugro FLI-MAP 400\",\\n      \"category\": \"Airborne Lidar\",\\n      \"parts\": [],\\n      \"properties\": [],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Toposys Combined System\",\\n      \"category\": \"Airborne Lidar\",\\n      \"parts\": [],\\n      \"properties\": [],\\n      \"implements\": []\\n    }\\n  ]\\n}\\n```', '<think>\\nAlright, I\\'m trying to figure out how to extract the required entities from this technical text. Let me go through it step by step.\\n\\nFirst, the user wants me to identify Target Entities: Sensor Models, Components, Technical Specs, Implementations, and Category. The extraction rules are a bit detailed, so I need to be careful.\\n\\nLooking at the text, I see mentions like \"Optech ALTM Gemini\" and \"Leica FPES.\" These seem like sensor models. So, those should go under sensors with their respective categories.\\n\\nNext, components. The text talks about parts like \"HDD Ground power supply,\" but that doesn\\'t fit the software or physical part context. However, there\\'s \"Flex-ible external sensor integration\" which might refer to a component that allows adding various sensors, so I\\'ll note that as a part.\\n\\nFor technical specs, numbers are key. I spot \"200m AGL,\" which is range. Then, \"167kHz PRF rate\" refers to pulse rate. The term \"0.0025/0.0025/0.005 deg\" seems like resolution, so that\\'s another spec.\\n\\nImplementations: The text mentions \"flight-management system (FCMS)\" and \"ROS2.\" Wait, does it say ROS2? Let me check again. Hmm, I don\\'t see ROS2 explicitly, but there\\'s a mention of \"flex-ible external sensor integration,\" which might relate to how sensors are implemented. Maybe that\\'s too vague.\\n\\nCategory: The text mentions uses like \"Disaster management, power-lines, pipe-line and railway and roadway corridors.\" This suggests it\\'s an airborne system used in various applications, possibly under \"Airborne LiDAR.\"\\n\\nI need to make sure I capture all the specs accurately and don\\'t miss any implied information. For example, \"Multipulse\" implies multiple pulses, so that should be noted as a property.\\n\\nAlso, ensuring that each sensor is correctly categorized. Optech ALTM Gemini seems to be under Airborne LiDAR, while Leica components might fall into another category if applicable, but the text doesn\\'t specify, so maybe they aren\\'t required here.\\n\\nI should structure this in JSON, following the example provided. Each sensor will have its own object within the \"sensors\" array, including name, category, parts, properties, and any implementations.\\n\\nFinally, double-checking to make sure all entities are correctly identified and no extra info is added outside the JSON.\\n</think>\\n\\n```json\\n{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Optech ALTM Gemini\",\\n      \"category\": \"Airborne LiDAR\",\\n      \"parts\": [\"Flex-ible external sensor integration\"],\\n      \"properties\": [\\n        \"range: 200m AGL\",\\n        \"pulse rate: 167kHz\",\\n        \"resolution: 0.0025/0.0025/0.005°\"\\n      ],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Leica FPES\",\\n      \"category\": \"Airborne LiDAR\",\\n      \"parts\": [],\\n      \"properties\": [\\n        \"range: 80m + Oscillating Mirror\"\\n      ],\\n      \"implements\": []\\n    }\\n  ]\\n}\\n```']\n"
     ]
    }
   ],
   "source": [
    "print('responses:', responses)\n",
    "# Save responses after every chunk to ensure progress is retained\n",
    "with open(\"R1_responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def clean_string(s):\n",
    "    \"\"\"\n",
    "    Clean and normalize strings by stripping whitespace, decoding unicode escapes,\n",
    "    normalizing characters, replacing common separators with a space, and fixing known encoding issues.\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return str(s).lower()\n",
    "    s = s.strip()\n",
    "    s = unicodedata.normalize('NFKC', s)\n",
    "    # s = re.sub(r\"[\\s\\_/]+\", \" \", s)\n",
    "    # Fix mis-encoded degree symbols: Replace \"â°\" with the correct \"°\"\n",
    "    s = s.replace(\"â\", \"\")\n",
    "    return s.lower()\n",
    "\n",
    "def extract_json_part(response_str):\n",
    "    \"\"\"\n",
    "    Extract the JSON block from Ollama's response string.\n",
    "    Tries to find the JSON block delimited by ```json and ```.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If response_str is a list, take the first element.\n",
    "        # content = response_str[0] if isinstance(response_str, list) else response_str\n",
    "        # Use regex to extract JSON block\n",
    "        # pattern = re.compile(r'```json\\s*(\\{.*?\\})\\s*```', re.DOTALL | re.MULTILINE)\n",
    "        # match = pattern.search(response_str)\n",
    "        # print(match)\n",
    "        # if match:\n",
    "        #     json_str = match.group(1).strip()\n",
    "        # else:\n",
    "        #     # Fallback method\n",
    "        json_str = response_str.split(\"```json\")[-1].split(\"```\")[0].strip()\n",
    "\n",
    "        return json.loads(json_str)\n",
    "    except (IndexError, json.JSONDecodeError) as e:\n",
    "        print(f\"Failed to extract JSON: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load responses from file\n",
    "with open(\"R1_responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = f.read()\n",
    "\n",
    "# Try parsing as a full JSON array; if that fails, split by lines.\n",
    "try:\n",
    "    responses = json.loads(raw_data)\n",
    "except json.JSONDecodeError:\n",
    "    responses = [json.loads(line) for line in raw_data.splitlines() if line.strip()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted: {'sensors': []}\n",
      "extracted: {'sensors': [{'name': 'Riegl LMS Q240i-60/LMS-Q240i-80', 'category': 'Aerocontrol', 'parts': ['rotating multi-facet mirror'], 'properties': ['range: 2m / 200m / 350m', 'angular resolution: 0.3 mrad with 1 mrad option', 'power consumption: 43 W', 'bit depth: 16 bits', 'data rate: practically unlimited'], 'implements': []}, {'name': 'Riegl LMS-S560-I/LMS-S560-A', 'category': 'Aerocontrol', 'parts': ['rotating multi-facet mirror', 'full waveform processing'], 'properties': ['power consumption: 120 W', 'bit depth: 16 bits', 'angular resolution: 0.3 mrad with 1 mrad option', 'data rate: practically unlimited'], 'implements': []}]}\n",
      "extracted: {'sensors': [{'name': 'TopoSys GmbH Harrier', 'category': 'Surveying LiDAR', 'parts': ['rotating multi-facet mirror', 'Applanix POSAV 310'], 'properties': ['rotation speed: 6 - 80Hz, 5 - 60Hz', 'mirror angle: 60°/80°', 'frame rate: 3/280/430 (80°), 3/250/380', 'range: N/A', 'resolution: 0.015/0.015/0.035°', 'power requirements: 28 V DC, 13 A max'], 'implements': ['TrackAir TopPIT']}]}\n",
      "extracted: [{'Sensor Model': 'TopEye Mk II', 'Components': ['Rotating multi-facet mirror'], 'Technical Specs': {'Wavelength': '1,064nm', 'Pulse Duration': '4ns', 'Range': '40m at low effect', 'Frequency': '0-75Hz'}, 'Implementations': ['Full waveform processing', '16 bits'], 'Category': 'Industrial LiDAR'}, {'Sensor Model': 'TopoSys GmbH Falcon III', 'Components': ['Rotating multi-facet mirror', 'Multi-facet mirror (up to 1mrad option)'], 'Technical Specs': {'Wavelength': '1,550nm', 'Pulse Duration': '<4ns', 'Range': '30m /800m /1,000m'}, 'Implementations': ['Full waveform processing', '16 bits'], 'Category': 'Industrial LiDAR'}]\n",
      "extracted: {'sensors': [{'name': 'Optech ALTM Gemini', 'category': 'Airborne LiDAR', 'parts': ['rotating multi-facet mirror', 'oscillating mirror', 'POS'], 'properties': ['range: 200m', 'PRF: 167kHz', 'accuracy: 0.0025/0.0025/0.005 deg', 'control rack size: 65 x 59 x 49cm'], 'implements': ['ROS2', 'FCMS']}, {'name': 'Applanix DSS', 'category': 'Airborne LiDAR', 'parts': ['POS'], 'properties': ['accuracy: 0.015/0.015/0.035 deg'], 'implements': []}, {'name': 'Turnkey solution (TopoSys GmbH Harrier)', 'category': 'Entry level LiDAR', 'parts': ['frame cameras'], 'properties': ['range: 150m', 'accuracy: 0.5 (@150m, 150km/h), 0.7 (@150m, 150km/h)'], 'implements': []}]}\n",
      "extracted: {'sensors': [{'name': 'FLI-MAP 400', 'category': 'Airborne Lidar', 'parts': [], 'properties': ['pulse_rate: 167,000 pulses per second'], 'implements': []}, {'name': 'LidAR Terrain Mapping system (LiteMapper) 2400', 'category': 'Airborne Lidar', 'parts': [], 'properties': [], 'implements': []}, {'name': 'ALTM Gemini', 'category': 'Airborne Lidar', 'parts': [], 'properties': ['pulse_rate: 167,000 pulses per second'], 'implements': []}]}\n",
      "extracted: {'sensors': [{'name': '', 'category': 'LiDAR', 'parts': ['rotating mirror', 'oscillating mirror', 'pulse frequency', 'data storage facilities', 'power equipment', 'trimble db950 l1/l2', 'applanix posav 410'], 'properties': [{'Component': 'Rotating Mirror', 'Property': 'Scan Angle (max.) [deg]', 'Value': '150Hz'}, {'Component': 'Pulse Frequency', 'Property': 'Range (min-max) [Hz]', 'Value': '250,000Hz'}, {'Component': 'Data Storage Facilities', 'Property': 'Type', 'Value': '[10]'}]}]}\n",
      "extracted: {'sensors': [{'name': 'Riegl LMS-Q240i-60/LMS-Q240i-80', 'category': 'Aerospatial', 'components': ['Rotating multi-facet mirror'], 'properties': {'weight': '20kg', 'dimensions': '56 x 20 x 22 cm [LxWxH]', 'power_consumption': '120 W (laser scanner)', 'wavelength': '1,500nm <4 ns', 'resolution': '0.3 mrad with 1 mrad option'}, 'implementations': []}, {'name': 'Riegl LMS-S560-I', 'category': 'Aerospatial', 'components': ['Rotating multi-facet mirror'], 'properties': {'weight': '20kg', 'dimensions': '56 x 20 x 22 cm [LxWxH]', 'power_consumption': '120 W', 'wavelength': '1,500nm <4 ns', 'resolution': '0.3 mrad with 1 mrad option'}, 'implementations': []}, {'name': 'Riegl LMS-S560-A', 'category': 'Aerospatial', 'components': ['Rotating multi-facet mirror'], 'properties': {'weight': '20kg', 'dimensions': '56 x 20 x 22 cm [LxWxH]', 'power_consumption': '120 W', 'wavelength': '1,500nm <4 ns', 'resolution': '0.3 mrad with 1 mrad option'}, 'implementations': []}]}\n",
      "extracted: {'sensors': [{'name': 'IGI LiteMapper 5600', 'category': 'LiDAR Scanner', 'components': ['rotating polygon mirror'], 'properties': {'weight': '30 kg', 'dimensions': '37 cm (width) x 56 cm (length) x 24 cm (height)', 'power_consumption': '45W', 'wavelength': '1064 nm', 'scan_rates': {'max': '150,000 Hz', 'full_cycle': '150,000 Hz'}, 'measurement_accuracy': '<10cm @ 1,000m AGL including GPS error of 10cm @ 2 sigma'}}, {'name': 'IGI LiteMapper 2400', 'category': 'LiDAR Scanner', 'components': ['oscillating mirror'], 'properties': {'weight': '40 kg (electronics)', 'dimensions': '45 cm (width) x 47 cm (depth) x 36 cm (height)', 'power_consumption': '28A average, 35A peak @ 28VDC', 'wavelength': '1064 nm', 'scan_rates': {'max': '90Hz'}, 'measurement_accuracy': '<10cm @ 1,000m AGL including GPS error of 10cm @ 2 sigma'}}, {'name': 'Leica Geosystems ALS50-II', 'category': 'LiDAR Scanner', 'components': ['oscillating mirror'], 'properties': {'weight': '22 kg (scanner head)', 'dimensions': '37 cm (width) x 56 cm (length) x 24 cm (height)', 'power_consumption': '37W', 'wavelength': '1064 nm', 'scan_rates': {'max': '90Hz'}, 'measurement_accuracy': '<5cm @ 1,000m AGL with GPS/IMU subsystem'}, 'implements': ['GPS/IMU subsystem for positioning accuracy']}]}\n",
      "extracted: {'sensors': [{'name': 'IGI LiteMapper 2400', 'category': 'Airborne Lidar', 'parts': ['pulse rate'], 'properties': ['pulse_rate: 167,000 pulses/second'], 'implements': []}, {'name': 'Fugro FLI-MAP 400', 'category': 'Airborne Lidar', 'parts': [], 'properties': [], 'implements': []}, {'name': 'Toposys Combined System', 'category': 'Airborne Lidar', 'parts': [], 'properties': [], 'implements': []}]}\n",
      "extracted: {'sensors': [{'name': 'Optech ALTM Gemini', 'category': 'Airborne LiDAR', 'parts': ['Flex-ible external sensor integration'], 'properties': ['range: 200m AGL', 'pulse rate: 167kHz', 'resolution: 0.0025/0.0025/0.005°'], 'implements': []}, {'name': 'Leica FPES', 'category': 'Airborne LiDAR', 'parts': [], 'properties': ['range: 80m + Oscillating Mirror'], 'implements': []}]}\n",
      "Processed 21 unique sensors.\n"
     ]
    }
   ],
   "source": [
    "# Use a dictionary to accumulate unique sensors based on (name, category, parts, properties)\n",
    "sensor_dict = {}\n",
    "\n",
    "for response in responses:\n",
    "    # If the response is not a dict, try extracting the JSON block\n",
    "    if not isinstance(response, dict):\n",
    "        extracted = extract_json_part(response)\n",
    "        if extracted is None:\n",
    "            continue\n",
    "        response = extracted\n",
    "\n",
    "    print('extracted:', response)\n",
    "    if isinstance(response, list):\n",
    "        continue\n",
    "    sensors = response.get(\"sensors\", [])\n",
    "    if not isinstance(sensors, list):\n",
    "        continue\n",
    "\n",
    "    for sensor in sensors:\n",
    "        # Validate required fields and clean them\n",
    "        sensor_name = clean_string(sensor.get(\"name\", \"unnamed sensor\"))\n",
    "        category_name = clean_string(sensor.get(\"category\", \"uncategorized\"))\n",
    "        parts_list = sensor.get(\"parts\", [])\n",
    "        properties_list = sensor.get(\"properties\", [])\n",
    "        implements_list = sensor.get(\"implements\", [])\n",
    "\n",
    "        cleaned_parts = sorted(clean_string(p) for p in parts_list if p)\n",
    "        cleaned_properties = sorted(clean_string(p) for p in properties_list if p)\n",
    "        cleaned_implements = sorted(clean_string(i) for i in implements_list if i)\n",
    "\n",
    "        # Use key without implements for merging duplicates:\n",
    "        key = (sensor_name, category_name, tuple(cleaned_parts), tuple(cleaned_properties))\n",
    "        \n",
    "        if key in sensor_dict:\n",
    "            # Merge the implements list (union of values)\n",
    "            current_impl = set(sensor_dict[key][\"implements\"])\n",
    "            new_impl = set(cleaned_implements)\n",
    "            sensor_dict[key][\"implements\"] = sorted(current_impl.union(new_impl))\n",
    "        else:\n",
    "            sensor_dict[key] = {\n",
    "                \"name\": sensor_name,\n",
    "                \"category\": category_name,\n",
    "                \"parts\": sorted(cleaned_parts),\n",
    "                \"properties\": sorted(cleaned_properties),\n",
    "                \"implements\": sorted(cleaned_implements)\n",
    "            }\n",
    "\n",
    "# Convert the sensor dictionary to a list\n",
    "final_sensors = list(sensor_dict.values())\n",
    "\n",
    "# Save the final, deduplicated JSON\n",
    "with open(\"R1_sensors_merged2.json\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "    json.dump({\"sensors\": final_sensors}, out_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Processed {len(final_sensors)} unique sensors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology created and saved as sensor_ontology_with_properties_and_implements.owl\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "with open(\"R1_sensors_merged2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a new ontology\n",
    "onto = get_ontology(\"http://example.org/sensor_ontology.owl\")\n",
    "\n",
    "with onto:\n",
    "    # Define basic classes and properties\n",
    "    class Sensor(Thing):\n",
    "        pass\n",
    "    \n",
    "    class Part(Thing):\n",
    "        pass\n",
    "    \n",
    "    class Property(Thing):\n",
    "        pass\n",
    "    \n",
    "    class Technology(Thing):\n",
    "        pass\n",
    "\n",
    "    class has_part_directly(ObjectProperty):\n",
    "        domain = [Sensor]\n",
    "        range = [Part]\n",
    "    \n",
    "    class implements(ObjectProperty):\n",
    "        domain = [Sensor]\n",
    "        range = [Technology]\n",
    "    \n",
    "    class has_property(ObjectProperty):\n",
    "        domain = [Sensor]\n",
    "        range = [Property]\n",
    "\n",
    "    # Define an annotation property for category\n",
    "    class category(AnnotationProperty):\n",
    "        pass\n",
    "\n",
    "    # Process the JSON data\n",
    "    category_classes = {} # dictionary to store created category classes.\n",
    "    part_classes = {}  # Cache for part classes to avoid duplicates\n",
    "    property_classes = {}  # Cache for property classes\n",
    "    technology_classes = {}  # Cache for technology classes\n",
    "\n",
    "# Process each sensor from the JSON data\n",
    "    for sensor_data in data[\"sensors\"]:\n",
    "        # Clean sensor name and category\n",
    "        sensor_name = clean_string(sensor_data[\"name\"]).replace(\" \", \"_\")\n",
    "        sensor_category_name = clean_string(sensor_data[\"category\"]).replace(\" \", \"_\")\n",
    "        \n",
    "        # Create or retrieve the category class (as a subclass of Sensor)\n",
    "        if sensor_category_name not in category_classes:\n",
    "            # Create new category class as a subclass of Sensor\n",
    "            category_class = types.new_class(sensor_category_name, (Sensor,))\n",
    "            category_classes[sensor_category_name] = category_class\n",
    "        else:\n",
    "            category_class = category_classes[sensor_category_name]\n",
    "\n",
    "        # Create the sensor model as a subclass of the category class\n",
    "        sensor_class = types.new_class(sensor_name, (category_class,))\n",
    "        \n",
    "        # Process and link parts\n",
    "        for part_name in sensor_data.get(\"parts\", []):\n",
    "            part_clean = clean_string(part_name).replace(\" \", \"_\")\n",
    "            if part_clean not in part_classes:\n",
    "                part_class = types.new_class(part_clean, (Part,))\n",
    "                part_classes[part_clean] = part_class\n",
    "            else:\n",
    "                part_class = part_classes[part_clean]\n",
    "            sensor_class.is_a.append(has_part_directly.some(part_class))\n",
    "\n",
    "        # Process and link properties\n",
    "        for prop_name in sensor_data.get(\"properties\", []):\n",
    "            prop_clean = clean_string(prop_name).replace(\" \", \"_\")\n",
    "            if prop_clean not in property_classes:\n",
    "                prop_class = types.new_class(prop_clean, (Property,))\n",
    "                property_classes[prop_clean] = prop_class\n",
    "            else:\n",
    "                prop_class = property_classes[prop_clean]\n",
    "            sensor_class.is_a.append(has_property.some(prop_class))\n",
    "\n",
    "        # Process and link technologies (implements relationship)\n",
    "        for tech_name in sensor_data.get(\"implements\", []):\n",
    "            tech_clean = clean_string(tech_name).replace(\" \", \"_\")\n",
    "            if tech_clean not in technology_classes:\n",
    "                tech_class = types.new_class(tech_clean, (Technology,))\n",
    "                technology_classes[tech_clean] = tech_class\n",
    "            else:\n",
    "                tech_class = technology_classes[tech_clean]\n",
    "            sensor_class.is_a.append(implements.some(tech_class))\n",
    "# Save the ontology to a file\n",
    "onto.save(file=\"R1_2_sensor_ontology_with_properties_and_implements.owl\", format=\"rdfxml\")\n",
    "\n",
    "print(\"Ontology created and saved as sensor_ontology_with_properties_and_implements.owl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
