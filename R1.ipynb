{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq pip --progress-bar off\n",
    "%pip install -qqq ollama --progress-bar off\n",
    "%pip install -qqq pathlib --progress-bar off\n",
    "%pip install -qqq pandas --progress-bar off\n",
    "%pip install -qqq PyPDF2 --progress-bar off\n",
    "%pip install -qqq owlready2 --progress-bar off\n",
    "%pip install -qqq rdflib --progress-bar off\n",
    "%pip install -qqq langchain-ollama --progress-bar off\n",
    "%pip install -qqq langchain-community --progress-bar off\n",
    "%pip install -qqq langchain_community pypdf --progress-bar off\n",
    "%pip install -qqq langchain-chroma --progress-bar off\n",
    "%pip install -qqq rank_bm25  --progress-bar off\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the imports\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import ollama\n",
    "import json\n",
    "from enum import Enum\n",
    "MODEL = \"deepseek-r1:8b-llama-distill-q8_0\"\n",
    "import json\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove LaTeX equations\n",
    "    text = re.sub(r'\\$.*?\\$', '', text)  # Remove inline equations\n",
    "    # Fix hyphenated words\n",
    "    text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n",
    "    # Remove excessive whitespace\n",
    "    return re.sub(r'\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF\n",
    "pdf_loader = PyPDFLoader(file_path=\"LiDAR-Sensors.pdf\",extract_images=False)\n",
    "docs = pdf_loader.load();\n",
    "# Enhanced cleaning pipeline\n",
    "for doc in docs:\n",
    "    doc.page_content = clean_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_splits(splits):\n",
    "    stats = {\n",
    "        'total_chunks': len(splits),\n",
    "        'avg_chunk_length': sum(len(c.page_content) for c in splits)/len(splits),\n",
    "        'max_length': max(len(c.page_content) for c in splits),\n",
    "        'min_length': min(len(c.page_content) for c in splits),\n",
    "        'metadata_fields': list(splits[0].metadata.keys()) if splits else []\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_chunks': 9,\n",
       " 'avg_chunk_length': 2127.6666666666665,\n",
       " 'max_length': 3143,\n",
       " 'min_length': 435,\n",
       " 'metadata_fields': ['source', 'page', 'page_label', 'start_index']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=lambda text: len(text.split()),  # Word-based counting\n",
    "        add_start_index=True,\n",
    "       separators=[\n",
    "        \"\\n\\n## \",    # Section headers\n",
    "        \"\\n\\n\",       # Paragraph breaks\n",
    "        \"\\n\",         # New lines\n",
    "        \"(?<!\\d)\\.(?!\\d)\\s+\",  # Sentence ends with space\n",
    "        \";\",          # Semi-colons\n",
    "        \", \",         # Commas\n",
    "        \" \"\n",
    "        ],\n",
    "        keep_separator=True,\n",
    "        is_separator_regex=True,\n",
    "    )\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "analyze_splits(splits)\n",
    "\n",
    "# word_count(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create embeddings and store in CHROMA database\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"KGLLM\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "# Add documents and their embeddings to Chroma (might take some time)\n",
    "vector_store.add_documents(documents=splits)\n",
    "\n",
    "# Create individual retrievers\n",
    "vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k = 3  # Match vector retriever's k\n",
    "\n",
    "# Create ensemble\n",
    "retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=[0.7, 0.3]  # Vector search 70%, BM25 30%\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 1, 'page_label': '25', 'source': 'LiDAR-Sensors.pdf', 'start_index': 2846}\n",
      ". Removable HDD Ground power supply Fixed-wing or helicopter 200 - 6,000m AGL ~17 hrs @ max pulse rate 0 - 40 °C cabin-side temperature Non-condensing Leica FPES Leica ALS Post Processor for point-cloud generation,T erraScan/T erraModeler for viewing/editing. DEMs, city models, flood plain, erosion & forestery studies, forest floor, disaster management, power-lines, pipe-line and railway and roadway corridors, coastal mapping. Full-function system for a wide variety of applications now features highly integrated FCMS flight-management system and flex - ible external sensor integration. Optech ALTM Gemini October 2006 23.4kg, 26 x 19 x 57cm 95kg, control rack size 65 x 59 x 49cm 28 VDC, 35 A (maximum) 1,060nm 7ns 0.8, 0.25, 0.15 1/e Class IV (FDA 21 CFR) 80 m + Oscillating Mirror 100Hz 167kHz 50 deg 4 ranges Leading edge 12 bits Trimble, 12 channel, dual-frequency 0.05cm POS 610, 200 Hz 0.0025/0.0025/0.005 deg POS PAC 0.0025/0.0025/0.005 deg 3cm < 10cm 1/11000 20 points - 100 Knots, 500m, 100Hz scan, +/- 10°, PRF = 167kHz. As above 0.25m As above 0.21m Applanix DSS, Rollei 39 Mpixel Removable hard disk, min 70 Gbytes Internal to the system T win engine fixed-wing, rotary wing 200m / 1km to 2km / 4km max; higher avail - able on request Unlimited -10°C to 35°C 0 to 95% non-condensing ALTM NAV DASHMap Power-line mapping, topographic survey, urban mapping, flood mapping, etc. Multipulse airborne Lidar system with the highest PRF rate of 167kHz in the industry; global 24/7 technical support.\n",
      "{'page': 4, 'page_label': '5', 'source': 'sensors.pdf', 'start_index': -1}\n",
      ". Four different distances between the LiDAR sensor and the sphere construction were used: 7 m, 12 m, 15 m, and 25 m. The minimum distance was chosen because at 7 m all LiDAR had all spheres in their FOV . The maximal distance was chosen after noticing that at this range the ﬁrst sensors were unable to detect the spheres; knowing the performance at25 m was a good indication for the following dynamic scenarios. The decision to use 12 m and 15 m in between instead of equidistant distances has no particular reasons. For each distance and for each LiDAR sensor, 1000 data points were taken (cf. Section 4.1 for the results).\n",
      "{'page': 2, 'page_label': '26', 'source': 'LiDAR-Sensors.pdf', 'start_index': -1}\n",
      ". Recording of digitised echo signals and sub - sequent full-waveform analysis. Manufacturer Type/name of Lidar sensor Date of introduction/last update Dimensions - weight [kg] & size [cm] of laser system - weight [kg] & size [cm] of total system - power requirements Laser Pulse Characteristics - wavelength [mm] - pulse length [ns] - beam divergence (across/along tr.) [mrad] - type/class laser - eyesafe range [m] Recording Methodology - scanning method [1] - rotation speed of mirror [2] - pulse frequency (min-max) [Hz] - max. scan angle [deg] - max. # of recorded echoes/pulse - pulse sampling frequency [3] - pulse detection method [4] - dynamic range of intensity signal [bits] Positioning System - GPS system [5] - GPS precision planimetric/height (2 sigma) [cm] - INS system [6] - INS precision (roll/pitch/heading) [deg] - GPS/INS postprocessing software Precision and Resolution - Pointing precision (roll/pitch/heading) [deg] - Range precision (2 sigma) [cm] - Elevation precision at 1km (2 sigma) [cm] - Overall planimetric precision (2 sigma) [cm] - Range precision (2 sigma) [cm] - Max. # of points/m2 - Along-track point spacing [m] [7] - Across-track point spacing [m] [8] Other System Parts - Cameras [9] - Data Storage Facilities [10] - Power equipment Operation Characteristics - typical platform - flying heights (min/typical/max) [m] - max. acquisition duration [hrs] - air temperature (min-max) [°C] - air humidity (min-max) [%] - mission-planning software - postprocessing software - proven applications Remarks [[1] E.g. rotating mirror, oscillating mirror etc. [2] Also called scan frequency. [3] Also called sample interval per pulse. [4] Describe here which part of the reflected pulse is recorded. [5] Brand, number of channels, single or dual frequency, update frequency [Hz] . [6] Brand, update frequency [Hz]. [7] Number referred to flight altitude 1000m. [8] Number referred to a typical flying speed of 150 km/h, or other appropriate speed. [9] Types of camera standard to system. [10] Type of storage facilities (tape, disk, etc.), storage [GB], removable or not.\n",
      "{'source': 'LiDAR-Sensors.pdf', 'page': 0, 'page_label': '24', 'start_index': 0}\n",
      "Product survey February 2007 GIM International Airborne Lidar Sensors This is the second Product Survey on Airborne Lidar Sensors; the last appeared under the title ‘Airborne Laser-scanners’ in our May 2004 issue. Seven companies were willing to co-operate by filling in the questionnaire for the present survey. ‘Airborne Laser-scanners’ is a term used in Europe; other parts of the world have generally adopted the term ‘Air - borne Lidar’. Two companies represented in our previous survey , Mosaic Mapping Systems and Terrapoint are beyond the scope of the present survey , while we welcome two newcomers. The first is Ingenieur-Gesellschaft für Interfaces (IGI) based in Kreuztal, Germany , which produces and sells the airborne Lidar Terrain Mapping system (LiteMapper) 2400. IGI is an engineering company founded in 1978 by Albrecht Grimm and specialising in the design and development of guidance positioning, attitude determination and sensormanagement systems for airborne survey . The second newcomer is Fugro, a company that operates the FLI-MAP 400 system for Lidar survey . This company is positioned somewhat eccentrically in relation to other firms in that it does not put the FLI-MAP system itself on the for-sale shelf but performs only surveys. However, its system has been developed in-house and differs significantly from what other sensor operators are using in performing surveys based on Lidar systems offered by one or more manufacturers. We felt the uniqueness of the Fugro system qualified it for inclusion in this product survey . Another company standing apart from its counterparts in a similar respect is the German Toposys, which enjoys a unique position worldwide in that it combines the manufacture of Lidar systems with self-executed Lidar surveys. The company considers this dual role an advantage as it provides a broad base of expertise. Although Optech, based in Toronto, Canada is a world leader in the development, manufacture and sale of Lidar systems, the company prefers here to present only its newest system, the Airborne Laser Terrain Mappers ALTM Gemini, able to generate 167,000 pulses per second. Precision and resolution statistics presented in these surveys are always a little tricky because the claims depend on system components taken into account. For example, does eleva - tion precision include GPS errors or is it quoted without? Statistics on minimum detectable size of objects should also be considered with care because this factor depends on flying height and target reflectivity . At a platform altitude of 200m power-lines just 8mm in diameter may be mapped; at flying height 1000m they need to be 3cm. The maximum possible number of points detected per square metre also depends on pulse rate and rotation/nutating speed of mirror on flying height, reflectivity and platform speed. The fields of application for Lidar are very diverse and include generation of digital elevation models, 3D-city modelling, forestry management, coastline protection, disaster man - agement, erosion studies, archaeology , monitoring of corridors such as power-lines, pipelines, railways and roads\n",
      "{'source': 'LiDAR-Sensors.pdf', 'page': 3, 'page_label': '27', 'start_index': 2640}\n",
      ". T urnkey solution, additional sensors such as temperature, oblique or video available, cus - tomised housing possible, stable frame cam - era also for photogrammetric work,very easy to handle, no operator required. T opoSys GmbH Harrier 24 October 2005 > 10kg customised due to options 2 boxes, > 30kg total 28 V DC, 13 A max. 900nm < 10ns 2.7mrad Class 1 0m Rotating multi-facet mirror 6 - 80Hz / 5 - 60Hz 30,000 60 deg / 80 deg First or last or alternating N/A Center of gravity of echo pulse 8 bits Applanix POSAV 310 5 - 30cm Applanix POSAV 310 0.015/0.015/0.035 deg Applanix Pos/Pac INS precision 3cm 15cm N.A. 3 10 points 0,5 (@150m, 150km/h) 0,7m (@150m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 200GB UPS Helicopter (60°) 3/280/430 (80°) 3/250/380 > 8 hrs 0 to + 50°C 80% (at or below 31°C) TrackAir T opPIT Low-altitude corridor mapping and survey - ing for construction and engineering, snow, ice and glacier mapping, ortho and trueortho images. Entry level system, low-cost turnkey solu - tion, additional sensors such as tempera - ture, oblique or video available, customised housing possible, very easy to handle, no operator required.\n",
      "{'source': 'LiDAR-Sensors.pdf', 'page': 0, 'page_label': '24', 'start_index': -1}\n",
      ". The fields of application for Lidar are very diverse and include generation of digital elevation models, 3D-city modelling, forestry management, coastline protection, disaster man - agement, erosion studies, archaeology , monitoring of corridors such as power-lines, pipelines, railways and roads. By Mathias Lemmens, editor-in-chief, GIM International Fugro FLI-MAP 400 Q1-2006 30kg, 50 x 30 x 30cm ~100kg 24V /30W 1,500nm 4ns 0.45 mrad (radial) Fiber / Class 1 M 0.3m Rotating mirror 150Hz 250,000Hz 60 deg 4 0.025 ps Threshold 11 bits 2x Trimble DB950 L1/L2, 10 Hz 5 / 10cm (2 sigma) Applanix PosAV 410, 200 Hz 0.008 / 0.008 / 0.015 deg GrafNav/PosProc 0.008 / 0.008 / 0.015 deg 2-3 cm Depending on network quality Depending on network quality 2-3 cm (2 sigma) 175 points (first return) altitude and speed- dependent 0.27m @ 150km/h 0.46m @ 400m AGL Forward and downward-looking 11Mpix still and video Removable hard disks, 80 GB Aircraft power 24V Helicopter/fixed wing 50 - 400m 3 - 6hrs -10 to 50 °C 99% non-condensing FLIP7 FLIP7 Corridor mapping, DTM/DSM [1] E.g. rotating mirror, oscillating mirror etc. [2] Also called scan frequency. [3] Also called sample interval per pulse. [4] Describe here which part of the reflected pulse is recorded. [5] Brand, number of channels, single or dual frequency, update frequency [Hz] . [6] Brand, update frequency [Hz]. [7] Number referred to flight altitude 1000m. [8] Number referred to a typical flying speed of 150 km/h, or other appropriate speed. [9] Types of camera standard to system. [10] Type of storage facilities (tape, disk, etc.), storage [GB], removable or not. Manufacturer Type/name of Lidar sensor Date of introduction/last update Dimensions - weight [kg] & size [cm] of laser system - weight [kg] & size [cm] of total system - power requirements Laser Pulse Characteristics - wavelength [mm] - pulse length [ns] - beam divergence (across/along tr.) [mrad] - type/class laser - eyesafe range [m] Recording Methodology - scanning method [1] - rotation speed of mirror [2] - pulse frequency (min-max) [Hz] - max. scan angle [deg] - max. # of recorded echoes/pulse - pulse sampling frequency [3] - pulse detection method [4] - dynamic range of intensity signal [bits] Positioning System - GPS system [5] - GPS precision planimetric/height (2 sigma) [cm] - INS system[6] - INS precision (roll/pitch/heading) [deg] - GPS/INS postprocessing software Precision and Resolution - Pointing precision (roll/pitch/heading) [deg] - Range precision (2 sigma) [cm] - Elevation precision at 1km (2 sigma) [cm] - Overall planimetric precision (2 sigma) [cm] - Range precision (2 sigma) [cm] - Max. # of points/m2 - Along-track point spacing [m] [7] - Across-track point spacing [m] [8] Other System Parts - Cameras [9] - Data Storage Facilities [10] - Power equipment Operation Characteristics - typical platform - flying heights (min/typical/max) [m] - max\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "query = \"What are the specifications of the LiDAR sensors mentioned?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "# # Inspect results\n",
    "for doc in results:\n",
    "    print(doc.metadata)\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 18, 'page_label': '19', 'source': 'sensors.pdf', 'start_index': -1}\n",
      ". Informed Consent Statement: Not applicable. Data Availability Statement: Data available on request due to privacy restrictions. The data presented in this study are available on request from the corresponding authors. The data are not publicly available due to company policies. Conﬂicts of Interest: The authors declare no conﬂict of interest. References 1. Driving, A. Levels of Driving Automation are Deﬁned in New SAE International Standard J3016: 2014; SAE International: Warrendale, PA, USA, 2014. 2. First Internationally Valid System Approval for Conditionally Automated Driving. Daimler. Available online: https: //www.daimler.com/innovation/product-innovation/autonomous-driving/system-approval-for-conditionally-automateddriving.html (accessed on 13 December 2021). 3. Roriz, R.; Cabral, J.; Gomes, T. Automotive LiDAR Technology: A Survey. IEEE Trans. Intell. Transp. Syst. 2022, 23, 6282–6297. doi: 10.1109/TITS.2021.3086804. [CrossRef] 4. Pendleton, S.D.; Andersen, H.; Du, X.; Shen, X.; Meghjani, M.; Eng, Y.H.; Rus, D.; Ang, M.H., Jr. Perception, planning, control, and coordination for autonomous vehicles. Machines 2017, 5, 6. [CrossRef]\n",
      "{'page': 13, 'page_label': '14', 'source': 'sensors.pdf', 'start_index': 0}\n",
      "Sensors 2022, 22, 7146 14 of 20 0 50 100 150 200 250 300 Distancetovehicle[m] -1 0 1 2 3 4 5 DeltabetweenGPSandmeasuredposition[m] MeasurementPoint OffsetRecreation (a) 0 50 100 150 200 250 300 Distancetovehicle[m] -1 0 1 2 3 4 5 DeltabetweenGPSandmeasuredposition[m] MeasurementPoint OffsetRecreation (b) 0 50 100 150 200 250 300 Distancetovehicle[m] -1 0 1 2 3 4 5 DeltabetweenGPSandmeasuredposition[m] MeasurementPoint OffsetRecreation (c) Figure 10. Results of Scenario 4. The difference between GPS and LiDAR measurement in relation to the distance is shown (a) Velodyne Velarray (1175 vehicle detections); (b) Robosense M1 (522 vehicle detections); (c) Livox Horizon (468 vehicle detections).\n",
      "{'page': 3, 'page_label': '4', 'source': 'sensors.pdf', 'start_index': -1}\n",
      ". • Update rate or frame rate. In order to avoid longer delays in the object detection, the sensor systems should have an update frequency or frame rate of more than 5 Hz. • ROS/ROS2 support. For an easy integration into our control software stack [6], a Linuxbased system implementation and an AD framework based on ROS2 is preferred. • Robustness of sensor systems. The test candidates should work well also in tougher weather conditions, and the sensor performance should not notably degrade under those conditions.\n",
      "{'source': 'LiDAR-Sensors.pdf', 'page': 1, 'page_label': '25', 'start_index': 2846}\n",
      ". Removable HDD Ground power supply Fixed-wing or helicopter 200 - 6,000m AGL ~17 hrs @ max pulse rate 0 - 40 °C cabin-side temperature Non-condensing Leica FPES Leica ALS Post Processor for point-cloud generation,T erraScan/T erraModeler for viewing/editing. DEMs, city models, flood plain, erosion & forestery studies, forest floor, disaster management, power-lines, pipe-line and railway and roadway corridors, coastal mapping. Full-function system for a wide variety of applications now features highly integrated FCMS flight-management system and flex - ible external sensor integration. Optech ALTM Gemini October 2006 23.4kg, 26 x 19 x 57cm 95kg, control rack size 65 x 59 x 49cm 28 VDC, 35 A (maximum) 1,060nm 7ns 0.8, 0.25, 0.15 1/e Class IV (FDA 21 CFR) 80 m + Oscillating Mirror 100Hz 167kHz 50 deg 4 ranges Leading edge 12 bits Trimble, 12 channel, dual-frequency 0.05cm POS 610, 200 Hz 0.0025/0.0025/0.005 deg POS PAC 0.0025/0.0025/0.005 deg 3cm < 10cm 1/11000 20 points - 100 Knots, 500m, 100Hz scan, +/- 10°, PRF = 167kHz. As above 0.25m As above 0.21m Applanix DSS, Rollei 39 Mpixel Removable hard disk, min 70 Gbytes Internal to the system T win engine fixed-wing, rotary wing 200m / 1km to 2km / 4km max; higher avail - able on request Unlimited -10°C to 35°C 0 to 95% non-condensing ALTM NAV DASHMap Power-line mapping, topographic survey, urban mapping, flood mapping, etc. Multipulse airborne Lidar system with the highest PRF rate of 167kHz in the industry; global 24/7 technical support.\n",
      "{'source': 'LiDAR-Sensors.pdf', 'page': 3, 'page_label': '27', 'start_index': 2640}\n",
      ". T urnkey solution, additional sensors such as temperature, oblique or video available, cus - tomised housing possible, stable frame cam - era also for photogrammetric work,very easy to handle, no operator required. T opoSys GmbH Harrier 24 October 2005 > 10kg customised due to options 2 boxes, > 30kg total 28 V DC, 13 A max. 900nm < 10ns 2.7mrad Class 1 0m Rotating multi-facet mirror 6 - 80Hz / 5 - 60Hz 30,000 60 deg / 80 deg First or last or alternating N/A Center of gravity of echo pulse 8 bits Applanix POSAV 310 5 - 30cm Applanix POSAV 310 0.015/0.015/0.035 deg Applanix Pos/Pac INS precision 3cm 15cm N.A. 3 10 points 0,5 (@150m, 150km/h) 0,7m (@150m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 200GB UPS Helicopter (60°) 3/280/430 (80°) 3/250/380 > 8 hrs 0 to + 50°C 80% (at or below 31°C) TrackAir T opPIT Low-altitude corridor mapping and survey - ing for construction and engineering, snow, ice and glacier mapping, ortho and trueortho images. Entry level system, low-cost turnkey solu - tion, additional sensors such as tempera - ture, oblique or video available, customised housing possible, very easy to handle, no operator required.\n",
      "{'source': 'LiDAR-Sensors.pdf', 'page': 3, 'page_label': '27', 'start_index': 0}\n",
      "GIM International February 2007 Product survey T opEye T opEye Mk II January 2006 25kg 250kg 500 W 1,064nm 4 ns 1 mrad 3B 40m at low effect Plamer Scanner 0-75Hz 1-50,000 +/- 20 deg 14 deg BWD/FWD Unlimited 2 GigaSamples Full Waveform logic 10 bits Trimble 5700 L1/L2 Honeywell 764 < 0,005 deg POS GPS T opEye PP < 0.25 mrad 2 sigma 1cm - Range indepenent N/A Std Product 30 points N/A N/A Rollei AIC Removable HDD - RW Honeywell 764 60m / 300m / 750m 3 hrs -10°C to + 35°C Non-condensing T opEye MPS T opEye PP & TASQ Corridor, 3D City, PowerLines, etc. The Palmer scanner means that a Laser Echo is extracted from each ‘sub area’ twice with a 4-8 sec time difference by a single mechanical system and with full receiver apperture. T opoSys GmbH Falcon III February 2000/July 2006 > 20kg customised due to options 2 boxes, < 95kg total 28 V DC, 15 A max. 1,550nm 5 ns 0.7 mrad Class IM 0.27m Fibre scanner Up to 415Hz 50,000 - 125,000 28 deg fixed 8 or full waveform Analogue Rising edge detection or full wave form 8 bits Applanix POSAV 510 5 - 30cm Applanix POSAV 510 0.005/0.005/0.008 deg Applanix Pos/Pac INS precision 1cm 7cm 10cm 1 50 points 0,1 (@1000m, 150km/h) 0,3m (@1000m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 500GB UPS Both + high speed aircrafts 30m / 1,500m / 2,000m > 8 hrs -10°C to + 50°C Non-condensing, <95% TrackAir T opPIT All kinds of applications which require high point density and error free data, such as city models, corridor / river / coastal / flood plain / wide area / forest mapping, deposites and mining, contruction and engineering, ortho and true-ortho images. High-end system, turnkey solution, stable scanner geometry avoids any data error, no repetitive calibration required, extremely high survey speed possible > 400km/h, very long flight lines possible. T opoSys GmbH Harrier 56 October 2005/September 2006 > 15kg customised due to options 2 boxes, > 45kg total 28 V DC, 17 A max. 1,550nm < 4 ns 0.3 mrad with up to 1mrad option Class 1 0m Rotating multi-facet mirror 10 - 160Hz 25,000 - 200,000 45 deg. or 60 deg Practically unlimited 1GHz Full waveform processing of complete echo 16 bits Applanix POSAV 410 5 - 30cm Applanix POSAV 410 0.008/0.008/0.015 deg Applanix Pos/Pac INS precision 3cm 15cm 15cm 2 40 points 0,6 (@ 1000m, 150km/h) 0,6m (@ 1000m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 500GB UPS Both 30m / 800m /1,000m > 8 hrs 0° to + 40°C 80% (at or below 31°C) TrackAir T opPIT Corridor mapping such as pipelines or power-lines or motorways, construction and engineering, forest, city, target classification, ortho and true-ortho images\n",
      "{'page': 18, 'page_label': '19', 'source': 'sensors.pdf', 'start_index': -1}\n",
      ". Informed Consent Statement: Not applicable. Data Availability Statement: Data available on request due to privacy restrictions. The data presented in this study are available on request from the corresponding authors. The data are not publicly available due to company policies. Conﬂicts of Interest: The authors declare no conﬂict of interest. References 1. Driving, A. Levels of Driving Automation are Deﬁned in New SAE International Standard J3016: 2014; SAE International: Warrendale, PA, USA, 2014. 2. First Internationally Valid System Approval for Conditionally Automated Driving. Daimler. Available online: https: //www.daimler.com/innovation/product-innovation/autonomous-driving/system-approval-for-conditionally-automateddriving.html (accessed on 13 December 2021). 3. Roriz, R.; Cabral, J.; Gomes, T. Automotive LiDAR Technology: A Survey. IEEE Trans. Intell. Transp. Syst. 2022, 23, 6282–6297. doi: 10.1109/TITS.2021.3086804. [CrossRef] 4. Pendleton, S.D.; Andersen, H.; Du, X.; Shen, X.; Meghjani, M.; Eng, Y.H.; Rus, D.; Ang, M.H., Jr. Perception, planning, control, and coordination for autonomous vehicles. Machines 2017, 5, 6. [CrossRef]\n",
      "{'page': 13, 'page_label': '14', 'source': 'sensors.pdf', 'start_index': 0}\n",
      "Sensors 2022, 22, 7146 14 of 20 0 50 100 150 200 250 300 Distancetovehicle[m] -1 0 1 2 3 4 5 DeltabetweenGPSandmeasuredposition[m] MeasurementPoint OffsetRecreation (a) 0 50 100 150 200 250 300 Distancetovehicle[m] -1 0 1 2 3 4 5 DeltabetweenGPSandmeasuredposition[m] MeasurementPoint OffsetRecreation (b) 0 50 100 150 200 250 300 Distancetovehicle[m] -1 0 1 2 3 4 5 DeltabetweenGPSandmeasuredposition[m] MeasurementPoint OffsetRecreation (c) Figure 10. Results of Scenario 4. The difference between GPS and LiDAR measurement in relation to the distance is shown (a) Velodyne Velarray (1175 vehicle detections); (b) Robosense M1 (522 vehicle detections); (c) Livox Horizon (468 vehicle detections).\n",
      "{'page': 3, 'page_label': '4', 'source': 'sensors.pdf', 'start_index': -1}\n",
      ". • Update rate or frame rate. In order to avoid longer delays in the object detection, the sensor systems should have an update frequency or frame rate of more than 5 Hz. • ROS/ROS2 support. For an easy integration into our control software stack [6], a Linuxbased system implementation and an AD framework based on ROS2 is preferred. • Robustness of sensor systems. The test candidates should work well also in tougher weather conditions, and the sensor performance should not notably degrade under those conditions.\n",
      "{'source': 'LiDAR-Sensors.pdf', 'page': 1, 'page_label': '25', 'start_index': 2846}\n",
      ". Removable HDD Ground power supply Fixed-wing or helicopter 200 - 6,000m AGL ~17 hrs @ max pulse rate 0 - 40 °C cabin-side temperature Non-condensing Leica FPES Leica ALS Post Processor for point-cloud generation,T erraScan/T erraModeler for viewing/editing. DEMs, city models, flood plain, erosion & forestery studies, forest floor, disaster management, power-lines, pipe-line and railway and roadway corridors, coastal mapping. Full-function system for a wide variety of applications now features highly integrated FCMS flight-management system and flex - ible external sensor integration. Optech ALTM Gemini October 2006 23.4kg, 26 x 19 x 57cm 95kg, control rack size 65 x 59 x 49cm 28 VDC, 35 A (maximum) 1,060nm 7ns 0.8, 0.25, 0.15 1/e Class IV (FDA 21 CFR) 80 m + Oscillating Mirror 100Hz 167kHz 50 deg 4 ranges Leading edge 12 bits Trimble, 12 channel, dual-frequency 0.05cm POS 610, 200 Hz 0.0025/0.0025/0.005 deg POS PAC 0.0025/0.0025/0.005 deg 3cm < 10cm 1/11000 20 points - 100 Knots, 500m, 100Hz scan, +/- 10°, PRF = 167kHz. As above 0.25m As above 0.21m Applanix DSS, Rollei 39 Mpixel Removable hard disk, min 70 Gbytes Internal to the system T win engine fixed-wing, rotary wing 200m / 1km to 2km / 4km max; higher avail - able on request Unlimited -10°C to 35°C 0 to 95% non-condensing ALTM NAV DASHMap Power-line mapping, topographic survey, urban mapping, flood mapping, etc. Multipulse airborne Lidar system with the highest PRF rate of 167kHz in the industry; global 24/7 technical support.\n",
      "{'source': 'LiDAR-Sensors.pdf', 'page': 3, 'page_label': '27', 'start_index': 2640}\n",
      ". T urnkey solution, additional sensors such as temperature, oblique or video available, cus - tomised housing possible, stable frame cam - era also for photogrammetric work,very easy to handle, no operator required. T opoSys GmbH Harrier 24 October 2005 > 10kg customised due to options 2 boxes, > 30kg total 28 V DC, 13 A max. 900nm < 10ns 2.7mrad Class 1 0m Rotating multi-facet mirror 6 - 80Hz / 5 - 60Hz 30,000 60 deg / 80 deg First or last or alternating N/A Center of gravity of echo pulse 8 bits Applanix POSAV 310 5 - 30cm Applanix POSAV 310 0.015/0.015/0.035 deg Applanix Pos/Pac INS precision 3cm 15cm N.A. 3 10 points 0,5 (@150m, 150km/h) 0,7m (@150m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 200GB UPS Helicopter (60°) 3/280/430 (80°) 3/250/380 > 8 hrs 0 to + 50°C 80% (at or below 31°C) TrackAir T opPIT Low-altitude corridor mapping and survey - ing for construction and engineering, snow, ice and glacier mapping, ortho and trueortho images. Entry level system, low-cost turnkey solu - tion, additional sensors such as tempera - ture, oblique or video available, customised housing possible, very easy to handle, no operator required.\n",
      "{'source': 'LiDAR-Sensors.pdf', 'page': 3, 'page_label': '27', 'start_index': 0}\n",
      "GIM International February 2007 Product survey T opEye T opEye Mk II January 2006 25kg 250kg 500 W 1,064nm 4 ns 1 mrad 3B 40m at low effect Plamer Scanner 0-75Hz 1-50,000 +/- 20 deg 14 deg BWD/FWD Unlimited 2 GigaSamples Full Waveform logic 10 bits Trimble 5700 L1/L2 Honeywell 764 < 0,005 deg POS GPS T opEye PP < 0.25 mrad 2 sigma 1cm - Range indepenent N/A Std Product 30 points N/A N/A Rollei AIC Removable HDD - RW Honeywell 764 60m / 300m / 750m 3 hrs -10°C to + 35°C Non-condensing T opEye MPS T opEye PP & TASQ Corridor, 3D City, PowerLines, etc. The Palmer scanner means that a Laser Echo is extracted from each ‘sub area’ twice with a 4-8 sec time difference by a single mechanical system and with full receiver apperture. T opoSys GmbH Falcon III February 2000/July 2006 > 20kg customised due to options 2 boxes, < 95kg total 28 V DC, 15 A max. 1,550nm 5 ns 0.7 mrad Class IM 0.27m Fibre scanner Up to 415Hz 50,000 - 125,000 28 deg fixed 8 or full waveform Analogue Rising edge detection or full wave form 8 bits Applanix POSAV 510 5 - 30cm Applanix POSAV 510 0.005/0.005/0.008 deg Applanix Pos/Pac INS precision 1cm 7cm 10cm 1 50 points 0,1 (@1000m, 150km/h) 0,3m (@1000m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 500GB UPS Both + high speed aircrafts 30m / 1,500m / 2,000m > 8 hrs -10°C to + 50°C Non-condensing, <95% TrackAir T opPIT All kinds of applications which require high point density and error free data, such as city models, corridor / river / coastal / flood plain / wide area / forest mapping, deposites and mining, contruction and engineering, ortho and true-ortho images. High-end system, turnkey solution, stable scanner geometry avoids any data error, no repetitive calibration required, extremely high survey speed possible > 400km/h, very long flight lines possible. T opoSys GmbH Harrier 56 October 2005/September 2006 > 15kg customised due to options 2 boxes, > 45kg total 28 V DC, 17 A max. 1,550nm < 4 ns 0.3 mrad with up to 1mrad option Class 1 0m Rotating multi-facet mirror 10 - 160Hz 25,000 - 200,000 45 deg. or 60 deg Practically unlimited 1GHz Full waveform processing of complete echo 16 bits Applanix POSAV 410 5 - 30cm Applanix POSAV 410 0.008/0.008/0.015 deg Applanix Pos/Pac INS precision 3cm 15cm 15cm 2 40 points 0,6 (@ 1000m, 150km/h) 0,6m (@ 1000m, 150km/h) RGB/CIR line scanner or frame cameras Removeable disc, 500GB UPS Both 30m / 800m /1,000m > 8 hrs 0° to + 40°C 80% (at or below 31°C) TrackAir T opPIT Corridor mapping such as pipelines or power-lines or motorways, construction and engineering, forest, city, target classification, ortho and true-ortho images\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: Entity-Focused Retrieval\n",
    "entity_query = \"\"\"\n",
    "EXTRACT: LiDAR sensors, their components, technical specifications.\n",
    "IGNORE: Experimental results, methodology, figures.\n",
    "\"\"\"\n",
    "entity_docs = retriever.get_relevant_documents(entity_query)\n",
    "\n",
    "# Stage 2: Relationship Extraction\n",
    "relation_query = \"\"\"\n",
    "FIND: has_part, implements, measurement_properties relationships.\n",
    "FILTER: Only technical specifications sections.\n",
    "\"\"\"\n",
    "relation_docs = retriever.get_relevant_documents(relation_query)\n",
    "# Combine and deduplicate\n",
    "final_docs = entity_docs + relation_docs\n",
    "retrieved_text = \"\\n\\n\".join([doc.page_content for doc in final_docs])\n",
    "\n",
    "for doc in final_docs:\n",
    "    print(doc.metadata)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.chat_models import ChatOllama\n",
    "# Initialize with your local model\n",
    "llm = ChatOllama(model=MODEL) \n",
    "compressor = LLMChainExtractor.from_llm(llm=llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever,\n",
    "    search_kwargs={\"k\": 10}  \n",
    ")\n",
    "\n",
    "# Enhanced query\n",
    "compressed_docs = compression_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KG_EXTRACTION_PROMPT = \"\"\"As a LiDAR sensor expert, analyze this technical text to extract:\n",
    "\n",
    "# **Target Entities**:\n",
    "# 1. Sensor Models: Manufacturer-branded names (Velodyne HDL-64E, Livox Horizon)\n",
    "# 2. Components: Physical/software parts (e.g., MEMS mirror, FPGA processor)\n",
    "# 3. Technical Specs: Quantified values with units (120m range, 0.08° resolution)\n",
    "# 4. Implementations: Standards/protocols (IEEE 802.11p, ROS2)\n",
    "\n",
    "# **Extraction Rules**:\n",
    "# - Preserve contextual relationships: \n",
    "#   \"The Velodyne VLP-32C's rotating assembly enables 360° coverage\" → \n",
    "#   {{\"parts\": [\"rotating assembly\"], \"properties\": [\"field of view: 360°\"]}}\n",
    "# - Capture implied properties from comparisons:\n",
    "#   \"Outperforms Ouster OS2 in range\" → \n",
    "#   {{\"properties\": [\"comparative_range: > Ouster OS2\"]}}\n",
    "# - Retain partial information with \"[INFERRED]\" tags\n",
    "\n",
    "# **Enhanced Format**:\n",
    "# ```json\n",
    "# {{\n",
    "#   \"sensors\": [\n",
    "#     {{\n",
    "#       \"name\": \"Livox Horizon\",\n",
    "#       \"category\": \"Automotive Lidar\",\n",
    "#       \"parts\": [\"MEMS mirror\", \"905nm laser array\"],\n",
    "#       \"properties\": [\n",
    "#         \"horizontal_fov: 81.7°\", \n",
    "#         \"range: 260m @ 10% reflectivity\",\n",
    "#         \"scan_pattern: non-repetitive\"\n",
    "#       ],\n",
    "#       \"implements\": [\"ROS2\", \"AutoSAR\"]\n",
    "#     }}\n",
    "#   ]\n",
    "# }}\n",
    "# ```\n",
    "# <text>\n",
    "# {text}\n",
    "# <text>\n",
    "# \"\"\"\n",
    "KG_EXTRACTION_PROMPT=\"\"\"\n",
    "As a LiDAR sensor expert, analyze this technical text to extract:\n",
    "\n",
    "**Target Entities**:\n",
    "1. Sensor Models: Manufacturer-branded names (Velodyne HDL-64E, Livox Horizon)\n",
    "2. Components: Physical/software parts (e.g., MEMS mirror, FPGA processor)\n",
    "3. Technical Specs: Quantified values with units (120m range, 0.08° resolution)\n",
    "4. Implementations: Standards/protocols (IEEE 802.11p, ROS2)\n",
    "\n",
    "**Extraction Rules**:\n",
    "- Preserve contextual relationships: \n",
    "  \"The Velodyne VLP-32C's rotating assembly enables 360° coverage\" → \n",
    "  {{\"parts\": [\"rotating assembly\"], \"properties\": [\"field of view: 360°\"]}}\n",
    "- Capture implied properties from comparisons:\n",
    "  \"Outperforms Ouster OS2 in range\" → \n",
    "  {{\"properties\": [\"comparative_range: > Ouster OS2\"]}}\n",
    "- Retain partial information with \"[INFERRED]\" tags\n",
    "\n",
    "\n",
    "**Enhanced Format**:\n",
    "```json\n",
    "{{\n",
    "  \"sensors\": [\n",
    "    {{\n",
    "      \"name\": \"Livox Horizon\",\n",
    "      \"category\": \"Automotive Lidar\",\n",
    "      \"parts\": [\"MEMS mirror\", \"905nm laser array\"],\n",
    "      \"properties\": [\n",
    "        \"horizontal_fov: 81.7°\", \n",
    "        \"range: 260m @ 10% reflectivity\",\n",
    "        \"scan_pattern: non-repetitive\"\n",
    "      ],\n",
    "      \"implements\": [\"ROS2\", \"AutoSAR\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "**Critical Instructions**:\n",
    "1. If no sensors are found, return: {\"sensors\": []}\n",
    "2. Always maintain valid JSON structure\n",
    "3. Never add extra text outside the JSON\n",
    "4. Use exact values from tables when available\n",
    "\n",
    "<example>\n",
    "Input: \"The Velodyne VLP-32C has a 200m range and 0.2° resolution\"\n",
    "Output:\n",
    "{{\n",
    "  \"sensors\": [\n",
    "    {{\n",
    "      \"name\": \"Velodyne VLP-32C\",\n",
    "      \"category\": \"Automotive LiDAR\",\n",
    "      \"parts\": [],\n",
    "      \"properties\": [\"range: 200m\", \"resolution: 0.2°\"],\n",
    "      \"implements\": []\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "</example>\n",
    "\n",
    "\n",
    "<text>\n",
    "{text}\n",
    "<text>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormat(Enum):\n",
    "    JSON = \"json_object\"\n",
    "    TEXT = \"text\"\n",
    " \n",
    " \n",
    "def call_model(\n",
    "    prompt: str, response_format: ResponseFormat = ResponseFormat.TEXT\n",
    ") -> str:\n",
    "    response = ollama.generate(\n",
    "        model=MODEL,\n",
    "        prompt=prompt,\n",
    "        keep_alive=\"1h\",\n",
    "        format=\"\" if response_format == ResponseFormat.TEXT else \"json\",\n",
    "    )\n",
    "    return response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'\"sensors\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(retrieved_text)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks):\n\u001b[1;32m----> 9\u001b[0m         final_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mKG_EXTRACTION_PROMPT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m# Send the final prompt to Ollama\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         response \u001b[38;5;241m=\u001b[39m call_model(final_prompt)\n",
      "\u001b[1;31mKeyError\u001b[0m: '\"sensors\"'"
     ]
    }
   ],
   "source": [
    "# Prepare the final prompt with the concatenated text\n",
    "\n",
    "responses = []\n",
    "\n",
    "# chunks = [retrieved_text[i:i + CHUNK_SIZE] for i in range(0, len(retrieved_text), CHUNK_SIZE)];\n",
    "chunks = text_splitter.split_text(retrieved_text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "        final_prompt = KG_EXTRACTION_PROMPT.format(text=chunk)\n",
    "        # Send the final prompt to Ollama\n",
    "        response = call_model(final_prompt)\n",
    "        responses.append(response)\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save responses after every chunk to ensure progress is retained\n",
    "with open(\"R1_responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 11 unique sensors.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def extract_json_part(response_str):\n",
    "    \"\"\"Extracts JSON content from Ollama's response string\"\"\"\n",
    "    try:\n",
    "        # Get first element of response list\n",
    "        if isinstance(response_str, list):\n",
    "            content = response_str[0]\n",
    "        else:\n",
    "            content = response_str\n",
    "            \n",
    "        # Extract JSON block\n",
    "        json_str = content.split(\"```json\")[-1].split(\"```\")[0].strip()\n",
    "        return json.loads(json_str)\n",
    "    except (IndexError, json.JSONDecodeError) as e:\n",
    "        print(f\"Failed to extract JSON: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def clean_string(s):\n",
    "    \"\"\"Enhanced cleaning/normalization\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return str(s).lower()\n",
    "        \n",
    "    # s = unicodedata.normalize('NFKC', s)\n",
    "    # s = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', s)  # Remove control chars\n",
    "    # s = re.sub(r'[_\\-\\n]+', ' ', s)  # Replace separators with space\n",
    "    # s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s.lower()\n",
    "\n",
    "# Load responses\n",
    "with open(\"R1_responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    responses = json.load(f)\n",
    "\n",
    "final_sensors = []\n",
    "seen_sensors = set()\n",
    "\n",
    "for response in responses:\n",
    "    try:\n",
    "        # Extract JSON from Ollama response format\n",
    "        response_json = extract_json_part(response)\n",
    "        if not response_json:\n",
    "            continue\n",
    "\n",
    "        # Process sensors with validation\n",
    "        sensors = response_json.get(\"sensors\", [])\n",
    "        if not isinstance(sensors, list):\n",
    "            continue\n",
    "            \n",
    "        for sensor in sensors:\n",
    "            # Validate required fields\n",
    "            if \"name\" not in sensor:\n",
    "                continue\n",
    "                \n",
    "            # Clean and normalize\n",
    "            sensor_name = clean_string(sensor[\"name\"])\n",
    "            category_name = clean_string(sensor.get(\"category\", \"uncategorized\"))\n",
    "            \n",
    "            # Process lists with null checks\n",
    "            parts = [clean_string(p) for p in sensor.get(\"parts\", []) if p]\n",
    "            properties = [clean_string(p) for p in sensor.get(\"properties\", []) if p]\n",
    "            implements = [clean_string(i) for i in sensor.get(\"implements\", []) if i]\n",
    "\n",
    "            # Create unique identifier\n",
    "            sensor_id = hash((\n",
    "                sensor_name, \n",
    "                category_name,\n",
    "                tuple(sorted(parts)),\n",
    "                tuple(sorted(properties)),\n",
    "                tuple(sorted(implements))\n",
    "            ))\n",
    "\n",
    "            if sensor_id not in seen_sensors:\n",
    "                seen_sensors.add(sensor_id)\n",
    "                final_sensors.append({\n",
    "                    \"name\": sensor_name,\n",
    "                    \"category\": category_name,\n",
    "                    \"parts\": sorted(parts),\n",
    "                    \"properties\": sorted(properties),\n",
    "                    \"implements\": sorted(implements)\n",
    "                })\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing entry: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Save results\n",
    "with open(\"R1_sensors_merged.json\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "    json.dump({\"sensors\": final_sensors}, out_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Processed {len(final_sensors)} unique sensors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology created and saved as sensor_ontology_with_properties_and_implements.owl\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"R1_sensors_merged.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a new ontology\n",
    "onto = get_ontology(\"http://example.org/sensor_ontology.owl\")\n",
    "\n",
    "with onto:\n",
    "    # Define basic classes and properties\n",
    "    class Sensor(Thing):\n",
    "        pass\n",
    "    \n",
    "    class Part(Thing):\n",
    "        pass\n",
    "    \n",
    "    class Property(Thing):\n",
    "        pass\n",
    "    \n",
    "    class Technology(Thing):\n",
    "        pass\n",
    "\n",
    "    class has_part_directly(ObjectProperty):\n",
    "        domain = [Sensor]\n",
    "        range = [Part]\n",
    "    \n",
    "    class implements(ObjectProperty):\n",
    "        domain = [Sensor]\n",
    "        range = [Technology]\n",
    "    \n",
    "    class has_property(ObjectProperty):\n",
    "        domain = [Sensor]\n",
    "        range = [Property]\n",
    "\n",
    "    # Define an annotation property for category\n",
    "    class category(AnnotationProperty):\n",
    "        pass\n",
    "\n",
    "    # Process the JSON data\n",
    "    part_classes = {}  # Cache for part classes to avoid duplicates\n",
    "    property_classes = {}  # Cache for property classes\n",
    "    technology_classes = {}  # Cache for technology classes\n",
    "\n",
    "    for sensor_data in data[\"sensors\"]:\n",
    "        # Create or get the sensor class\n",
    "        sensor_name = sensor_data[\"name\"].replace(\" \", \"_\")\n",
    "        sensor_category = sensor_data[\"category\"].replace(\" \", \"_\")\n",
    "        \n",
    "        # Define the sensor class dynamically\n",
    "        sensor_class = types.new_class(sensor_name, (Sensor,))\n",
    "        \n",
    "        # Assign category as an annotation\n",
    "        sensor_class.category.append(sensor_category)\n",
    "\n",
    "        # Add parts and relationships\n",
    "        for part_name in sensor_data[\"parts\"]:\n",
    "            part_name_cleaned = part_name.replace(\" \", \"_\")\n",
    "            if part_name_cleaned not in part_classes:\n",
    "                part_class = types.new_class(part_name_cleaned, (Part,))\n",
    "                part_classes[part_name_cleaned] = part_class\n",
    "            else:\n",
    "                part_class = part_classes[part_name_cleaned]\n",
    "\n",
    "            # Create the relationship\n",
    "            sensor_class.is_a.append(has_part_directly.some(part_class))\n",
    "\n",
    "        # Add properties and relationships\n",
    "        for property_name in sensor_data[\"properties\"]:\n",
    "            property_name_cleaned = property_name.replace(\" \", \"_\")\n",
    "            if property_name_cleaned not in property_classes:\n",
    "                property_class = types.new_class(property_name_cleaned, (Property,))\n",
    "                property_classes[property_name_cleaned] = property_class\n",
    "            else:\n",
    "                property_class = property_classes[property_name_cleaned]\n",
    "\n",
    "            # Create the relationship\n",
    "            sensor_class.is_a.append(has_property.some(property_class))\n",
    "\n",
    "        # Add technologies (implements relationship)\n",
    "        for tech_name in sensor_data[\"implements\"]:\n",
    "            tech_name_cleaned = tech_name.replace(\" \", \"_\")\n",
    "            if tech_name_cleaned not in technology_classes:\n",
    "                tech_class = types.new_class(tech_name_cleaned, (Technology,))\n",
    "                technology_classes[tech_name_cleaned] = tech_class\n",
    "            else:\n",
    "                tech_class = technology_classes[tech_name_cleaned]\n",
    "\n",
    "            # Create the relationship\n",
    "            sensor_class.is_a.append(implements.some(tech_class))\n",
    "\n",
    "# Save the ontology to a file\n",
    "onto.save(file=\"R1_sensor_ontology_with_properties_and_implements.owl\", format=\"rdfxml\")\n",
    "\n",
    "print(\"Ontology created and saved as sensor_ontology_with_properties_and_implements.owl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
