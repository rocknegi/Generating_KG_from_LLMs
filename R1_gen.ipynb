{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq pip --progress-bar off\n",
    "%pip install -qqq ollama --progress-bar off\n",
    "%pip install -qqq pathlib --progress-bar off\n",
    "%pip install -qqq pandas --progress-bar off\n",
    "%pip install -qqq pdfplumber --progress-bar off\n",
    "%pip install -qqq owlready2 --progress-bar off\n",
    "%pip install -qqq rdflib --progress-bar off\n",
    "%pip install -qqq langchain-ollama --progress-bar off\n",
    "%pip install -qqq langchain-community --progress-bar off\n",
    "%pip install -qqq langchain_community --progress-bar off\n",
    "%pip install -qqq langchain-chroma --progress-bar off\n",
    "%pip install -qqq pdfplumber --progress-bar off\n",
    "%pip install -qqq rank_bm25  --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pdfplumber\n",
    "from typing import List, Dict\n",
    "from ollama import Client\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. PDF Processing Layer\n",
    "# ---------------------------\n",
    "\n",
    "def extract_text_with_tables(pdf_path: str) -> List[Dict]:\n",
    "    \"\"\"Enhanced PDF extraction preserving tables and structure\"\"\"\n",
    "    text_chunks = []\n",
    "    current_section = \"\"\n",
    "    current_section_header = \"Document Header\"  # Initialize with default\n",
    "    TABLE_START = \"<<<TABLE>>>\"\n",
    "    TABLE_END = \"<</TABLE>>>\"\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_number, page in enumerate(pdf.pages, 1):\n",
    "            text = page.extract_text() or \"\"\n",
    "            tables = page.extract_tables()\n",
    "            \n",
    "            # Process tables\n",
    "            table_text = \"\"\n",
    "            for table in tables:\n",
    "                for row in table:\n",
    "                    table_text += \"| \" + \" | \".join(str(cell) for cell in row) + \" |\\n\"\n",
    "                table_text += \"\\n\"\n",
    "            \n",
    "            # Detect section headers\n",
    "            section_match = re.search(r'\\n(\\d+\\.\\s+[A-Z][a-z]+(?: [A-Z][a-z]+)*)\\n', text)\n",
    "            if section_match:\n",
    "                if current_section:\n",
    "                    text_chunks.append({\n",
    "                        \"content\": current_section.strip(),\n",
    "                        \"metadata\": {\n",
    "                            \"page\": page_number,\n",
    "                            \"section\": current_section_header\n",
    "                        }\n",
    "                    })\n",
    "                current_section_header = section_match.group(1)\n",
    "                current_section = \"\"\n",
    "            \n",
    "            # Build content\n",
    "            page_content = f\"{text}\\n{TABLE_START}\\n{table_text}{TABLE_END}\"\n",
    "            current_section += f\"\\n{page_content}\"\n",
    "            \n",
    "        # Add remaining content\n",
    "        if current_section:\n",
    "            text_chunks.append({\n",
    "                \"content\": current_section.strip(),\n",
    "                \"metadata\": {\n",
    "                    \"page\": page_number,\n",
    "                    \"section\": current_section_header\n",
    "                }\n",
    "            })\n",
    "            \n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2. Chunk Processing Engine\n",
    "# ---------------------------\n",
    "\n",
    "class LidarProcessor:\n",
    "    def __init__(self, model_name=\"deepseek-r1:8b-llama-distill-q8_0\"):\n",
    "        self.client = Client(host='http://localhost:11434')\n",
    "        self.model = model_name\n",
    "        self.extraction_prompt = \"\"\"As a LiDAR sensor expert, analyze this technical text to extract:\n",
    "\n",
    "**Target Entities**:\n",
    "1. Sensor Models: Manufacturer-branded names (Velodyne HDL-64E, Livox Horizon)\n",
    "2. Components: Physical/software parts (e.g., MEMS mirror, FPGA processor)\n",
    "3. Technical Specs: Quantified values with units (120m range, 0.08° resolution)\n",
    "4. Implementations: Standards/protocols (IEEE 802.11p, ROS2)\n",
    "\n",
    "**Extraction Rules**:\n",
    "- Preserve contextual relationships: \n",
    "  \"The Velodyne VLP-32C's rotating assembly enables 360° coverage\" → \n",
    "  {{\"parts\": [\"rotating assembly\"], \"properties\": [\"field of view: 360°\"]}}\n",
    "- Capture implied properties from comparisons:\n",
    "  \"Outperforms Ouster OS2 in range\" → \n",
    "  {{\"properties\": [\"comparative_range: > Ouster OS2\"]}}\n",
    "- Retain partial information with \"[INFERRED]\" tags\n",
    "\n",
    "\n",
    "**Enhanced Format**:\n",
    "```json\n",
    "{{\n",
    "  \"sensors\": [\n",
    "    {{\n",
    "      \"name\": \"Livox Horizon\",\n",
    "      \"category\": \"Automotive Lidar\",\n",
    "      \"parts\": [\"MEMS mirror\", \"905nm laser array\"],\n",
    "      \"properties\": [\n",
    "        \"horizontal_fov: 81.7°\", \n",
    "        \"range: 260m @ 10% reflectivity\",\n",
    "        \"scan_pattern: non-repetitive\"\n",
    "      ],\n",
    "      \"implements\": [\"ROS2\", \"AutoSAR\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "**Critical Instructions**:\n",
    "1. If no sensors are found, return: {{\"sensors\": []}}\n",
    "2. Always maintain valid JSON structure\n",
    "3. Never add extra text outside the JSON\n",
    "4. Use exact values from tables when available\n",
    "\n",
    "<example>\n",
    "Input: \"The Velodyne VLP-32C has a 200m range and 0.2° resolution\"\n",
    "Output:\n",
    "{{\n",
    "  \"sensors\": [\n",
    "    {{\n",
    "      \"name\": \"Velodyne VLP-32C\",\n",
    "      \"category\": \"Automotive LiDAR\",\n",
    "      \"parts\": [],\n",
    "      \"properties\": [\"range: 200m\", \"resolution: 0.2°\"],\n",
    "      \"implements\": []\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "</example>\n",
    "\n",
    "\n",
    "<text>\n",
    "{text}\n",
    "<text>\n",
    "\"\"\"\n",
    "\n",
    "    def process_chunk(self, text: str) -> List[Dict]:\n",
    "        \"\"\"Execute LLM extraction with error handling\"\"\"\n",
    "        try:\n",
    "            response = self.client.generate(\n",
    "                model=self.model,\n",
    "                prompt=f\"{self.extraction_prompt}{text}\",\n",
    "                format=\"json\",\n",
    "                options={\n",
    "                    \"temperature\": 0,\n",
    "                    \"top_p\": 0.5,\n",
    "                    \"num_ctx\": 4096,\n",
    "                    \"num_predict\": 1024 \n",
    "                }\n",
    "            )\n",
    "            # Handle empty responses\n",
    "            raw_response = response.get('response', '{}').strip()\n",
    "            if not raw_response or raw_response.count('{') == 0:\n",
    "                print(f\"Empty response for chunk: {text[:50]}...\")\n",
    "                return []\n",
    "            # Add JSON validation\n",
    "            try:\n",
    "                parsed = json.loads(raw_response)\n",
    "                if \"sensors\" not in parsed:\n",
    "                    print(f\"Missing 'sensors' key in response: {raw_response}\")\n",
    "                    return []\n",
    "                    \n",
    "                if not isinstance(parsed[\"sensors\"], list):\n",
    "                    print(f\"Invalid sensors format: {type(parsed['sensors'])}\")\n",
    "                    return []\n",
    "                    \n",
    "                return parsed[\"sensors\"]\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Failed to parse JSON: {e}\\nRaw response: {raw_response}\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "          print(f\"Unexpected error: {str(e)}\")\n",
    "          return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3. Knowledge Fusion System\n",
    "# ---------------------------\n",
    "\n",
    "class KnowledgeMerger:\n",
    "    def __init__(self):\n",
    "        self.sensor_map = defaultdict(lambda: {\n",
    "            \"parts\": set(),\n",
    "            \"properties\": set(),\n",
    "            \"implements\": set(),\n",
    "            \"categories\": set()\n",
    "        })\n",
    "\n",
    "    def add_sensor(self, sensor: Dict):\n",
    "        key = sensor['name'].lower().strip()\n",
    "        entry = self.sensor_map[key]\n",
    "        \n",
    "        # Merge properties\n",
    "        entry['name'] = sensor['name']\n",
    "        entry['parts'].update(sensor.get('parts', []))\n",
    "        entry['properties'].update(sensor.get('properties', []))\n",
    "        entry['implements'].update(sensor.get('implements', []))\n",
    "        entry['categories'].add(sensor.get('category', 'Uncategorized'))\n",
    "\n",
    "    def finalize(self) -> List[Dict]:\n",
    "        \"\"\"Convert merged data to final format\"\"\"\n",
    "        return [{\n",
    "            \"name\": v['name'],\n",
    "            \"categories\": list(v['categories']),\n",
    "            \"parts\": sorted(v['parts']),\n",
    "            \"properties\": sorted(v['properties']),\n",
    "            \"implements\": sorted(v['implements'])\n",
    "        } for v in self.sensor_map.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4. Execution Pipeline\n",
    "# ---------------------------\n",
    "\n",
    "def process_pdf_to_kg(pdf_path: str) -> List[Dict]:\n",
    "    # 1. Extract structured content\n",
    "    chunks = extract_text_with_tables(pdf_path)\n",
    "\n",
    "    # 2. Initialize processors\n",
    "    processor = LidarProcessor()\n",
    "    merger = KnowledgeMerger()\n",
    "    \n",
    "    # 3. Process each chunk\n",
    "    for chunk in chunks:\n",
    "        sensors = processor.process_chunk(chunk['content'])\n",
    "        for sensor in sensors:\n",
    "            merger.add_sensor(sensor)\n",
    "    \n",
    "    # 4. Post-process and validate\n",
    "    return merger.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 'sensors' key in response: {\n",
      "\"LiDAR sensors are widely used in agriculture for various applications such as crop classification, inspection of crop viability, crop mapping, cloud profiling, collision avoidance, obstacle detection in autonomous traveling, and soil resource conservation. They also play a significant role in agricultural field machinery, object detection, and high-throughput crop phenotyping.\"\n",
      "\n",
      ": \"LiDAR sensors are widely used in agriculture for various applications such as crop classification, inspection of crop viability, crop mapping, cloud profiling, collision avoidance, obstacle detection in autonomous traveling, and soil resource conservation. They also play a significant role in agricultural field machinery, object detection, and high-throughput crop phenotyping.\"\n",
      "\n",
      "}\n",
      "Missing 'sensors' key in response: {\n",
      "\"abstract\": {\n",
      "  \"en\": \"This paper presents a review of recent advancements in LiDAR technology for agricultural applications, focusing on its use in crop monitoring and field mapping. The study highlights the effectiveness of LiDAR in various agricultural settings, including farmland, forests, orchards, vineyards, and urban green spaces. It also discusses the challenges faced by LiDAR sensors in these environments, such as varying terrain, dynamic obstacles, and environmental factors like sunlight, moisture, and dust. Additionally, the paper reviews testing procedures for LiDAR performance in agricultural applications, emphasizing the importance of standardized protocols to ensure reliability and accuracy.\"\n",
      "},\n",
      "\"keywords\": [\n",
      "  \"LiDAR technology\",\n",
      "  \"agricultural applications\",\n",
      "  \"crop monitoring\",\n",
      "  \"field mapping\",\n",
      "  \"testing procedures\"\n",
      "],\n",
      "\"title\": {\n",
      "  \"en\": \"Advancements in LiDAR Technology for Agricultural Applications: A Review\"\n",
      "}\n",
      "}\n",
      "Missing 'sensors' key in response: {}\n"
     ]
    }
   ],
   "source": [
    "results = process_pdf_to_kg(\"remotesensing-16-04623.pdf\")\n",
    "    \n",
    "with open(\"lidar_kg.json\", \"w\") as f:\n",
    "    json.dump({\"sensors\": results}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def normalize_properties(properties: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"Generic property normalization and deduplication\"\"\"\n",
    "    prop_map = {}\n",
    "    \n",
    "    for prop in properties:\n",
    "        try:\n",
    "            # 1. Normalize Unicode characters\n",
    "            normalized = unicodedata.normalize('NFKC', prop)\n",
    "            \n",
    "            # 2. Split into key/value (case-insensitive)\n",
    "            key, value = re.split(r\":\\s*\", normalized, 1)\n",
    "            key = key.strip().lower()\n",
    "            \n",
    "            # 3. Standardize units and values\n",
    "            value = re.sub(r'(\\d+)\\s*(m|meters?)\\b', r'\\1m', value)  # Range\n",
    "            value = re.sub(r'(\\d+)\\s*degrees?', r'\\1°', value)       # Angles\n",
    "            value = re.sub(r'\\u00b0', '°', value)                    # Degree symbol\n",
    "            \n",
    "            # 4. Conflict resolution (keep last occurrence)\n",
    "            prop_map[key] = value\n",
    "            \n",
    "        except ValueError:\n",
    "            continue  # Skip malformed properties\n",
    "\n",
    "    # 5. Deduplicate and format\n",
    "    return {k: v for k, v in prop_map.items()}\n",
    "\n",
    "def clean_sensor_data(sensors: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Process sensor data generically\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"name\": sensor[\"name\"],\n",
    "            \"category\": sensor[\"categories\"][0] if sensor[\"categories\"] else \"Other\",\n",
    "            \"specifications\": normalize_properties(sensor[\"properties\"]),\n",
    "            \"components\": list(set(sensor[\"parts\"])),\n",
    "            \"interfaces\": list(set(sensor[\"implements\"]))\n",
    "        }\n",
    "        for sensor in sensors\n",
    "    ]\n",
    "\n",
    "# Usage example\n",
    "with open(\"lidar_kg.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "cleaned_data = clean_sensor_data(data[\"sensors\"])\n",
    "\n",
    "with open(\"cleaned_output.json\", \"w\") as f:\n",
    "    json.dump({\"sensors\": cleaned_data}, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
