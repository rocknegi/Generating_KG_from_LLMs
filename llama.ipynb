{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq pip --progress-bar off\n",
    "%pip install -qqq ollama --progress-bar off\n",
    "%pip install -qqq pathlib --progress-bar off\n",
    "%pip install -qqq pandas --progress-bar off\n",
    "%pip install -qqq PyPDF2 --progress-bar off\n",
    "%pip install -qqq owlready2 --progress-bar off\n",
    "%pip install -qqq rdflib --progress-bar off\n",
    "%pip install -qqq langchain-ollama --progress-bar off\n",
    "%pip install -qqq langchain-community --progress-bar off\n",
    "%pip install -qqq langchain_community pypdf --progress-bar off\n",
    "%pip install -qqq langchain-chroma --progress-bar off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the imports\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import ollama\n",
    "import json\n",
    "from enum import Enum\n",
    "MODEL = \"llama3.1:8b-instruct-q8_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF\n",
    "pdf_loader = PyPDFLoader(file_path=\"sensors.pdf\")\n",
    "docs = pdf_loader.load();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average words per document: 438.2\n",
      "Average characters per document: 2702.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate Average Document Size\n",
    "def word_count(texts):\n",
    "  total_words = 0\n",
    "  total_characters = 0\n",
    "\n",
    "  for doc in texts:\n",
    "      content = doc.page_content\n",
    "      word_count = len(content.split())  # Count words\n",
    "      char_count = len(content)         # Count characters\n",
    "      total_words += word_count\n",
    "      total_characters += char_count\n",
    "\n",
    "  num_docs = len(texts)\n",
    "  avg_words = total_words / num_docs if num_docs > 0 else 0\n",
    "  avg_characters = total_characters / num_docs if num_docs > 0 else 0\n",
    "\n",
    "  print(f\"Average words per document: {avg_words}\")\n",
    "  print(f\"Average characters per document: {avg_characters}\")\n",
    "\n",
    "word_count(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average words per document: 136.78666666666666\n",
      "Average characters per document: 843.32\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "word_count(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5f69798c-8746-430b-9a41-12de8b4b26c6',\n",
       " '3af57f9e-c00c-47f3-b5f3-295534308b32',\n",
       " 'be6d821c-7b33-4195-8fe4-7c0348aed782',\n",
       " '0995a062-6530-4a5c-ad4a-d8e03e81bf6d',\n",
       " 'fed973ba-b1da-4adc-98b1-e2639a357c3f',\n",
       " 'b00e2fc4-e7b3-438c-bfcc-ce0588c117f6',\n",
       " '7e9766f6-c147-4af7-9c3f-d5c4f1317afd',\n",
       " '35a7ccb8-283a-4774-b29f-f5d49abbaded',\n",
       " 'c627c17a-3f91-4c25-b592-bf1c23dfc22f',\n",
       " '113ffd49-79a4-4ef4-b9a4-6d61f395856e',\n",
       " '949d4b4f-f26a-43c3-9a16-1398c2fa27d6',\n",
       " 'a2189861-fe33-4a06-9bca-1f6a99b05f92',\n",
       " '8da8fda0-bfe5-4137-a869-0573c34b252b',\n",
       " 'b11e36b4-494c-4b28-8e2e-924d09bf6f0d',\n",
       " '862179f6-46d4-4a1c-93b6-3ab40a5cf266',\n",
       " '270b982d-805b-449b-a0b8-8d7cd999f5a9',\n",
       " '6c8d581a-cea5-412f-9921-046e488c00e1',\n",
       " '33a6425f-65eb-4f7c-9c26-4c208a21208a',\n",
       " '2f54bf12-8d03-40e0-bed4-5c739afd514b',\n",
       " 'ce053794-840e-48ca-aa1a-14ea37a730a9',\n",
       " '47e7b000-081b-4bfc-a84f-2bafb74ce882',\n",
       " 'b8602ad4-fa50-4daa-8464-9e668f84a0e7',\n",
       " '26cc7b74-3870-4241-8119-b91d49975e5b',\n",
       " 'c1b07ad7-8d5f-491e-a1f8-eac119efea8f',\n",
       " '333b5e69-3e95-4a32-b772-d949567f8047',\n",
       " 'fe856bec-ab5f-471f-8207-f015a2d981aa',\n",
       " 'd27b56e6-19c2-4131-8238-b217985a1319',\n",
       " 'e0c667a2-0d1a-4019-94b5-d163f8a009be',\n",
       " '1dab7bc9-f125-4e34-80de-9c2afd74106a',\n",
       " 'b2d4635a-1765-46c1-accd-dd33f18fc969',\n",
       " '84491295-a5f4-448b-83d7-d2da2c0392cc',\n",
       " '62b123d9-6a45-4dc2-b63e-ce4288a97b09',\n",
       " '973d7661-3b84-4305-a28f-14faeb1fbb74',\n",
       " 'a85e7d47-264f-4f58-b7cf-efebe1f7c527',\n",
       " '0e1d7d80-e733-417c-a38c-83d45fd5e68c',\n",
       " '1acc085d-e681-45d7-801e-126908474828',\n",
       " '7d668d20-00de-4436-9f53-daad09bb4d3e',\n",
       " '62ee6ec3-ff48-428e-804c-6606a78f68cf',\n",
       " 'd4a534cc-6148-444e-a0b2-a7abfa7e7299',\n",
       " '4b8cf5e4-e41b-4256-bb61-0bba4a985647',\n",
       " '52ef3c6e-c21a-459e-bd66-68d954d8ce6d',\n",
       " 'dbdf2c45-25d5-4eb2-b6ce-9e73851f3507',\n",
       " '6c35b052-a85a-4b41-8c1b-e65fd358c747',\n",
       " '64acc2db-e7a0-4b96-9d2a-7f4013297307',\n",
       " '2309fc32-7308-4b00-97ec-bff8dfeb8691',\n",
       " '1e985120-41b3-48f3-80c8-c3b9fb462e1c',\n",
       " '0cf5791b-d8ca-4b2b-8ede-43e2f3577515',\n",
       " 'b6ef61e7-5dce-492e-9876-889185ecbbfa',\n",
       " '893dff61-5d1e-46c8-8ae3-b5b27a57292b',\n",
       " 'a7136d31-3c3a-45ab-853b-51dbf13de454',\n",
       " 'd7d07d4f-73e3-4e83-a5eb-4ca8d75cfeba',\n",
       " 'fe412e43-5aaa-4ad6-b34d-1251ed7a17f3',\n",
       " '3e4315a6-30a9-482f-94bb-d3e40e088f05',\n",
       " '92d09348-2404-47e3-8e62-ce14f680677b',\n",
       " 'aeb4ec6a-1a1b-47e0-8e70-6b165d5e52d5',\n",
       " '298ade9f-06a6-48ce-a89d-e474fbf7d02c',\n",
       " '495efc62-a632-470c-b56f-5ccab3a3c9a1',\n",
       " '496ac4bd-be75-49e8-9d43-cbf02bbe0a2b',\n",
       " 'ffcbd6fe-f5f7-4733-91d7-12c3b29947a8',\n",
       " 'fd34a52f-1eda-420e-babc-d5bda3c9805c',\n",
       " '6caede5b-89b1-42b6-bdd0-f69c7cf5116c',\n",
       " 'f4a8ab96-c3fe-4924-8c4c-16c867dfe4ec',\n",
       " 'cd1b4fb5-36cb-4750-b702-05c5c7a91946',\n",
       " '73125505-7446-4f8e-a2ea-bc4bfc907cb0',\n",
       " 'caa78371-045b-47d0-a910-442a84e6055e',\n",
       " '100a48b5-2709-43ce-a492-07716cb5d44b',\n",
       " '978dfd2c-aada-41e3-861a-aa23ebb554da',\n",
       " '7d29be63-7042-4dc6-bc1a-cfd9f62c0896',\n",
       " '3e34adc8-3fac-4af7-92b9-4a8219d34c2d',\n",
       " '909ba9eb-c4d9-4e91-bedb-0a89b9a15dec',\n",
       " '1d63a02c-3940-446b-a7b2-53045f441084',\n",
       " '349a07e6-ec2c-4fe3-b276-d8f5238538fe',\n",
       " 'abedffbe-9eac-4dbe-93a8-d983180bd128',\n",
       " 'a4cee71e-0a61-4d63-b2f4-7134ba4003d6',\n",
       " '1a691fcf-ed06-4940-9d69-826fe3c4309f']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create embeddings and store in CHROMA database\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"KGLLM\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "# Add documents and their embeddings to Chroma (might take some time)\n",
    "vector_store.add_documents(documents=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query the database\n",
    "query = \"\"\"\n",
    "Extract different LiDAR sensors, their categories, and detailed parts from the given text. \n",
    "Additionally, identify and describe the relationships between each sensor and its parts, \n",
    "including any specific functions or configurations of the parts in relation to the sensors.\n",
    "Also, extract any specific properties (e.g., range, resolution, field of view) and implemented technologies \n",
    "or standards (e.g., GNSS, INS) associated with the sensors.\n",
    "\"\"\"\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(query, k=15)\n",
    "# Concatenate the retrieved chunks\n",
    "retrieved_text = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "# #save the retrieved text\n",
    "# with open(\"retrieved_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(retrieved_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARIZE_PROMPT = \"\"\"\n",
    "As a LiDAR sensor expert, your task is to extract, categorize, and group all the **real, specific, and branded** LiDAR sensor names, their associated components (parts), and relevant properties or implementations mentioned in the following text.\n",
    "\n",
    "**Output Requirements**:\n",
    "1. Provide a concise and structured list of LiDAR sensors and their associated parts.\n",
    "2. Extract and include any **specific properties** or **capabilities** (e.g., \"range\", \"resolution\", \"field of view\") for each sensor, using the \"has property\" relationship.\n",
    "3. Identify and include any **implemented technologies or standards** (e.g., \"GNSS\", \"INS\") using the \"implements\" relationship.\n",
    "4. Group and standardize similar categories to avoid duplicates (e.g., \"Automotive LiDAR\", \"Automotive LiDAR Sensors\", and \"Automotive Sensors\" should be grouped under one category, \"Automotive LiDAR\").\n",
    "5. Categorize the sensors based on their application, type, or any mentioned specifications (e.g., Automotive, Industrial, Surveying).\n",
    "6. Identify and list the **specific parts or components** of each sensor (e.g., \"Laser Module\", \"Spinning Mechanism\", \"Control Unit\"). If no parts are mentioned for a sensor, leave the \"parts\" field empty.\n",
    "\n",
    "**Exclusion Criteria**:\n",
    "- Do not include generic terms such as \"LiDAR\", \"LiDAR sensor\", \"LiDAR sensors\", \"various LiDAR sensors\", or \"no specific brand model mentioned\".\n",
    "- Exclude datasets or evaluation tools (e.g., \"Kitti\", \"NuScenes\").\n",
    "- Ignore descriptions or summaries like \"solid-state LiDAR\", \"lidar technology\", or \"selected sensors are mechanical or solid-state types\".\n",
    "- Avoid placeholder entries like \"not mentioned\" or \"various\".\n",
    "\n",
    "**Formatting**:\n",
    "- Strictly follow the JSON template below and ensure no additional text or explanations are provided:\n",
    "  {{\n",
    "    \"sensors\": [\n",
    "      {{\n",
    "        \"name\": \"Velodyne HDL-64E\",\n",
    "        \"category\": \"Automotive LiDAR\",\n",
    "        \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\n",
    "        \"properties\": [\"range: 100m\", \"resolution: 0.2 degrees\"],\n",
    "        \"implements\": [\"GNSS\", \"INS\"]\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "\n",
    "**Additional Instructions**:\n",
    "- Only include a category if it contains sensors.\n",
    "- Use consistent naming conventions for categories. Avoid redundancy or variations in names.\n",
    "- If no sensors, parts, properties, or implementations are found in the text, return an empty JSON: {{\"sensors\": []}}.\n",
    "- Do not include any additional explanations or information; only return the JSON output.\n",
    "\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormat(Enum):\n",
    "    JSON = \"json_object\"\n",
    "    TEXT = \"text\"\n",
    " \n",
    " \n",
    "def call_model(\n",
    "    prompt: str, response_format: ResponseFormat = ResponseFormat.TEXT\n",
    ") -> str:\n",
    "    response = ollama.generate(\n",
    "        model=MODEL,\n",
    "        prompt=prompt,\n",
    "        keep_alive=\"1h\",\n",
    "        format=\"\" if response_format == ResponseFormat.TEXT else \"json\",\n",
    "    )\n",
    "    return response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Velodyne HDL-64E\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\\n      \"properties\": [\"range: 100m\", \"resolution: 0.2 degrees\"],\\n      \"implements\": [\"GNSS\", \"INS\"]\\n    },\\n    {\\n      \"name\": \"Quanergy M8\",\\n      \"category\": \"Industrial LiDAR\",\\n      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\\n      \"properties\": [\"range: 100m\", \"resolution: 0.1 degrees\"],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Ibeo LUX\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\\n      \"properties\": [\"range: 200m\", \"resolution: 0.1 degrees\"],\\n      \"implements\": [\"GNSS\"]\\n    },\\n    {\\n      \"name\": \"LeddarTech M16\",\\n      \"category\": \"Industrial LiDAR\",\\n      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\\n      \"properties\": [\"range: 150m\", \"resolution: 0.2 degrees\"],\\n      \"implements\": []\\n    }\\n  ]\\n}', '{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Velodyne HDL-64E\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\\n      \"properties\": [\"range: not mentioned\", \"resolution: not mentioned\"],\\n      \"implements\": []\\n    }\\n  ]\\n}', 'Based on the provided text, I found no specific LiDAR sensor names with their associated components or properties. However, I can infer some general requirements for LiDAR sensors in a testing scenario.\\n\\nHere is an empty JSON output as per the instructions:\\n\\n{\\n  \"sensors\": []\\n}', 'Based on the provided text, there is no specific information about LiDAR sensors or their components, properties, or implementations. However, I can provide an empty JSON output as per your requirements:\\n\\n{\\n  \"sensors\": []\\n}', '{\\n    \"sensors\": [\\n        {\\n            \"name\": \"Velodyne Velarray\",\\n            \"category\": \"Automotive LiDAR\",\\n            \"parts\": [],\\n            \"properties\": [\"horizontal FOV: 120°\", \"vertical FOV: 25°\"],\\n            \"implements\": []\\n        },\\n        {\\n            \"name\": \"Robosense M1\",\\n            \"category\": \"Automotive LiDAR\",\\n            \"parts\": [],\\n            \"properties\": [\"horizontal FOV: 120°\", \"vertical FOV: 25°\"],\\n            \"implements\": []\\n        },\\n        {\\n            \"name\": \"Livox Horizon\",\\n            \"category\": \"Automotive LiDAR\",\\n            \"parts\": [],\\n            \"properties\": [\"horizontal FOV: 72°\", \"vertical FOV: 30°\"],\\n            \"implements\": []\\n        }\\n    ]\\n}', '{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Blickfeld Cube\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\\n      \"properties\": [],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Innoviz Pro\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [],\\n      \"properties\": [],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Velodyne HDL-64E\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\\n      \"properties\": [],\\n      \"implements\": [\"GNSS\"]\\n    },\\n    {\\n      \"name\": \"Velarray\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [],\\n      \"properties\": [],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Robosense M1\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [],\\n      \"properties\": [],\\n      \"implements\": [\"GNSS\"]\\n    },\\n    {\\n      \"name\": \"Livox Horizon\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [],\\n      \"properties\": [\"range: 200m\"],\\n      \"implements\": []\\n    }\\n  ]\\n}', '{\\n  \"sensors\": []\\n}', '{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Velodyne HDL-64E\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [],\\n      \"properties\": [],\\n      \"implements\": []\\n    }\\n  ]\\n}', 'The provided text does not contain any specific information about LiDAR sensors, their components, properties, or implementations. Therefore, the output will be an empty JSON:\\n\\n{\\n  \"sensors\": []\\n}', '{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Velodyne HDL-64E\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\\n      \"properties\": [],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Blickfeld Cube Range\",\\n      \"category\": \"Industrial LiDAR\",\\n      \"parts\": [\"Range Module\"],\\n      \"properties\": [\"field of view: narrow\"],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Innoviz Pro\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [],\\n      \"properties\": [],\\n      \"implements\": []\\n    }\\n  ]\\n}', '{\\n  \"sensors\": [\\n    {\\n      \"name\": \"Velodyne HDL-64E\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"],\\n      \"properties\": [],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Robosense M1\",\\n      \"category\": \"Automotive LiDAR\",\\n      \"parts\": [],\\n      \"properties\": [\\n        \"vertical resolution: higher than Velodyne Velarray\"\\n      ],\\n      \"implements\": []\\n    },\\n    {\\n      \"name\": \"Livox Horizon\",\\n      \"category\": \"Surveying LiDAR\",\\n      \"parts\": [],\\n      \"properties\": [],\\n      \"implements\": []\\n    }\\n  ]\\n}', '{\\n  \"sensors\": []\\n}', '{\\n    \"sensors\": []\\n}']\n"
     ]
    }
   ],
   "source": [
    "# Prepare the final prompt with the concatenated text\n",
    "\n",
    "responses = []\n",
    "CHUNK_SIZE = 1000\n",
    "chunks = [retrieved_text[i:i + CHUNK_SIZE] for i in range(0, len(retrieved_text), CHUNK_SIZE)];\n",
    "for i, chunk in enumerate(chunks):\n",
    "        final_prompt = SUMMARIZE_PROMPT.format(text=chunk)\n",
    "    # Send the final prompt to Ollama\n",
    "        response = call_model(final_prompt)\n",
    "        responses.append(response)\n",
    "print(responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save responses after every chunk to ensure progress is retained\n",
    "with open(\"responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensors processed, duplicates removed, and saved to final_sensors_with_parts5.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Function to clean and normalize strings\n",
    "def clean_string(s):\n",
    "    # s = s.strip()  # Remove leading/trailing whitespace\n",
    "    # s = s.encode('utf-8').decode('unicode_escape')  # Decode Unicode escapes\n",
    "    # s = unicodedata.normalize('NFKC', s)  # Normalize special characters\n",
    "    # s = re.sub(r\"[\\s\\_/]+\", \" \", s)  # Replace special separators with space\n",
    "    return s.lower()\n",
    "\n",
    "# Load responses and process them\n",
    "with open(\"responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    responses = json.load(f)\n",
    "\n",
    "# Placeholder for final results and a set to track unique sensors\n",
    "final_sensors = []\n",
    "seen_sensors = set()\n",
    "\n",
    "# Process responses into final_sensors\n",
    "for response in responses:\n",
    "    try:\n",
    "        response_json = json.loads(response)\n",
    "\n",
    "        if \"sensors\" in response_json and isinstance(response_json[\"sensors\"], list):\n",
    "            for sensor in response_json[\"sensors\"]:\n",
    "                sensor_name = clean_string(sensor.get(\"name\", \"Unnamed Sensor\"))\n",
    "                category_name = clean_string(sensor.get(\"category\", \"Uncategorized\"))\n",
    "                parts_list = sensor.get(\"parts\", [])\n",
    "                properties_list = sensor.get(\"properties\", [])\n",
    "                implements_list = sensor.get(\"implements\", [])\n",
    "\n",
    "                # Clean and sort parts to ensure consistent order\n",
    "                cleaned_parts = sorted(clean_string(part) for part in parts_list)\n",
    "                cleaned_properties = sorted(clean_string(prop) for prop in properties_list)\n",
    "                cleaned_implements = sorted(clean_string(imp) for imp in implements_list)\n",
    "               \n",
    "                # Create a tuple to represent the sensor uniquely\n",
    "                sensor_tuple = (sensor_name, category_name, tuple(cleaned_parts), tuple(cleaned_properties), tuple(cleaned_implements))\n",
    "\n",
    "                # If the combination is not seen, add it to the list\n",
    "                if sensor_tuple not in seen_sensors:\n",
    "                    seen_sensors.add(sensor_tuple)\n",
    "                    final_sensors.append({\n",
    "                        \"name\": sensor_name,\n",
    "                        \"category\": category_name,\n",
    "                        \"parts\": cleaned_parts,\n",
    "                        \"properties\": cleaned_properties,\n",
    "                        \"implements\": cleaned_implements\n",
    "                    })\n",
    "    except json.JSONDecodeError as e:\n",
    "        pass\n",
    "        # print(f\"Error parsing response: {response}. Details: {e}\")\n",
    "\n",
    "# Save the cleaned and unique sensors to a new file\n",
    "with open(\"final_sensors_with_parts5.json\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "    json.dump({\"sensors\": final_sensors}, out_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Sensors processed, duplicates removed, and saved to final_sensors_with_parts5.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology created and saved as sensor_ontology_with_properties_and_implements.owl\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"final_sensors_with_parts5.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a new ontology\n",
    "onto = get_ontology(\"http://example.org/sensor_ontology.owl\")\n",
    "\n",
    "with onto:\n",
    "    # Define basic classes and properties\n",
    "    class Sensor(Thing):\n",
    "        pass\n",
    "    \n",
    "    class Part(Thing):\n",
    "        pass\n",
    "    \n",
    "    class Property(Thing):\n",
    "        pass\n",
    "    \n",
    "    class Technology(Thing):\n",
    "        pass\n",
    "\n",
    "    class has_part_directly(ObjectProperty):\n",
    "        domain = [Sensor]\n",
    "        range = [Part]\n",
    "    \n",
    "    class implements(ObjectProperty):\n",
    "        domain = [Sensor]\n",
    "        range = [Technology]\n",
    "    \n",
    "    class has_property(ObjectProperty):\n",
    "        domain = [Sensor]\n",
    "        range = [Property]\n",
    "\n",
    "    # Define an annotation property for category\n",
    "    class category(AnnotationProperty):\n",
    "        pass\n",
    "\n",
    "    # Process the JSON data\n",
    "    part_classes = {}  # Cache for part classes to avoid duplicates\n",
    "    property_classes = {}  # Cache for property classes\n",
    "    technology_classes = {}  # Cache for technology classes\n",
    "\n",
    "    for sensor_data in data[\"sensors\"]:\n",
    "        # Create or get the sensor class\n",
    "        sensor_name = sensor_data[\"name\"].replace(\" \", \"_\")\n",
    "        sensor_category = sensor_data[\"category\"].replace(\" \", \"_\")\n",
    "        \n",
    "        # Define the sensor class dynamically\n",
    "        sensor_class = types.new_class(sensor_name, (Sensor,))\n",
    "        \n",
    "        # Assign category as an annotation\n",
    "        sensor_class.category.append(sensor_category)\n",
    "\n",
    "        # Add parts and relationships\n",
    "        for part_name in sensor_data[\"parts\"]:\n",
    "            part_name_cleaned = part_name.replace(\" \", \"_\")\n",
    "            if part_name_cleaned not in part_classes:\n",
    "                part_class = types.new_class(part_name_cleaned, (Part,))\n",
    "                part_classes[part_name_cleaned] = part_class\n",
    "            else:\n",
    "                part_class = part_classes[part_name_cleaned]\n",
    "\n",
    "            # Create the relationship\n",
    "            sensor_class.is_a.append(has_part_directly.some(part_class))\n",
    "\n",
    "        # Add properties and relationships\n",
    "        for property_name in sensor_data[\"properties\"]:\n",
    "            property_name_cleaned = property_name.replace(\" \", \"_\")\n",
    "            if property_name_cleaned not in property_classes:\n",
    "                property_class = types.new_class(property_name_cleaned, (Property,))\n",
    "                property_classes[property_name_cleaned] = property_class\n",
    "            else:\n",
    "                property_class = property_classes[property_name_cleaned]\n",
    "\n",
    "            # Create the relationship\n",
    "            sensor_class.is_a.append(has_property.some(property_class))\n",
    "\n",
    "        # Add technologies (implements relationship)\n",
    "        for tech_name in sensor_data[\"implements\"]:\n",
    "            tech_name_cleaned = tech_name.replace(\" \", \"_\")\n",
    "            if tech_name_cleaned not in technology_classes:\n",
    "                tech_class = types.new_class(tech_name_cleaned, (Technology,))\n",
    "                technology_classes[tech_name_cleaned] = tech_class\n",
    "            else:\n",
    "                tech_class = technology_classes[tech_name_cleaned]\n",
    "\n",
    "            # Create the relationship\n",
    "            sensor_class.is_a.append(implements.some(tech_class))\n",
    "\n",
    "# Save the ontology to a file\n",
    "onto.save(file=\"sensor_ontology_with_properties_and_implements.owl\", format=\"rdfxml\")\n",
    "\n",
    "print(\"Ontology created and saved as sensor_ontology_with_properties_and_implements.owl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.org/sensor_ontology.owl#\n",
      "[sensor_ontology.Sensor, sensor_ontology.Part, sensor_ontology.velodyne_velarray, sensor_ontology.robosense_m1, sensor_ontology.livox_horizon, sensor_ontology.horizon_m1_cube, sensor_ontology.cube_range, sensor_ontology.h800_pro, sensor_ontology.velodyne_hdl-64e, sensor_ontology.laser_module, sensor_ontology.spinning_mechanism, sensor_ontology.blickfeld_cube, sensor_ontology.innoviz_pro, sensor_ontology.velarray, sensor_ontology.blickfeld_cube_range]\n",
      "[sensor_ontology.has_part_directly, sensor_ontology.category]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the ontology\n",
    "onto = get_ontology(\"sensor_ontology.owl\").load()\n",
    "\n",
    "# Print basic information to check loading\n",
    "print(onto.base_iri)\n",
    "print(list(onto.classes()))\n",
    "print(list(onto.properties()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
