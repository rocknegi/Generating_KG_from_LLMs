{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq pip --progress-bar off\n",
    "%pip install -qqq ollama==0.3.3 --progress-bar off\n",
    "%pip install -qqq pathlib --progress-bar off\n",
    "%pip install -qqq pandas --progress-bar off\n",
    "%pip install -qqq PyPDF2 --progress-bar off\n",
    "%pip install -qqq ollama --progress-bar off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from enum import Enum\n",
    "import PyPDF2\n",
    "import ollama\n",
    "from datetime import datetime as Date\n",
    "\n",
    "MODEL = \"llama3.1:8b-instruct-q8_0\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text extracted from pdf\n"
     ]
    }
   ],
   "source": [
    "def extract_pdf_text(pdf_path):\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \" \".join(page.extract_text() for page in reader.pages)\n",
    "    return text\n",
    "\n",
    "pdf_text = extract_pdf_text(\"sensors.pdf\")\n",
    "print(\"text extracted from pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormat(Enum):\n",
    "    JSON = \"json_object\"\n",
    "    TEXT = \"text\"\n",
    " \n",
    " \n",
    "def call_model(\n",
    "    prompt: str, response_format: ResponseFormat = ResponseFormat.TEXT\n",
    ") -> str:\n",
    "    response = ollama.generate(\n",
    "        model=MODEL,\n",
    "        prompt=prompt,\n",
    "        keep_alive=\"1h\",\n",
    "        format=\"\" if response_format == ResponseFormat.TEXT else \"json\",\n",
    "    )\n",
    "    return response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SUMMARIZE_PROMPT = \"\"\"\n",
    "As a LiDAR sensor expert, your task is to extract and categorize all the LiDAR sensor names mentioned in the following text. \n",
    "\n",
    "**Output Requirements**:\n",
    "1. Provide a concise and structured list of LiDAR sensors.\n",
    "2. Categorize the sensors based on their application, type, or any mentioned specifications (e.g., Automotive, Industrial, Surveying).\n",
    "3. Include the brand or model name if mentioned.\n",
    "\n",
    "**Formatting**:\n",
    "- Strictly follow the JSON template below:\n",
    "{{\n",
    "    \"categories\": [\n",
    "        {{\n",
    "            \"name\": \"Category Name\",\n",
    "            \"sensors\": [\n",
    "                \"Sensor 1\",\n",
    "                \"Sensor 2\"\n",
    "            ]\n",
    "        }}\n",
    "    ],\n",
    "    \"metadata\": {{\n",
    "        \"total_categories\": <number>,\n",
    "        \"total_unique_sensors\": <number>\n",
    "    }}\n",
    "}}\n",
    "\n",
    "**Additional Instructions**:\n",
    "- Only include a sensor category if found along with the identified list of values.\n",
    "- If no sensors are found in the text, return an empty JSON: {{}}.\n",
    "- Do not include any additional explanations or information.\n",
    "\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONDecodeError: Could not parse response: {}\n",
      " \n",
      "(Note: The text does not mention any LiDAR sensors.)\n",
      "Error details: Extra data: line 3 column 1 (char 5)\n",
      "JSONDecodeError: Could not parse response: {}\n",
      "{\n",
      "    \"categories\": [\n",
      "        {\n",
      "            \"name\": \"Unknown Sensors\",\n",
      "            \"sensors\": [\n",
      "                \"LiDAR sensor\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"metadata\": {\n",
      "        \"total_categories\": 1,\n",
      "        \"total_unique_sensors\": 1\n",
      "    }\n",
      "}\n",
      "Error details: Extra data: line 2 column 1 (char 3)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Chunk size for processing\n",
    "CHUNK_SIZE = 1000\n",
    "chunks = [pdf_text[i:i+CHUNK_SIZE] for i in range(0, len(pdf_text), CHUNK_SIZE)]\n",
    "\n",
    "# Placeholder for final results\n",
    "categories_dict = defaultdict(set)\n",
    "\n",
    "# Loop through chunks and get responses\n",
    "for chunk in chunks:\n",
    "    formatted_prompt = SUMMARIZE_PROMPT.format(text=chunk)\n",
    "    response = call_model(formatted_prompt)  # Call your model with the prompt   \n",
    "\n",
    "    try:\n",
    "        # Try parsing the response as JSON\n",
    "        response_json = json.loads(response)\n",
    "        \n",
    "        # Ensure that \"categories\" exists in the response and that it's a list\n",
    "        if \"categories\" in response_json and isinstance(response_json[\"categories\"], list):\n",
    "            for category in response_json[\"categories\"]:\n",
    "                category_name = category.get(\"name\", \"Unidentified Category\")  # Use a default if \"name\" is missing\n",
    "                sensors = category.get(\"sensors\", [])\n",
    "                categories_dict[category_name].update(sensors)\n",
    "        else:\n",
    "            print(f\"No 'categories' key found in response: {response_json}\")\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSONDecodeError: Could not parse response: {response}\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to out/Extracted_Data_11.19.2024_222553.json\n"
     ]
    }
   ],
   "source": [
    "# Prepare the final JSON structure\n",
    "categories_list = []\n",
    "unique_sensors = set()\n",
    "\n",
    "# Loop over the categories_dict to create the list of categories and their sensors\n",
    "for category_name, sensors in categories_dict.items():\n",
    "    categories_list.append({\n",
    "        \"name\": category_name,\n",
    "        \"sensors\": sorted(sensors)\n",
    "    })\n",
    "    unique_sensors.update(sensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
