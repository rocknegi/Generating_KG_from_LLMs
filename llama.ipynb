{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq pip --progress-bar off\n",
    "%pip install -qqq ollama --progress-bar off\n",
    "%pip install -qqq pathlib --progress-bar off\n",
    "%pip install -qqq pandas --progress-bar off\n",
    "%pip install -qqq PyPDF2 --progress-bar off\n",
    "%pip install -qqq ollama --progress-bar off\n",
    "%pip install -qqq owlready2 --progress-bar off\n",
    "%pip install -qqq rdflib --progress-bar off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from enum import Enum\n",
    "import PyPDF2\n",
    "import ollama\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from datetime import datetime\n",
    "import unicodedata\n",
    "\n",
    "MODEL = \"llama3.1:8b-instruct-q8_0\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text extracted from pdf\n"
     ]
    }
   ],
   "source": [
    "def extract_pdf_text(pdf_path):\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \" \".join(page.extract_text() for page in reader.pages)\n",
    "    return text\n",
    "\n",
    "pdf_text = extract_pdf_text(\"sensors.pdf\")\n",
    "print(\"text extracted from pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormat(Enum):\n",
    "    JSON = \"json_object\"\n",
    "    TEXT = \"text\"\n",
    " \n",
    " \n",
    "def call_model(\n",
    "    prompt: str, response_format: ResponseFormat = ResponseFormat.TEXT\n",
    ") -> str:\n",
    "    response = ollama.generate(\n",
    "        model=MODEL,\n",
    "        prompt=prompt,\n",
    "        keep_alive=\"1h\",\n",
    "        format=\"\" if response_format == ResponseFormat.TEXT else \"json\",\n",
    "    )\n",
    "    return response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SUMMARIZE_PROMPT = \"\"\"\n",
    "As a LiDAR sensor expert, your task is to extract, categorize, and group all the **real, specific, and branded** LiDAR sensor names mentioned in the following text.\n",
    "\n",
    "**Output Requirements**:\n",
    "1. Provide a concise and structured list of LiDAR sensors.\n",
    "2. Group and standardize similar categories to avoid duplicates (e.g., \"Automotive LiDAR\", \"Automotive LiDAR Sensors\", and \"Automotive Sensors\" should be grouped under one category, \"Automotive LiDAR\").\n",
    "3. Categorize the sensors based on their application, type, or any mentioned specifications (e.g., Automotive, Industrial, Surveying).\n",
    "4. Include only **specific branded or model names** of sensors (e.g., \"Velodyne Velarray\", \"Livox Horizon\"). \n",
    "\n",
    "**Exclusion Criteria**:\n",
    "- Do not include generic terms such as \"LiDAR\", \"LiDAR sensor\", \"LiDAR sensors\", \"various LiDAR sensors\", or \"no specific brand model mentioned\".\n",
    "- Exclude datasets or evaluation tools (e.g., \"Kitti\", \"NuScenes\").\n",
    "- Ignore descriptions or summaries like \"solid-state LiDAR\", \"lidar technology\", or \"selected sensors are mechanical or solid-state types\".\n",
    "- Avoid placeholder entries like \"not mentioned\" or \"various\".\n",
    "\n",
    "**Formatting**:\n",
    "- Strictly follow the JSON template below:\n",
    "  {{\n",
    "    \"sensors\": [\n",
    "      {{\n",
    "        \"name\": \"Lidar Sensor 1\",\n",
    "        \"category\": \"Category Name\",\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "\n",
    "**Additional Instructions**:\n",
    "- Only include a category if it contains sensors.\n",
    "- Use consistent naming conventions for categories. Avoid redundancy or variations in names.\n",
    "- If no sensors are found in the text, return an empty JSON: {{}}.\n",
    "- Do not include any additional explanations or information.\n",
    "\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created and saved.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Chunk size for processing\n",
    "CHUNK_SIZE = 1000\n",
    "chunks = [pdf_text[i:i + CHUNK_SIZE] for i in range(0, len(pdf_text), CHUNK_SIZE)]\n",
    "\n",
    "# Save chunks to a file if needed\n",
    "with open(\"intermediate_data/chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f)\n",
    "\n",
    "print(\"Chunks created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model responses saved.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Process chunks with the model and save responses\n",
    "responses = []\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    formatted_prompt = SUMMARIZE_PROMPT.format(text=chunk)\n",
    "    response = call_model(formatted_prompt)  # Call your expensive model\n",
    "    responses.append(response)\n",
    "\n",
    "    # Save responses after every chunk to ensure progress is retained\n",
    "    with open(\"intermediate_data/responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(responses, f)\n",
    "\n",
    "print(\"Model responses saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Function to clean strings\n",
    "def clean_string(s):\n",
    "    s = s.strip()  # Remove leading/trailing whitespace\n",
    "    s = s.encode('utf-8').decode('unicode_escape')  # Decode Unicode escapes\n",
    "    s = unicodedata.normalize('NFKC', s)  # Normalize special characters\n",
    "    s = re.sub(r\"[\\s\\-_/]+\", \" \", s)  # Replace special separators with space\n",
    "    s = s.replace(\"\\u00c2\", \"\")  # Remove unwanted artifacts\n",
    "    return s.lower()\n",
    "\n",
    "# Load responses and process them\n",
    "with open(\"intermediate_data/responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    responses = json.load(f)\n",
    "\n",
    "# Placeholder for final results and a set to track unique sensors\n",
    "final_sensors = []\n",
    "seen_sensors = set()\n",
    "\n",
    "# Process responses into final_sensors\n",
    "for response in responses:\n",
    "    try:\n",
    "        response_json = json.loads(response)\n",
    "\n",
    "        if \"sensors\" in response_json and isinstance(response_json[\"sensors\"], list):\n",
    "            for sensor in response_json[\"sensors\"]:\n",
    "                sensor_name = clean_string(sensor.get(\"name\", \"Unnamed Sensor\"))\n",
    "                category_name = clean_string(sensor.get(\"category\", \"Uncategorized\"))\n",
    "\n",
    "                # Create a tuple to represent the sensor as a unique combination of name and category\n",
    "                sensor_tuple = (sensor_name, category_name)\n",
    "\n",
    "                # If the combination is not seen, add it to the list\n",
    "                if sensor_tuple not in seen_sensors:\n",
    "                    seen_sensors.add(sensor_tuple)\n",
    "                    final_sensors.append({\n",
    "                        \"name\": sensor_name,\n",
    "                        \"category\": category_name\n",
    "                    })\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing response: {response}. Details: {e}\")\n",
    "\n",
    "# Save the cleaned and unique sensors to a new file\n",
    "with open(\"final_sensors_no_duplicates.json\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "    json.dump({\"sensors\": final_sensors}, out_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Sensors processed, duplicates removed, and saved to final_sensors_no_duplicates.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology created and saved.\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "# Create a new ontology\n",
    "onto = get_ontology(\"http://example.org/sensors.owl\")\n",
    "\n",
    "# Define classes (Category first, then Sensor as subclass)\n",
    "with onto:\n",
    "    class Category(Thing):\n",
    "        pass\n",
    "\n",
    "    class Sensor(Category):  # Sensor is a subclass of Category\n",
    "        pass\n",
    "    class has_sensor(ObjectProperty):\n",
    "        domain = [Category]\n",
    "        range = [Sensor]\n",
    "\n",
    "# Add individual sensors and categories\n",
    "for sensor in final_sensors:\n",
    "    category_class = types.new_class(sensor[\"category\"], (Category,))\n",
    "    sensor_class = types.new_class(sensor[\"name\"], (Sensor,))\n",
    "    category_class.is_a.append(has_sensor.some(sensor_class))\n",
    "# Save the ontology\n",
    "onto.save(file=\"sensors_ontology.owl\", format=\"rdfxml\")\n",
    "print(\"Ontology created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OWL file created at: lidar_ontology.owl\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import get_ontology, Thing, ObjectProperty\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "# Helper function to clean names\n",
    "def clean_name(name):\n",
    "    return re.sub(r'\\W+', '_', name).strip('_')\n",
    "\n",
    "def create_ontology_from_json(json_data, ontology_url=\"http://example.org/lidar.owl\", output_file=\"lidar_ontology.owl\"):\n",
    "    ontology = get_ontology(ontology_url)\n",
    "\n",
    "    with ontology:\n",
    "        # Define core classes\n",
    "        class LidarCategory(Thing):\n",
    "            pass\n",
    "\n",
    "        class Sensor(Thing):\n",
    "            pass\n",
    "\n",
    "        class has_sensor(ObjectProperty):\n",
    "            domain = [LidarCategory]\n",
    "            range = [Sensor]\n",
    "\n",
    "        sensor_classes = {}\n",
    "\n",
    "        for category in json_data.get(\"categories\", []):\n",
    "            category_name = clean_name(category[\"name\"])\n",
    "            \n",
    "            try:\n",
    "                # Create category class only once\n",
    "                category_class = type(category_name, (LidarCategory,), {})\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating category class '{category_name}': {e}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "\n",
    "            for sensor in category.get(\"sensors\", []):\n",
    "                sensor_name = clean_name(sensor)\n",
    "                \n",
    "                if sensor_name not in sensor_classes:\n",
    "                    try:\n",
    "                        # Create sensor class only once\n",
    "                        sensor_class = type(sensor_name, (Sensor,), {})\n",
    "                        sensor_classes[sensor_name] = sensor_class\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating sensor class '{sensor_name}': {e}\")\n",
    "                        traceback.print_exc()\n",
    "                        continue\n",
    "                else:\n",
    "                    sensor_class = sensor_classes[sensor_name]\n",
    "\n",
    "                try:\n",
    "                    # Add restriction only once per sensor class\n",
    "                    category_class.is_a.append(has_sensor.some(sensor_class))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error adding restriction for '{category_name}' -> '{sensor_name}': {e}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "    try:\n",
    "        ontology.save(file=output_file, format=\"rdfxml\")\n",
    "        print(f\"OWL file created at: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving OWL file: {e}\")\n",
    "        traceback.print_exc()\n",
    "json_data = json.loads(final_output)\n",
    "create_ontology_from_json(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OWL file created at: out/OWL/LIDAR06.12.2024_123654.owl\n"
     ]
    }
   ],
   "source": [
    "json_data = json.loads(final_output)\n",
    "\n",
    "# Define output OWL file path\n",
    "output_owl_file = f\"out/OWL/LIDAR{datetime.now().strftime('%d.%m.%Y_%H%M%S')}.owl\"\n",
    "# Generate the OWL ontology\n",
    "create_ontology_from_json(json_data, output_file=output_owl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OWL_PROMPT = \"\"\"\n",
    "You are an ontology engineering expert specializing in converting structured JSON data into Web Ontology Language (OWL) representations.\n",
    "\n",
    "**Task:** Transform the provided JSON data into a fully functional OWL ontology that captures all semantic relationships, hierarchical structures, and details present in the data.\n",
    "\n",
    "**Input JSON Structure:**\n",
    "\n",
    "{JSON}\n",
    "\n",
    "### Ontology Creation Guidelines:\n",
    "\n",
    "1. **Analyze the JSON Structure**:\n",
    "   - Identify all entities: categories, sensors, and their relationships.\n",
    "   - Treat each category as a subclass of the \"Category\" superclass.\n",
    "   - Treat each sensor as a subclass of the \"Sensor\" superclass.\n",
    "   - Explicitly represent every sensor listed in the JSON as a subclass of `Sensor`.\n",
    "\n",
    "2. **Create OWL Classes**:\n",
    "   - Use \"Thing\" as the base class for all entities.\n",
    "   - Create \"Category\" and \"Sensor\" as direct subclasses of \"Thing\".\n",
    "   - Define each category['name'] from the JSON as a subclass of \"Category\".\n",
    "   - Define each element of the array category['sensor'] from the JSON as a subclass of \"Sensor\".\n",
    "   - Ensure every sensor listed under a category['sensor'] is included as a class.\n",
    "\n",
    "3. **Define Relationships**:\n",
    "   - Use object properties to capture relationships:\n",
    "     - **belongsToCategory**: Links each sensor to the category it belongs to.\n",
    "     - **hasSensor**: Links each category to the sensors it contains.\n",
    "   - For each sensor:\n",
    "     - Create a restriction using **someValuesFrom** to link it to its category via the `belongsToCategory` property.\n",
    "   - For each category:\n",
    "     - Create an object property linking it to its sensors using the `hasSensor` property.\n",
    "\n",
    "4. **Handle Categories Without Sensors**:\n",
    "   - If a category has no sensors listed, create the category class and add a comment (`rdfs:comment`) indicating this.\n",
    "\n",
    "5. **Ontological Structure**:\n",
    "   - Ensure a hierarchical structure:\n",
    "     - **Thing** as the root class.\n",
    "     - **Category** and **Sensor** as direct subclasses.\n",
    "   - Represent categories and sensors as subclasses under their respective hierarchies.\n",
    "   - Use meaningful naming conventions (e.g., PascalCase for classes, camelCase for properties).\n",
    "   - Include comments (`rdfs:comment`) for every class, property, and relationship.\n",
    "\n",
    "6. **Validation and Completeness**:\n",
    "   - Represent all categories and sensors, including categories with no sensors or overlapping names.\n",
    "   - Explicitly capture all semantic relationships for clarity and completeness.\n",
    "   - Validate the ontology for logical consistency.\n",
    "\n",
    "7. **Example Ontology Structure**:\n",
    "   - Classes:\n",
    "     - Base: Thing\n",
    "     - Subclasses: Category and Sensor\n",
    "     - Derived classes for each category and sensor (e.g., AutomotiveLidar, BlickfeldCubeSensors2022).\n",
    "   - Object Properties:\n",
    "     - **belongsToCategory**: Links sensors to their categories.\n",
    "     - **hasSensor**: Links categories to their sensors.\n",
    "   - Relationships:\n",
    "     - If \"Automotive Lidar\" contains \"Blickfeld Cube Sensors 2022\", create:\n",
    "       ```xml\n",
    "       <owl:Class rdf:about=\"#BlickfeldCubeSensors2022\">\n",
    "           <rdfs:label>Blickfeld Cube Sensors 2022</rdfs:label>\n",
    "           <rdfs:subClassOf rdf:resource=\"#Sensor\"/>\n",
    "           <rdfs:subClassOf>\n",
    "               <owl:Restriction>\n",
    "                   <owl:onProperty rdf:resource=\"#belongsToCategory\"/>\n",
    "                   <owl:someValuesFrom rdf:resource=\"#AutomotiveLidar\"/>\n",
    "               </owl:Restriction>\n",
    "           </rdfs:subClassOf>\n",
    "       </owl:Class>\n",
    "       ```\n",
    "       ```xml\n",
    "       <owl:Class rdf:about=\"#AutomotiveLidar\">\n",
    "           <rdfs:label>Automotive Lidar</rdfs:label>\n",
    "           <rdfs:subClassOf rdf:resource=\"#Category\"/>\n",
    "           <hasSensor rdf:resource=\"#BlickfeldCubeSensors2022\"/>\n",
    "       </owl:Class>\n",
    "       ```\n",
    "\n",
    "   - For empty categories, add a comment:\n",
    "     ```xml\n",
    "     <owl:Class rdf:about=\"#NoCategory\">\n",
    "         <rdfs:label>No Category</rdfs:label>\n",
    "         <rdfs:comment>No sensors were listed for this category in the JSON data.</rdfs:comment>\n",
    "     </owl:Class>\n",
    "     ```\n",
    "\n",
    "**Ontology Creation Guidelines:**\n",
    "- Use valid OWL and RDF/XML syntax suitable for tools like Protégé.\n",
    "\n",
    "**Output Requirements:**\n",
    "1. Provide **only the complete OWL ontology in RDF/XML format**.\n",
    "2. Do not include explanations, code snippets, or Python scripts.\n",
    "3. The output must start with `<?xml version=\"1.0\"?>` and end with `</rdf:RDF>`.\n",
    "4. Exclude any additional comments, explanations, or programming instructions.\n",
    "**Generate the complete OWL ontology based on these guidelines.**\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "OWL_RESPONSE = call_model(OWL_PROMPT.format(JSON=final_output));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the owl file\n",
    "with open(\"Extracted_Data2.owl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(OWL_RESPONSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
