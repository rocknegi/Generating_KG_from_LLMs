{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq pip --progress-bar off\n",
    "%pip install -qqq ollama --progress-bar off\n",
    "%pip install -qqq pathlib --progress-bar off\n",
    "%pip install -qqq pandas --progress-bar off\n",
    "%pip install -qqq PyPDF2 --progress-bar off\n",
    "%pip install -qqq ollama --progress-bar off\n",
    "%pip install -qqq owlready2 --progress-bar off\n",
    "%pip install -qqq rdflib --progress-bar off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from enum import Enum\n",
    "import PyPDF2\n",
    "import ollama\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from datetime import datetime\n",
    "import unicodedata\n",
    "\n",
    "MODEL = \"llama3.1:8b-instruct-q8_0\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text extracted from pdf\n"
     ]
    }
   ],
   "source": [
    "def extract_pdf_text(pdf_path):\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \" \".join(page.extract_text() for page in reader.pages)\n",
    "    return text\n",
    "\n",
    "pdf_text = extract_pdf_text(\"sensors.pdf\")\n",
    "print(\"text extracted from pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormat(Enum):\n",
    "    JSON = \"json_object\"\n",
    "    TEXT = \"text\"\n",
    " \n",
    " \n",
    "def call_model(\n",
    "    prompt: str, response_format: ResponseFormat = ResponseFormat.TEXT\n",
    ") -> str:\n",
    "    response = ollama.generate(\n",
    "        model=MODEL,\n",
    "        prompt=prompt,\n",
    "        keep_alive=\"1h\",\n",
    "        format=\"\" if response_format == ResponseFormat.TEXT else \"json\",\n",
    "    )\n",
    "    return response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SUMMARIZE_PROMPT = \"\"\"\n",
    "As a LiDAR sensor expert, your task is to extract, categorize, and group all the **real, specific, and branded** LiDAR sensor names and their associated components (parts) mentioned in the following text.\n",
    "\n",
    "**Output Requirements**:\n",
    "1. Provide a concise and structured list of LiDAR sensors and their associated parts.\n",
    "2. Group and standardize similar categories to avoid duplicates (e.g., \"Automotive LiDAR\", \"Automotive LiDAR Sensors\", and \"Automotive Sensors\" should be grouped under one category, \"Automotive LiDAR\").\n",
    "3. Categorize the sensors based on their application, type, or any mentioned specifications (e.g., Automotive, Industrial, Surveying).\n",
    "4. Identify and list the **specific parts or components** of each sensor (e.g., \"Laser Module\", \"Spinning Mechanism\", \"Control Unit\"). If no parts are mentioned for a sensor, leave the \"parts\" field empty.\n",
    "\n",
    "**Exclusion Criteria**:\n",
    "- Do not include generic terms such as \"LiDAR\", \"LiDAR sensor\", \"LiDAR sensors\", \"various LiDAR sensors\", or \"no specific brand model mentioned\".\n",
    "- Exclude datasets or evaluation tools (e.g., \"Kitti\", \"NuScenes\").\n",
    "- Ignore descriptions or summaries like \"solid-state LiDAR\", \"lidar technology\", or \"selected sensors are mechanical or solid-state types\".\n",
    "- Avoid placeholder entries like \"not mentioned\" or \"various\".\n",
    "\n",
    "**Formatting**:\n",
    "- Strictly follow the JSON template below:\n",
    "  {{\n",
    "    \"sensors\": [\n",
    "      {{\n",
    "        \"name\": \"Lidar Sensor 1\",\n",
    "        \"category\": \"Category Name\",\n",
    "        \"parts\": [\"Part 1\", \"Part 2\"]\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "\n",
    "**Additional Instructions**:\n",
    "- Only include a category if it contains sensors.\n",
    "- Use consistent naming conventions for categories. Avoid redundancy or variations in names.\n",
    "- If no sensors or parts are found in the text, return an empty JSON: {{}}.\n",
    "- Do not include any additional explanations or information.\n",
    "\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created and saved.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Chunk size for processing\n",
    "CHUNK_SIZE = 1000\n",
    "chunks = [pdf_text[i:i + CHUNK_SIZE] for i in range(0, len(pdf_text), CHUNK_SIZE)]\n",
    "\n",
    "# Save chunks to a file if needed\n",
    "with open(\"intermediate_data/chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f)\n",
    "\n",
    "print(\"Chunks created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model responses saved.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Process chunks with the model and save responses\n",
    "responses = []\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    formatted_prompt = SUMMARIZE_PROMPT.format(text=chunk)\n",
    "    response = call_model(formatted_prompt)  # Call your expensive model\n",
    "    responses.append(response)\n",
    "\n",
    "    # Save responses after every chunk to ensure progress is retained\n",
    "    with open(\"intermediate_data/responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(responses, f)\n",
    "\n",
    "print(\"Model responses saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response: {} \n",
      "\n",
      "The provided text does not mention any specific LiDAR sensor names or associated components. The text appears to be a citation and academic article metadata, but it doesn't contain the necessary information for extraction and categorization as per the task requirements.. Details: Extra data: line 3 column 1 (char 5)\n",
      "Error parsing response: Here is the extracted information in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"sensors\": [\n",
      "    {\n",
      "      \"name\": \"Livox Horizon\",\n",
      "      \"category\": \"Automotive LiDAR\",\n",
      "      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Robosense M1\",\n",
      "      \"category\": \"Automotive LiDAR\",\n",
      "      \"parts\": [\"Control Unit\", \"Sensor Head\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Blickfeld Cube\",\n",
      "      \"category\": \"Automotive LiDAR\",\n",
      "      \"parts\": [\"Camera Module\", \"MEMS Scanner\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Blickfeld Cube Range\",\n",
      "      \"category\": \"Automotive LiDAR\",\n",
      "      \"parts\": [\"Laser Scanner\", \"Signal Processing Unit\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Velodyne Velarray H800\",\n",
      "      \"category\": \"Automotive LiDAR\",\n",
      "      \"parts\": [\"High-Resolution Sensor Head\", \"FPGA-based Signal Processor\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Innoviz Pro\",\n",
      "      \"category\": \"Automotive LiDAR\",\n",
      "      \"parts\": [\"Laser Module\", \"MEMS Scanner\"]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: {}\n",
      "I couldn't find any specific, real, branded LiDAR sensor names or their associated components mentioned in the text.\n",
      "\n",
      "Since there are no sensors or parts mentioned, I return an empty JSON as per the instructions.. Details: Extra data: line 2 column 1 (char 3)\n",
      "Error parsing response: Here is the extracted list of LiDAR sensors, categorized by application or type, along with their associated components:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"sensors\": [\n",
      "    {\n",
      "      \"name\": \"Livox\",\n",
      "      \"category\": \"LiDAR\",\n",
      "      \"parts\": [\"Rotating Prisms\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Robosense\",\n",
      "      \"category\": \"Industrial LiDAR\",\n",
      "      \"parts\": []\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Blickfeld\",\n",
      "      \"category\": \"Surveying LiDAR\",\n",
      "      \"parts\": [\"MEMS\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Velodyne\",\n",
      "      \"category\": \"Autonomous Vehicle LiDAR\",\n",
      "      \"parts\": [\"Solid State\", \"MEMS\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Innoviz\",\n",
      "      \"category\": \"Autonomous Vehicle LiDAR\",\n",
      "      \"parts\": [\"MEMS\"]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Note: Some parts (e.g., \"Principle\") are not explicitly listed as individual components, but I tried to include the relevant information that can be inferred from the text. If you want to stick strictly to the given format and only list specific parts/components mentioned in the text, the output would be:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"sensors\": [\n",
      "    {\n",
      "      \"name\": \"Livox\",\n",
      "      \"category\": \"LiDAR\",\n",
      "      \"parts\": [\"Rotating Prisms\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Blickfeld\",\n",
      "      \"category\": \"Surveying LiDAR\",\n",
      "      \"parts\": []\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Velodyne\",\n",
      "      \"category\": \"Autonomous Vehicle LiDAR\",\n",
      "      \"parts\": []\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Innoviz\",\n",
      "      \"category\": \"Autonomous Vehicle LiDAR\",\n",
      "      \"parts\": []\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: ```json\n",
      "{\n",
      "  \"sensors\": [\n",
      "    {\n",
      "      \"name\": \"Velodyne HDL-32E\",\n",
      "      \"category\": \"Automotive LiDAR\",\n",
      "      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Quanergy M8\",\n",
      "      \"category\": \"Industrial LiDAR\",\n",
      "      \"parts\": []\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: ```json\n",
      "{\n",
      "    \"sensors\": [\n",
      "        {\n",
      "            \"name\": \"Velodyne\",\n",
      "            \"category\": \"Industrial LiDAR\",\n",
      "            \"parts\": []\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"LIDAR Sensor (unspecified brand)\",\n",
      "            \"category\": \"Automotive LiDAR\",\n",
      "            \"parts\": [\"Spinning Mechanism\", \"Control Unit\"]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "Note: The text does not specify the exact model or type of Velodyne LiDAR sensor, so I have only included the general category \"Industrial LiDAR\".. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: After analyzing the provided text, I was unable to extract any specific LiDAR sensor names or their associated components. The text appears to describe an experimental setup and mathematical equations related to a point cloud analysis, but it does not mention any branded or specific LiDAR sensors.\n",
      "\n",
      "However, since you requested that I follow the JSON template and provide a structured list of LiDAR sensors with their parts (even if there are none), I will create a minimal JSON output. Please note that this output is empty because no specific LiDAR sensor information was found in the text.\n",
      "\n",
      "\n",
      "```\n",
      "{\n",
      "  \"sensors\": []\n",
      "}\n",
      "```. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: ```json\n",
      "{\n",
      "  \"sensors\": []\n",
      "}\n",
      "```\n",
      "\n",
      "The provided text does not mention specific LiDAR sensor names or their associated components.. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: {}\n",
      " \n",
      "There are no specific LiDAR sensor names or parts mentioned in the provided text.. Details: Extra data: line 3 column 1 (char 5)\n",
      "Error parsing response: Here is the extracted list of LiDAR sensors, their associated parts, and categorized by application or type:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"sensors\": [\n",
      "    {\n",
      "      \"name\": \"Livox Horizon\",\n",
      "      \"category\": \"Surveying/Indoor Mapping\",\n",
      "      \"parts\": []\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Blickfeld Cube\",\n",
      "      \"category\": \"Automotive\",\n",
      "      \"parts\": []\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Velarray\",\n",
      "      \"category\": \"Automotive\",\n",
      "      \"parts\": []\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Note: Although the text mentions other LiDAR sensors, only Livox Horizon, Blickfeld Cube, and Velarray are specific, branded names with at least one mention. Other references to LiDAR sensors were either generic or not specified as a brand model.. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: {}\n",
      " \n",
      "\n",
      "Explanation: The provided text does not mention any real, specific, or branded LiDAR sensor names or their associated components. Hence, there's nothing to extract and categorize based on the given requirements.. Details: Extra data: line 4 column 1 (char 6)\n",
      "Error parsing response: ```json\n",
      "{\n",
      "  \"sensors\": [\n",
      "    {\n",
      "      \"name\": \"Velodyne LiDAR\",\n",
      "      \"category\": \"Industrial/Robotics LiDAR\",\n",
      "      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Hesai Mid-40 LiDAR\",\n",
      "      \"category\": \"Automotive LiDAR\",\n",
      "      \"parts\": [\"Lidar Board\", \"Mechanical Frame\"]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "The code above provides the JSON output with the specific and branded LiDAR sensors extracted, categorized, and grouped as per the requirements. \n",
      "\n",
      "**Notes:**\n",
      "\n",
      "1. Only two LiDAR sensor names are explicitly mentioned in the provided text - \"Velodyne\" and \"Hesai Mid-40.\" Other LiDARs were excluded due to lack of specific brand or model names.\n",
      "2. Velodyne is a well-known industrial/robotics LiDAR manufacturer, making it suitable for categorization under this category. Hesai's Mid-40 is primarily used in automotive applications.\n",
      "3. The components listed (\"Laser Module,\" \"Spinning Mechanism\" and \"Lidar Board,\" \"Mechanical Frame\") are deduced from a general understanding of typical LiDAR sensor structure, as specific parts mentioned in the text were not found.\n",
      "\n",
      "If no sensors or parts are found in the provided text, an empty JSON object like this would be returned: `{}. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: ```json\n",
      "{\n",
      "    \"sensors\": []\n",
      "}\n",
      "```\n",
      "\n",
      "There are no specific LiDAR sensor names or associated components mentioned in the given text. The output is an empty JSON object as instructed when no sensors or parts are found.. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: Based on the provided text, I was unable to extract any specific LiDAR sensor names or associated parts. The text appears to be a research paper with no mention of LiDAR sensors.\n",
      "\n",
      "However, I did find a reference to \"SAE International Standard J3016: 2014\", which may relate to automotive LiDAR. But without further information, it's difficult to determine if this is indeed related to LiDAR or just a general standard for autonomous driving.\n",
      "\n",
      "Given the exclusion criteria and lack of relevant information in the text, I will return an empty JSON object:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"sensors\": []\n",
      "}\n",
      "```. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: After processing the text, I was unable to extract any specific LiDAR sensor names and their associated components. The text appears to be a reference list of academic papers and projects related to autonomous vehicles, with no specific mention of LiDAR sensors or their parts.\n",
      "\n",
      "However, I did find some mentions of automotive LiDAR technology and related projects. Here is an empty JSON response:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"sensors\": []\n",
      "}\n",
      "```. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing response: Here is the extracted and categorized list of LiDAR sensors and their associated components:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"sensors\": [\n",
      "    {\n",
      "      \"name\": \"Quanergy M8\",\n",
      "      \"category\": \"Automotive LiDAR\",\n",
      "      \"parts\": [\"Laser Module\", \"Spinning Mechanism\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Velodyne VLS-128\",\n",
      "      \"category\": \"Autonomous Vehicle LiDAR\",\n",
      "      \"parts\": [\"Lidar Sensor Head\", \"Control Unit\"]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"LIDAR-Lite v4\",\n",
      "      \"category\": \"Surveying and Mapping LiDAR\",\n",
      "      \"parts\": [\"Optical System\", \"Signal Processing Unit\"]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Note: The specific models of LiDAR sensors (e.g., Quanergy M8, Velodyne VLS-128) were extracted from the reference [11] in the original text. These are real, specific, and branded LiDAR sensor names.. Details: Expecting value: line 1 column 1 (char 0)\n",
      "Sensors processed, duplicates removed, and saved to final_sensors_with_parts.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Function to clean strings\n",
    "def clean_string(s):\n",
    "    s = s.strip()  # Remove leading/trailing whitespace\n",
    "    s = s.encode('utf-8').decode('unicode_escape')  # Decode Unicode escapes\n",
    "    s = unicodedata.normalize('NFKC', s)  # Normalize special characters\n",
    "    s = re.sub(r\"[\\s\\-_/]+\", \" \", s)  # Replace special separators with space\n",
    "    s = s.replace(\"\\u00c2\", \"\")  # Remove unwanted artifacts\n",
    "    return s.lower()\n",
    "\n",
    "# Load responses and process them\n",
    "with open(\"intermediate_data/responses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    responses = json.load(f)\n",
    "\n",
    "# Placeholder for final results and a set to track unique sensors\n",
    "final_sensors = []\n",
    "seen_sensors = set()\n",
    "\n",
    "# Process responses into final_sensors\n",
    "for response in responses:\n",
    "    try:\n",
    "        response_json = json.loads(response)\n",
    "\n",
    "        if \"sensors\" in response_json and isinstance(response_json[\"sensors\"], list):\n",
    "            for sensor in response_json[\"sensors\"]:\n",
    "                sensor_name = clean_string(sensor.get(\"name\", \"Unnamed Sensor\"))\n",
    "                category_name = clean_string(sensor.get(\"category\", \"Uncategorized\"))\n",
    "                parts_list = sensor.get(\"parts\", [])\n",
    "\n",
    "                # Ensure parts are cleaned and formatted\n",
    "                cleaned_parts = [clean_string(part) for part in parts_list]\n",
    "\n",
    "                # Create a tuple to represent the sensor as a unique combination of name, category, and parts\n",
    "                sensor_tuple = (sensor_name, category_name, tuple(cleaned_parts))\n",
    "\n",
    "                # If the combination is not seen, add it to the list\n",
    "                if sensor_tuple not in seen_sensors:\n",
    "                    seen_sensors.add(sensor_tuple)\n",
    "                    final_sensors.append({\n",
    "                        \"name\": sensor_name,\n",
    "                        \"category\": category_name,\n",
    "                        \"parts\": cleaned_parts\n",
    "                    })\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing response: {response}. Details: {e}\")\n",
    "\n",
    "# Save the cleaned and unique sensors to a new file\n",
    "with open(\"final_sensors_with_parts.json\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "    json.dump({\"sensors\": final_sensors}, out_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Sensors processed, duplicates removed, and saved to final_sensors_with_parts.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology updated and saved.\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "# Create a new ontology\n",
    "onto = get_ontology(\"http://example.org/sensors.owl\")\n",
    "\n",
    "# Define classes and relationships\n",
    "with onto:\n",
    "    class Category(Thing):\n",
    "        pass\n",
    "\n",
    "    class Sensor(Thing):  \n",
    "        pass\n",
    "\n",
    "    class Part(Thing):  \n",
    "        pass\n",
    "\n",
    "    class partOf(ObjectProperty):  # Standardized relationship\n",
    "        domain = [Part]\n",
    "        range = [Sensor]\n",
    "\n",
    "    class belongsToCategory(ObjectProperty):  \n",
    "        domain = [Sensor]\n",
    "        range = [Category]\n",
    "\n",
    "# Add categories, sensors, and parts\n",
    "for sensor in final_sensors:\n",
    "    # Create or get the category class\n",
    "    category_name = sensor[\"category\"].replace(\" \", \"_\")\n",
    "    category_class = onto.search_one(iri=f\"*{category_name}\") or types.new_class(category_name, (Category,))\n",
    "    category_class.comment = f\"This category represents {sensor['category']} sensors.\"\n",
    "\n",
    "    # Create the sensor class\n",
    "    sensor_name = sensor[\"name\"].replace(\" \", \"_\")\n",
    "    sensor_class = onto.search_one(iri=f\"*{sensor_name}\") or types.new_class(sensor_name, (Sensor,))\n",
    "    sensor_class.comment = f\"This is the {sensor['name']} sensor model.\"\n",
    "\n",
    "    # Link sensor to its category\n",
    "    sensor_class.is_a.append(belongsToCategory.value(category_class))\n",
    "\n",
    "    # Add parts as individuals related to the sensor\n",
    "    if \"parts\" in sensor and sensor[\"parts\"]:\n",
    "        for part_name in sensor[\"parts\"]:\n",
    "            part_individual = onto.search_one(iri=f\"*{part_name.replace(' ', '_')}\") or Part(part_name.replace(\" \", \"_\"))\n",
    "            part_individual.comment = f\"This part is a {part_name} of the {sensor['name']} sensor.\"\n",
    "            sensor_class.is_a.append(partOf.value(part_individual))\n",
    "\n",
    "# Save the ontology\n",
    "onto.save(file=\"sensors_ontology_updated.owl\", format=\"rdfxml\")\n",
    "print(\"Ontology updated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OWL file created at: lidar_ontology.owl\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import get_ontology, Thing, ObjectProperty\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "# Helper function to clean names\n",
    "def clean_name(name):\n",
    "    return re.sub(r'\\W+', '_', name).strip('_')\n",
    "\n",
    "def create_ontology_from_json(json_data, ontology_url=\"http://example.org/lidar.owl\", output_file=\"lidar_ontology.owl\"):\n",
    "    ontology = get_ontology(ontology_url)\n",
    "\n",
    "    with ontology:\n",
    "        # Define core classes\n",
    "        class LidarCategory(Thing):\n",
    "            pass\n",
    "\n",
    "        class Sensor(Thing):\n",
    "            pass\n",
    "\n",
    "        class has_sensor(ObjectProperty):\n",
    "            domain = [LidarCategory]\n",
    "            range = [Sensor]\n",
    "\n",
    "        sensor_classes = {}\n",
    "\n",
    "        for category in json_data.get(\"categories\", []):\n",
    "            category_name = clean_name(category[\"name\"])\n",
    "            \n",
    "            try:\n",
    "                # Create category class only once\n",
    "                category_class = type(category_name, (LidarCategory,), {})\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating category class '{category_name}': {e}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "\n",
    "            for sensor in category.get(\"sensors\", []):\n",
    "                sensor_name = clean_name(sensor)\n",
    "                \n",
    "                if sensor_name not in sensor_classes:\n",
    "                    try:\n",
    "                        # Create sensor class only once\n",
    "                        sensor_class = type(sensor_name, (Sensor,), {})\n",
    "                        sensor_classes[sensor_name] = sensor_class\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating sensor class '{sensor_name}': {e}\")\n",
    "                        traceback.print_exc()\n",
    "                        continue\n",
    "                else:\n",
    "                    sensor_class = sensor_classes[sensor_name]\n",
    "\n",
    "                try:\n",
    "                    # Add restriction only once per sensor class\n",
    "                    category_class.is_a.append(has_sensor.some(sensor_class))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error adding restriction for '{category_name}' -> '{sensor_name}': {e}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "    try:\n",
    "        ontology.save(file=output_file, format=\"rdfxml\")\n",
    "        print(f\"OWL file created at: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving OWL file: {e}\")\n",
    "        traceback.print_exc()\n",
    "json_data = json.loads(final_output)\n",
    "create_ontology_from_json(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OWL file created at: out/OWL/LIDAR06.12.2024_123654.owl\n"
     ]
    }
   ],
   "source": [
    "json_data = json.loads(final_output)\n",
    "\n",
    "# Define output OWL file path\n",
    "output_owl_file = f\"out/OWL/LIDAR{datetime.now().strftime('%d.%m.%Y_%H%M%S')}.owl\"\n",
    "# Generate the OWL ontology\n",
    "create_ontology_from_json(json_data, output_file=output_owl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OWL_PROMPT = \"\"\"\n",
    "You are an ontology engineering expert specializing in converting structured JSON data into Web Ontology Language (OWL) representations.\n",
    "\n",
    "**Task:** Transform the provided JSON data into a fully functional OWL ontology that captures all semantic relationships, hierarchical structures, and details present in the data.\n",
    "\n",
    "**Input JSON Structure:**\n",
    "\n",
    "{JSON}\n",
    "\n",
    "### Ontology Creation Guidelines:\n",
    "\n",
    "1. **Analyze the JSON Structure**:\n",
    "   - Identify all entities: categories, sensors, and their relationships.\n",
    "   - Treat each category as a subclass of the \"Category\" superclass.\n",
    "   - Treat each sensor as a subclass of the \"Sensor\" superclass.\n",
    "   - Explicitly represent every sensor listed in the JSON as a subclass of `Sensor`.\n",
    "\n",
    "2. **Create OWL Classes**:\n",
    "   - Use \"Thing\" as the base class for all entities.\n",
    "   - Create \"Category\" and \"Sensor\" as direct subclasses of \"Thing\".\n",
    "   - Define each category['name'] from the JSON as a subclass of \"Category\".\n",
    "   - Define each element of the array category['sensor'] from the JSON as a subclass of \"Sensor\".\n",
    "   - Ensure every sensor listed under a category['sensor'] is included as a class.\n",
    "\n",
    "3. **Define Relationships**:\n",
    "   - Use object properties to capture relationships:\n",
    "     - **belongsToCategory**: Links each sensor to the category it belongs to.\n",
    "     - **hasSensor**: Links each category to the sensors it contains.\n",
    "   - For each sensor:\n",
    "     - Create a restriction using **someValuesFrom** to link it to its category via the `belongsToCategory` property.\n",
    "   - For each category:\n",
    "     - Create an object property linking it to its sensors using the `hasSensor` property.\n",
    "\n",
    "4. **Handle Categories Without Sensors**:\n",
    "   - If a category has no sensors listed, create the category class and add a comment (`rdfs:comment`) indicating this.\n",
    "\n",
    "5. **Ontological Structure**:\n",
    "   - Ensure a hierarchical structure:\n",
    "     - **Thing** as the root class.\n",
    "     - **Category** and **Sensor** as direct subclasses.\n",
    "   - Represent categories and sensors as subclasses under their respective hierarchies.\n",
    "   - Use meaningful naming conventions (e.g., PascalCase for classes, camelCase for properties).\n",
    "   - Include comments (`rdfs:comment`) for every class, property, and relationship.\n",
    "\n",
    "6. **Validation and Completeness**:\n",
    "   - Represent all categories and sensors, including categories with no sensors or overlapping names.\n",
    "   - Explicitly capture all semantic relationships for clarity and completeness.\n",
    "   - Validate the ontology for logical consistency.\n",
    "\n",
    "7. **Example Ontology Structure**:\n",
    "   - Classes:\n",
    "     - Base: Thing\n",
    "     - Subclasses: Category and Sensor\n",
    "     - Derived classes for each category and sensor (e.g., AutomotiveLidar, BlickfeldCubeSensors2022).\n",
    "   - Object Properties:\n",
    "     - **belongsToCategory**: Links sensors to their categories.\n",
    "     - **hasSensor**: Links categories to their sensors.\n",
    "   - Relationships:\n",
    "     - If \"Automotive Lidar\" contains \"Blickfeld Cube Sensors 2022\", create:\n",
    "       ```xml\n",
    "       <owl:Class rdf:about=\"#BlickfeldCubeSensors2022\">\n",
    "           <rdfs:label>Blickfeld Cube Sensors 2022</rdfs:label>\n",
    "           <rdfs:subClassOf rdf:resource=\"#Sensor\"/>\n",
    "           <rdfs:subClassOf>\n",
    "               <owl:Restriction>\n",
    "                   <owl:onProperty rdf:resource=\"#belongsToCategory\"/>\n",
    "                   <owl:someValuesFrom rdf:resource=\"#AutomotiveLidar\"/>\n",
    "               </owl:Restriction>\n",
    "           </rdfs:subClassOf>\n",
    "       </owl:Class>\n",
    "       ```\n",
    "       ```xml\n",
    "       <owl:Class rdf:about=\"#AutomotiveLidar\">\n",
    "           <rdfs:label>Automotive Lidar</rdfs:label>\n",
    "           <rdfs:subClassOf rdf:resource=\"#Category\"/>\n",
    "           <hasSensor rdf:resource=\"#BlickfeldCubeSensors2022\"/>\n",
    "       </owl:Class>\n",
    "       ```\n",
    "\n",
    "   - For empty categories, add a comment:\n",
    "     ```xml\n",
    "     <owl:Class rdf:about=\"#NoCategory\">\n",
    "         <rdfs:label>No Category</rdfs:label>\n",
    "         <rdfs:comment>No sensors were listed for this category in the JSON data.</rdfs:comment>\n",
    "     </owl:Class>\n",
    "     ```\n",
    "\n",
    "**Ontology Creation Guidelines:**\n",
    "- Use valid OWL and RDF/XML syntax suitable for tools like Protégé.\n",
    "\n",
    "**Output Requirements:**\n",
    "1. Provide **only the complete OWL ontology in RDF/XML format**.\n",
    "2. Do not include explanations, code snippets, or Python scripts.\n",
    "3. The output must start with `<?xml version=\"1.0\"?>` and end with `</rdf:RDF>`.\n",
    "4. Exclude any additional comments, explanations, or programming instructions.\n",
    "**Generate the complete OWL ontology based on these guidelines.**\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "OWL_RESPONSE = call_model(OWL_PROMPT.format(JSON=final_output));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the owl file\n",
    "with open(\"Extracted_Data2.owl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(OWL_RESPONSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
